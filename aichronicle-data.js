// ================================================
// THE AI CHRONICLE - Knowledge Graph Data
// Auto-generated and updated daily via GitHub Actions
// Last updated: 2026-02-11
// ================================================

const AIChronicleData = {
    "metadata": {
        "lastUpdated": "2026-02-11T06:59:01.042751Z",
        "totalArticles": 144,
        "totalNodes": 166,
        "totalEdges": 231,
        "dateRange": {
            "start": "2026-02-04",
            "end": "2026-02-11"
        }
    },
    "nodes": [
        {
            "id": "article-4e2348af",
            "type": "article",
            "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
            "summary": "arXiv:2602.07032v1 Announce Type: new Abstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually co",
            "url": "https://arxiv.org/abs/2602.07032",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-cbe7a7f3",
            "type": "article",
            "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
            "summary": "arXiv:2602.07034v1 Announce Type: new Abstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Exi",
            "url": "https://arxiv.org/abs/2602.07034",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-7da7b9d6",
            "type": "article",
            "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
            "summary": "arXiv:2602.07035v1 Announce Type: new Abstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct",
            "url": "https://arxiv.org/abs/2602.07035",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-fc694bfa",
            "type": "article",
            "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
            "summary": "arXiv:2602.07040v1 Announce Type: new Abstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to in",
            "url": "https://arxiv.org/abs/2602.07040",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-9f4197a3",
            "type": "article",
            "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
            "summary": "arXiv:2602.07055v1 Announce Type: new Abstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, part",
            "url": "https://arxiv.org/abs/2602.07055",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-654cc34f",
            "type": "article",
            "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
            "summary": "arXiv:2602.07153v1 Announce Type: new Abstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify ",
            "url": "https://arxiv.org/abs/2602.07153",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-32cefdbb",
            "type": "article",
            "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
            "summary": "arXiv:2602.07187v1 Announce Type: new Abstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by critic",
            "url": "https://arxiv.org/abs/2602.07187",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-5c5168b9",
            "type": "article",
            "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
            "summary": "arXiv:2602.07238v1 Announce Type: new Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-",
            "url": "https://arxiv.org/abs/2602.07238",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f297f39a",
            "type": "article",
            "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
            "summary": "arXiv:2602.07253v1 Announce Type: new Abstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer visio",
            "url": "https://arxiv.org/abs/2602.07253",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e1fdcfbe",
            "type": "article",
            "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
            "summary": "arXiv:2602.07259v1 Announce Type: new Abstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how m",
            "url": "https://arxiv.org/abs/2602.07259",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-2ebe3eb0",
            "type": "article",
            "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
            "summary": "arXiv:2602.07267v1 Announce Type: new Abstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion",
            "url": "https://arxiv.org/abs/2602.07267",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-9d4302c9",
            "type": "article",
            "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
            "summary": "arXiv:2602.07274v1 Announce Type: new Abstract: Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common",
            "url": "https://arxiv.org/abs/2602.07274",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f3a26c90",
            "type": "article",
            "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
            "summary": "arXiv:2602.07276v1 Announce Type: new Abstract: Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by c",
            "url": "https://arxiv.org/abs/2602.07276",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-63b5018d",
            "type": "article",
            "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System",
            "summary": "arXiv:2602.07308v1 Announce Type: new Abstract: The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selectin",
            "url": "https://arxiv.org/abs/2602.07308",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-310c6cc4",
            "type": "article",
            "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving",
            "summary": "arXiv:2602.07339v1 Announce Type: new Abstract: Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using s",
            "url": "https://arxiv.org/abs/2602.07339",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e813294f",
            "type": "article",
            "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management",
            "summary": "arXiv:2602.07342v1 Announce Type: new Abstract: Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world",
            "url": "https://arxiv.org/abs/2602.07342",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f23f74fa",
            "type": "article",
            "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents",
            "summary": "arXiv:2602.07359v1 Announce Type: new Abstract: Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a f",
            "url": "https://arxiv.org/abs/2602.07359",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-d10f3bd2",
            "type": "article",
            "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents",
            "summary": "arXiv:2602.07391v1 Announce Type: new Abstract: AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exp",
            "url": "https://arxiv.org/abs/2602.07391",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e5058201",
            "type": "article",
            "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation",
            "summary": "arXiv:2602.07399v1 Announce Type: new Abstract: Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{",
            "url": "https://arxiv.org/abs/2602.07399",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-72c66faa",
            "type": "article",
            "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction",
            "summary": "arXiv:2602.07408v1 Announce Type: new Abstract: Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug disc",
            "url": "https://arxiv.org/abs/2602.07408",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-a25d130b",
            "type": "article",
            "title": "Enhanced Graph Transformer with Serialized Graph Tokens",
            "summary": "arXiv:2602.09065v1 Announce Type: new Abstract: Transformers have demonstrated success in graph learning, particularly for node-level tasks. However, existing methods encounter an information bottleneck when generating graph-level representations. The prevalent single token paradigm fails to fully leverage the inherent strength of self-attention in encoding token sequences, and degenerates into a weighted sum of node signals. To address this issue, we design a novel serialized token paradigm to ",
            "url": "https://arxiv.org/abs/2602.09065",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1f71bc5f",
            "type": "article",
            "title": "Spectral Disentanglement and Enhancement: A Dual-domain Contrastive Framework for Representation Learning",
            "summary": "arXiv:2602.09066v1 Announce Type: new Abstract: Large-scale multimodal contrastive learning has recently achieved impressive success in learning rich and transferable representations, yet it remains fundamentally limited by the uniform treatment of feature dimensions and the neglect of the intrinsic spectral structure of the learned features. Empirical evidence indicates that high-dimensional embeddings tend to collapse into narrow cones, concentrating task-relevant semantics in a small subspace",
            "url": "https://arxiv.org/abs/2602.09066",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-35934f1e",
            "type": "article",
            "title": "Learning to Remember, Learn, and Forget in Attention-Based Models",
            "summary": "arXiv:2602.09075v1 Announce Type: new Abstract: In-Context Learning (ICL) in transformers acts as an online associative memory and is believed to underpin their high performance on complex sequence processing tasks. However, in gated linear attention models, this memory has a fixed capacity and is prone to interference, especially for long sequences. We propose Palimpsa, a self-attention model that views ICL as a continual learning problem that must address a stability-plasticity dilemma. Palimp",
            "url": "https://arxiv.org/abs/2602.09075",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-aea92709",
            "type": "article",
            "title": "Patient foundation model for risk stratification in low-risk overweight patients",
            "summary": "arXiv:2602.09079v1 Announce Type: new Abstract: Accurate risk stratification in patients with overweight or obesity is critical for guiding preventive care and allocating high-cost therapies such as GLP-1 receptor agonists. We present PatientTPP, a neural temporal point process (TPP) model trained on over 500,000 real-world clinical trajectories to learn patient representations from sequences of diagnoses, labs, and medications. We extend existing TPP modeling approaches to include static and nu",
            "url": "https://arxiv.org/abs/2602.09079",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-c9b84994",
            "type": "article",
            "title": "Looping Back to Move Forward: Recursive Transformers for Efficient and Flexible Large Multimodal Models",
            "summary": "arXiv:2602.09080v1 Announce Type: new Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in vision-language tasks, yet their vast parameter counts are often underutilized during both training and inference. In this work, we embrace the idea of looping back to move forward: reusing model parameters through recursive refinement to extract stronger multimodal representations without increasing model size. We propose RecursiveVLM, a recursive Transformer architecture tailored ",
            "url": "https://arxiv.org/abs/2602.09080",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f29de023",
            "type": "article",
            "title": "DMamba: Decomposition-enhanced Mamba for Time Series Forecasting",
            "summary": "arXiv:2602.09081v1 Announce Type: new Abstract: State Space Models (SSMs), particularly Mamba, have shown potential in long-term time series forecasting. However, existing Mamba-based architectures often struggle with datasets characterized by non-stationary patterns. A key observation from time series theory is that the statistical nature of inter-variable relationships differs fundamentally between the trend and seasonal components of a decomposed series. Trend relationships are often driven b",
            "url": "https://arxiv.org/abs/2602.09081",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-72518136",
            "type": "article",
            "title": "From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics",
            "summary": "arXiv:2602.09101v1 Announce Type: new Abstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $\\alpha$-refinement limit, and we provide Lyapunov-based stability and convergence analyses. We also introduce an Adam-inspired nonlocal Lagrangian formulation, offering a variational viewpoint. Numerical sim",
            "url": "https://arxiv.org/abs/2602.09101",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-7cdf294e",
            "type": "article",
            "title": "Distributed Hybrid Parallelism for Large Language Models: Comparative Study and System Design Guide",
            "summary": "arXiv:2602.09109v1 Announce Type: new Abstract: With the rapid growth of large language models (LLMs), a wide range of methods have been developed to distribute computation and memory across hardware devices for efficient training and inference. While existing surveys provide descriptive overviews of these techniques, systematic analysis of their benefits and trade offs and how such insights can inform principled methodology for designing optimal distributed systems remain limited. This paper of",
            "url": "https://arxiv.org/abs/2602.09109",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-4b257351",
            "type": "article",
            "title": "Benchmarking the Energy Savings with Speculative Decoding Strategies",
            "summary": "arXiv:2602.09113v1 Announce Type: new Abstract: Speculative decoding has emerged as an effective method to reduce latency and inference cost of LLM inferences. However, there has been inadequate attention towards the energy requirements of these models. To address this gap, this paper presents a comprehensive survey of energy requirements of speculative decoding strategies, with detailed analysis on how various factors -- model size and family, speculative decoding strategies, and dataset charac",
            "url": "https://arxiv.org/abs/2602.09113",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-a1d0fad6",
            "type": "article",
            "title": "Importance inversion transfer identifies shared principles for cross-domain learning",
            "summary": "arXiv:2602.09116v1 Announce Type: new Abstract: The capacity to transfer knowledge across scientific domains relies on shared organizational principles. However, existing transfer-learning methodologies often fail to bridge radically heterogeneous systems, particularly under severe data scarcity or stochastic noise. This study formalizes Explainable Cross-Domain Transfer Learning (X-CDTL), a framework unifying network science and explainable artificial intelligence to identify structural invaria",
            "url": "https://arxiv.org/abs/2602.09116",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-75fa300e",
            "type": "article",
            "title": "SpinCastML an Open Decision-Making Application for Inverse Design of Electrospinning Manufacturing: A Machine Learning, Optimal Sampling and Inverse Monte Carlo Approach",
            "summary": "arXiv:2602.09120v1 Announce Type: new Abstract: Electrospinning is a powerful technique for producing micro to nanoscale fibers with application specific architectures. Small variations in solution or operating conditions can shift the jet regime, generating non Gaussian fiber diameter distributions. Despite substantial progress, no existing framework enables inverse design toward desired fiber outcomes while integrating polymer solvent chemical constraints or predicting full distributions. Spin",
            "url": "https://arxiv.org/abs/2602.09120",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-9fbda9c9",
            "type": "article",
            "title": "Epistemic Throughput: Fundamental Limits of Attention-Constrained Inference",
            "summary": "arXiv:2602.09127v1 Announce Type: new Abstract: Recent generative and tool-using AI systems can surface a large volume of candidates at low marginal cost, yet only a small fraction can be checked carefully. This creates a decoder-side bottleneck: downstream decision-makers must form reliable posteriors from many public records under scarce attention. We formalize this regime via Attention-Constrained Inference (ACI), in which a cheap screening stage processes $K$ records and an expensive verific",
            "url": "https://arxiv.org/abs/2602.09127",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1b11aa05",
            "type": "article",
            "title": "Counterfactual Maps: What They Are and How to Find Them",
            "summary": "arXiv:2602.09128v1 Announce Type: new Abstract: Counterfactual explanations are a central tool in interpretable machine learning, yet computing them exactly for complex models remains challenging. For tree ensembles, predictions are piecewise constant over a large collection of axis-aligned hyperrectangles, implying that an optimal counterfactual for a point corresponds to its projection onto the nearest rectangle with an alternative label under a chosen metric. Existing methods largely overlook",
            "url": "https://arxiv.org/abs/2602.09128",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-a34306ca",
            "type": "article",
            "title": "UniComp: A Unified Evaluation of Large Language Model Compression via Pruning, Quantization and Distillation",
            "summary": "arXiv:2602.09130v1 Announce Type: new Abstract: Model compression is increasingly essential for deploying large language models (LLMs), yet existing evaluations are limited in method coverage and focus primarily on knowledge-centric benchmarks. Thus, we introduce UniComp, a unified evaluation framework for comparing pruning, quantization, and knowledge distillation. UniComp evaluates compressed models along three dimensions: performance, reliability, and efficiency, using a diverse set of capabi",
            "url": "https://arxiv.org/abs/2602.09130",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-48d99f5d",
            "type": "article",
            "title": "What do Geometric Hallucination Detection Metrics Actually Measure?",
            "summary": "arXiv:2602.09158v1 Announce Type: new Abstract: Hallucination remains a barrier to deploying generative models in high-consequence applications. This is especially true in cases where external ground truth is not readily available to validate model outputs. This situation has motivated the study of geometric signals in the internal state of an LLM that are predictive of hallucination and require limited external knowledge. Given that there are a range of factors that can lead model output to be ",
            "url": "https://arxiv.org/abs/2602.09158",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-dccff92c",
            "type": "article",
            "title": "Boltzmann Reinforcement Learning for Noise resilience in Analog Ising Machines",
            "summary": "arXiv:2602.09162v1 Announce Type: new Abstract: Analog Ising machines (AIMs) have emerged as a promising paradigm for combinatorial optimization, utilizing physical dynamics to solve Ising problems with high energy efficiency. However, the performance of traditional optimization and sampling algorithms on these platforms is often limited by inherent measurement noise. We introduce BRAIN (Boltzmann Reinforcement for Analog Ising Networks), a distribution learning framework that utilizes variation",
            "url": "https://arxiv.org/abs/2602.09162",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e246c0fb",
            "type": "article",
            "title": "Faster Rates For Federated Variational Inequalities",
            "summary": "arXiv:2602.09164v1 Announce Type: new Abstract: In this paper, we study federated optimization for solving stochastic variational inequalities (VIs), a problem that has attracted growing attention in recent years. Despite substantial progress, a significant gap remains between existing convergence rates and the state-of-the-art bounds known for federated convex optimization. In this work, we address this limitation by establishing a series of improved convergence rates. First, we show that, for ",
            "url": "https://arxiv.org/abs/2602.09164",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-8b7e9847",
            "type": "article",
            "title": "Train Less, Infer Faster: Efficient Model Finetuning and Compression via Structured Sparsity",
            "summary": "arXiv:2602.09169v1 Announce Type: new Abstract: Fully finetuning foundation language models (LMs) with billions of parameters is often impractical due to high computational costs, memory requirements, and the risk of overfitting. Although methods like low-rank adapters help address these challenges by adding small trainable modules to the frozen LM, they also increase memory usage and do not reduce inference latency. We uncover an intriguing phenomenon: sparsifying specific model rows and column",
            "url": "https://arxiv.org/abs/2602.09169",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-991e8495",
            "type": "article",
            "title": "$n$-Musketeers: Reinforcement Learning Shapes Collaboration Among Language Models",
            "summary": "arXiv:2602.09173v1 Announce Type: new Abstract: Recent progress in reinforcement learning with verifiable rewards (RLVR) shows that small, specialized language models (SLMs) can exhibit structured reasoning without relying on large monolithic LLMs. We introduce soft hidden-state collaboration, where multiple heterogeneous frozen SLM experts are integrated through their internal representations via a trainable attention interface. Experiments on Reasoning Gym and GSM8K show that this latent integ",
            "url": "https://arxiv.org/abs/2602.09173",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1150f873",
            "type": "article",
            "title": "Weighted Wasserstein Barycenter of Gaussian Processes for exotic Bayesian Optimization tasks",
            "summary": "arXiv:2602.09181v1 Announce Type: new Abstract: Exploiting the analogy between Gaussian Distributions and Gaussian Processes' posterior, we present how the weighted Wasserstein Barycenter of Gaussian Processes (W2BGP) can be used to unify, under a common framework, different exotic Bayesian Optimization (BO) tasks. Specifically, collaborative/federated BO, (synchronous) batch BO, and multi-fidelity BO are considered in this paper. Our empirical analysis proves that each one of these tasks requir",
            "url": "https://arxiv.org/abs/2602.09181",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f20a6856",
            "type": "article",
            "title": "Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection",
            "summary": "arXiv:2602.09147v1 Announce Type: new Abstract: The goal of the PAN workshop is to advance computational stylometry and text forensics via objective and reproducible evaluation. In 2026, we run the following five tasks: (1) Voight-Kampff Generative AI Detection, particularly in mixed and obfuscated authorship scenarios, (2) Text Watermarking, a new task that aims to find new and benchmark the robustness of existing text watermarking schemes, (3) Multi-author Writing Style Analysis, a continued t",
            "url": "https://arxiv.org/abs/2602.09147",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-5ab2326e",
            "type": "article",
            "title": "Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning",
            "summary": "arXiv:2602.09269v1 Announce Type: new Abstract: Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this proof-of-concept paper, we introduce inclusion analytics, a discourse-based framework for examining inclusion as a dynamic, interactional process in CPS. We conceptualize inclusion along three complemen",
            "url": "https://arxiv.org/abs/2602.09269",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-d08b34f5",
            "type": "article",
            "title": "Effective Reasoning Chains Reduce Intrinsic Dimensionality",
            "summary": "arXiv:2602.09276v1 Announce Type: new Abstract: Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challengin",
            "url": "https://arxiv.org/abs/2602.09276",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1b747745",
            "type": "article",
            "title": "Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention",
            "summary": "arXiv:2602.09312v1 Announce Type: new Abstract: Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resources. In this paper, we present a topic continuity model aimed at assessing whether a response aligns with the initial conversation topic. Our model is built upon the expansion of the corresponding natu",
            "url": "https://arxiv.org/abs/2602.09312",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-32b45ef9",
            "type": "article",
            "title": "Beyond Uniform Credit: Causal Credit Assignment for Policy Optimization",
            "summary": "arXiv:2602.09331v1 Announce Type: new Abstract: Policy gradient methods for language model reasoning, such as GRPO and DAPO, assign uniform credit to all generated tokens - the filler phrase \"Let me think\" receives the same gradient update as the critical calculation \"23 + 45 = 68.\" We propose counterfactual importance weighting: mask reasoning spans, measure the drop in answer probability, and upweight tokens accordingly during policy gradient updates. Our method requires no auxiliary models or",
            "url": "https://arxiv.org/abs/2602.09331",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-faab3e2e",
            "type": "article",
            "title": "FM SO.P: A Progressive Task Mixture Framework with Automatic Evaluation for Cross-Domain SOP Understanding",
            "summary": "arXiv:2602.09336v1 Announce Type: new Abstract: Standard Operating Procedures (SOPs) are critical for enterprise operations, yet existing language models struggle with SOP understanding and cross-domain generalization. Current methods fail because joint training cannot differentiate between reasoning capabilities that SOP requires: terminology precision, sequential ordering, and constraint reasoning. We propose FM SO.P, solving these challenges through two novelties. First, we introduce progress",
            "url": "https://arxiv.org/abs/2602.09336",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-68717585",
            "type": "article",
            "title": "Understanding Risk and Dependency in AI Chatbot Use from User Discourse",
            "summary": "arXiv:2602.09339v1 Announce Type: new Abstract: Generative AI systems are increasingly embedded in everyday life, yet empirical understanding of how psychological risk associated with AI use emerges, is experienced, and is regulated by users remains limited. We present a large-scale computational thematic analysis of posts collected between 2023 and 2025 from two Reddit communities, r/AIDangers and r/ChatbotAddiction, explicitly focused on AI-related harm and distress. Using a multi-agent, LLM-a",
            "url": "https://arxiv.org/abs/2602.09339",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-6dbefeb3",
            "type": "article",
            "title": "Digital Linguistic Bias in Spanish: Evidence from Lexical Variation in LLMs",
            "summary": "arXiv:2602.09346v1 Announce Type: new Abstract: This study examines the extent to which Large Language Models (LLMs) capture geographic lexical variation in Spanish, a language that exhibits substantial regional variation. Treating LLMs as virtual informants, we probe their dialectal knowledge using two survey-style question formats: Yes-No questions and multiple-choice questions. To this end, we exploited a large-scale, expert-curated database of Spanish lexical variation. Our evaluation covers",
            "url": "https://arxiv.org/abs/2602.09346",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-d247370e",
            "type": "article",
            "title": "Unsupervised Cross-Lingual Part-of-Speech Tagging with Monolingual Corpora Only",
            "summary": "arXiv:2602.09366v1 Announce Type: new Abstract: Due to the scarcity of part-of-speech annotated data, existing studies on low-resource languages typically adopt unsupervised approaches for POS tagging. Among these, POS tag projection with word alignment method transfers POS tags from a high-resource source language to a low-resource target language based on parallel corpora, making it particularly suitable for low-resource language settings. However, this approach relies heavily on parallel corp",
            "url": "https://arxiv.org/abs/2602.09366",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-4bae6092",
            "type": "article",
            "title": "AgentSkiller: Scaling Generalist Agent Intelligence through Semantically Integrated Cross-Domain Data Synthesis",
            "summary": "arXiv:2602.09372v1 Announce Type: new Abstract: Large Language Model agents demonstrate potential in solving real-world problems via tools, yet generalist intelligence is bottlenecked by scarce high-quality, long-horizon data. Existing methods collect privacy-constrained API logs or generate scripted interactions lacking diversity, which struggle to produce data requisite for scaling capabilities. We propose AgentSkiller, a fully automated framework synthesizing multi-turn interaction data acros",
            "url": "https://arxiv.org/abs/2602.09372",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-fd1f2822",
            "type": "article",
            "title": "AfriNLLB: Efficient Translation Models for African Languages",
            "summary": "arXiv:2602.09373v1 Announce Type: new Abstract: In this work, we present AfriNLLB, a series of lightweight models for efficient translation from and into African languages. AfriNLLB supports 15 language pairs (30 translation directions), including Swahili, Hausa, Yoruba, Amharic, Somali, Zulu, Lingala, Afrikaans, Wolof, and Egyptian Arabic, as well as other African Union official languages such as Arabic (MSA), French, Portuguese, and Spanish. Our training data covers bidirectional translation b",
            "url": "https://arxiv.org/abs/2602.09373",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-63a35fb0",
            "type": "article",
            "title": "BiasScope: Towards Automated Detection of Bias in LLM-as-a-Judge Evaluation",
            "summary": "arXiv:2602.09383v1 Announce Type: new Abstract: LLM-as-a-Judge has been widely adopted across various research and practical applications, yet the robustness and reliability of its evaluation remain a critical issue. A core challenge it faces is bias, which has primarily been studied in terms of known biases and their impact on evaluation outcomes, while automated and systematic exploration of potential unknown biases is still lacking. Nevertheless, such exploration is crucial for enhancing the ",
            "url": "https://arxiv.org/abs/2602.09383",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-8f7681c7",
            "type": "article",
            "title": "Contractual Deepfakes: Can Large Language Models Generate Contracts?",
            "summary": "arXiv:2602.09384v1 Announce Type: new Abstract: Notwithstanding their unprecedented ability to generate text, LLMs do not understand the meaning of words, have no sense of context and cannot reason. Their output constitutes an approximation of statistically dominant word patterns. And yet, the drafting of contracts is often presented as a typical legal task that could be facilitated by this technology. This paper seeks to put an end to such unreasonable ideas. Predicting words differs from using",
            "url": "https://arxiv.org/abs/2602.09384",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-18be501e",
            "type": "article",
            "title": "Effective vocabulary expanding of multilingual language models for extremely low-resource languages",
            "summary": "arXiv:2602.09388v1 Announce Type: new Abstract: Multilingual pre-trained language models(mPLMs) offer significant benefits for many low-resource languages. To further expand the range of languages these models can support, many works focus on continued pre-training of these models. However, few works address how to extend mPLMs to low-resource languages that were previously unsupported. To tackle this issue, we expand the model's vocabulary using a target language corpus. We then screen out a su",
            "url": "https://arxiv.org/abs/2602.09388",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-ff6acbb4",
            "type": "article",
            "title": "Are Language Models Sensitive to Morally Irrelevant Distractors?",
            "summary": "arXiv:2602.09416v1 Announce Type: new Abstract: With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human ",
            "url": "https://arxiv.org/abs/2602.09416",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-7af1a410",
            "type": "article",
            "title": "Breaking the Pre-Sampling Barrier: Activation-Informed Difficulty-Aware Self-Consistency",
            "summary": "arXiv:2602.09438v1 Announce Type: new Abstract: Self-Consistency (SC) is an effective decoding strategy that improves the reasoning performance of Large Language Models (LLMs) by generating multiple chain-of-thought reasoning paths and selecting the final answer via majority voting. However, it suffers from substantial inference costs because it requires a large number of samples. To mitigate this issue, Difficulty-Adaptive Self-Consistency (DSC) was proposed to reduce unnecessary token usage fo",
            "url": "https://arxiv.org/abs/2602.09438",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-17444c75",
            "type": "article",
            "title": "Evaluating Social Bias in RAG Systems: When External Context Helps and Reasoning Hurts",
            "summary": "arXiv:2602.09442v1 Announce Type: new Abstract: Social biases inherent in large language models (LLMs) raise significant fairness concerns. Retrieval-Augmented Generation (RAG) architectures, which retrieve external knowledge sources to enhance the generative capabilities of LLMs, remain susceptible to the same bias-related challenges. This work focuses on evaluating and understanding the social bias implications of RAG. Through extensive experiments across various retrieval corpora, LLMs, and b",
            "url": "https://arxiv.org/abs/2602.09442",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-4f37efc6",
            "type": "article",
            "title": "Conceptual Cultural Index: A Metric for Cultural Specificity via Relative Generality",
            "summary": "arXiv:2602.09444v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed in multicultural settings; however, systematic evaluation of cultural specificity at the sentence level remains underexplored. We propose the Conceptual Cultural Index (CCI), which estimates cultural specificity at the sentence level. CCI is defined as the difference between the generality estimate within the target culture and the average generality estimate across other cultures. This formula",
            "url": "https://arxiv.org/abs/2602.09444",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-7bf91af0",
            "type": "article",
            "title": "NOWJ @BioCreative IX ToxHabits: An Ensemble Deep Learning Approach for Detecting Substance Use and Contextual Information in Clinical Texts",
            "summary": "arXiv:2602.09469v1 Announce Type: new Abstract: Extracting drug use information from unstructured Electronic Health Records remains a major challenge in clinical Natural Language Processing. While Large Language Models demonstrate advancements, their use in clinical NLP is limited by concerns over trust, control, and efficiency. To address this, we present NOWJ submission to the ToxHabits Shared Task at BioCreative IX. This task targets the detection of toxic substance use and contextual attribu",
            "url": "https://arxiv.org/abs/2602.09469",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1e64b33f",
            "type": "article",
            "title": "Listen to the Layers: Mitigating Hallucinations with Inter-Layer Disagreement",
            "summary": "arXiv:2602.09486v1 Announce Type: new Abstract: Pretrained Large Language Models (LLMs) are prone to generating fluent yet factually incorrect text-a phenomenon known as hallucinations, undermining their reliability and utility in downstream tasks. We hypothesize that a generated text span's factuality is correlated with its representational instability across the model's internal layers. Based on this, we propose the CoCoA (Confusion and Consistency Aware) decoder, a novel, training-free decodi",
            "url": "https://arxiv.org/abs/2602.09486",
            "source": "arxiv",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-35caebc0",
            "type": "article",
            "title": "9 fun questions to try asking Google Photos",
            "summary": "A collage of outdoor images, a blue icon that say \"Ask Photos,\" and examples of Ask Photos prompts.",
            "url": "https://blog.google/products-and-platforms/products/photos/ask-button-ask-photos-tips/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9eef7a37",
            "type": "article",
            "title": "Helping kids and teens learn and grow online on Safer Internet Day",
            "summary": "User profile on smartphone connected to security, media, and settings icons.",
            "url": "https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-2026-kids-teens/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e42f6ff4",
            "type": "article",
            "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
            "summary": "A collage of four images, the first of a woman with curly hair in front of a silver laptop, the second of the same woman and a man with short black hair speaking on a stairwell, the third of a the same man with glasses, and an aerial image of NTID",
            "url": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-828c66e8",
            "type": "article",
            "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
            "summary": "A woman outdoors in the snow looks at a tablet. A half pipe is behind her.",
            "url": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-f9c339ba",
            "type": "article",
            "title": "Watch our new Gemini ad ahead of football\u2019s biggest weekend",
            "summary": "A toddler in a blue and yellow striped shirt sits on a kitchen counter eating a red apple. Text in the corner reads: 'New Home, Google Gemini SB Commercial\u2019",
            "url": "https://blog.google/company-news/inside-google/company-announcements/gemini-ad-new-home/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-1eabfc9f",
            "type": "article",
            "title": "The latest AI news we announced in January",
            "summary": "mp4 showing a carousel of images including a card reading \"Help that's made for you\"",
            "url": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-5d835c59",
            "type": "article",
            "title": "Transformers.js v4 Preview: Now Available on NPM!",
            "summary": "",
            "url": "https://huggingface.co/blog/transformersjs-v4",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-4b956a17",
            "type": "article",
            "title": "Introducing SyGra Studio",
            "summary": "",
            "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-5a59b4d6",
            "type": "article",
            "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3\u2019s Top Model",
            "summary": "",
            "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-5f5ee2c2",
            "type": "article",
            "title": "A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions",
            "summary": "In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. Then he came across a post on Reddit about&#8230;",
            "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e3e028d7",
            "type": "article",
            "title": "Why the Moltbook frenzy was like Pok\u00e9mon",
            "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-d7ce15dc",
            "type": "article",
            "title": "Making AI Work, MIT Technology Review\u2019s new AI newsletter, is here",
            "summary": "For years, our newsroom has explored AI\u2019s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&#160; But how is AI actually being used in fields like health care, climate tech, education,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-63da4d4a",
            "type": "article",
            "title": "Moltbook was peak AI theater",
            "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on January 28 by Matt Schlicht,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
            "source": "blogs",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-4c5e5bb4",
            "type": "article",
            "title": "This is the most misunderstood graph in AI",
            "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;",
            "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-1ca5a016",
            "type": "article",
            "title": "From guardrails to governance: A CEO\u2019s guide for securing agentic systems",
            "summary": "The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;",
            "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-74411f01",
            "type": "article",
            "title": "Lab: The Full-Stack Platform for Training Your Own Models",
            "summary": "",
            "url": "https://www.primeintellect.ai/blog/lab",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-88376e30",
            "type": "article",
            "title": "Ask HN: What is your AI assisted dev workflow",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46971761",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1fbaa373",
            "type": "article",
            "title": "Anti-detection browser server for AI agents, powered by Camoufox",
            "summary": "",
            "url": "https://github.com/jo-inc/camofox-browser",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-048af060",
            "type": "article",
            "title": "Show HN: GHOSTYPE \u2013 AI voice input that learns your writing style",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46971643",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e33ec200",
            "type": "article",
            "title": "Show HN: \"hard questions\" as a shared language for cross-domain reasoning",
            "summary": "",
            "url": "https://github.com/onestardao/WFGY",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-3467bf31",
            "type": "article",
            "title": "Exponential Code, Network Effects in AI, & the Return of Apprenticeships",
            "summary": "",
            "url": "https://www.implications.com/p/exponential-code-network-effects",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-25cac8c4",
            "type": "article",
            "title": "Vibrant Frog Collab \u2013 AI-Powered Writing Assistant",
            "summary": "",
            "url": "https://frogteam.ai/VibrantFrog/default.html",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-659a713b",
            "type": "article",
            "title": "Show HN: Track and analyze AI coding tool usage across your team",
            "summary": "",
            "url": "https://trackr-bay.vercel.app/welcome",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-cd3b4e61",
            "type": "article",
            "title": "Spec-Driven Development with Claude Code",
            "summary": "",
            "url": "https://www.braingrid.ai/blog/building-braingrid-with-braingrid",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-ab56a54a",
            "type": "article",
            "title": "AI-Driven Low-Fi Prototyping with Balsamiq Cloud",
            "summary": "",
            "url": "https://balsamiq.com/blog/low-fidelity-prototyping/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-9b48a269",
            "type": "article",
            "title": "It's Time to Rage Against the AI Music Machine",
            "summary": "",
            "url": "https://time.com/7338205/rage-against-ai-generated-music/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-77a4448e",
            "type": "article",
            "title": "Show HN: Askill \u2013 A package manager for AI agent skills with AI safety scoring",
            "summary": "",
            "url": "https://github.com/avibe-bot/askill",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-988e455f",
            "type": "article",
            "title": "AI is now a magic decompiler",
            "summary": "",
            "url": "https://stephenjayakar.com/posts/magic-decomp/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-2fda8e80",
            "type": "article",
            "title": "AI Can Work on VMs",
            "summary": "",
            "url": "https://www.fluid.sh/blog/how-fluid-reads-source-vms-safely",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-69422bd6",
            "type": "article",
            "title": "Why Smart Lawyers Are Building AI Tools Instead of Buying Them",
            "summary": "",
            "url": "https://natlawreview.com/article/why-smart-lawyers-are-building-ai-tools-instead-buying-them",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-a3df4332",
            "type": "article",
            "title": "Seedream 5.0-Preview Test: An image model that does web search during generation",
            "summary": "",
            "url": "https://www.atlascloud.ai/collections/seedream-5",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-536dd25a",
            "type": "article",
            "title": "Free AI Prompts Library and Community to Share Prompts and Prompt Builder",
            "summary": "",
            "url": "https://promptshub.shop/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-6f83ea10",
            "type": "article",
            "title": "Anthropic's 'anonymous' interviews cracked with an LLM",
            "summary": "",
            "url": "https://techxplore.com/news/2026-02-anthropic-anonymous-llm.html",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f9ec84ad",
            "type": "article",
            "title": "Show HN: I taught GPT-OSS-120B to see using Google Lens and OpenCV",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46971287",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-bce70d36",
            "type": "article",
            "title": "Functional Programming in an LLM World",
            "summary": "",
            "url": "https://notes.druchan.com/fp-in-llm-world",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-4499cfa1",
            "type": "article",
            "title": "Show HN: AdKit MCP: Inject Ads into Your LLMs",
            "summary": "",
            "url": "https://www.adkitmcp.com/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-2866e138",
            "type": "article",
            "title": "Show HN: AgentNotifier \u2013 phone alerts when Codex/Claude need input",
            "summary": "",
            "url": "https://github.com/almuqrin/agentnotifier",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-9a066ce9",
            "type": "article",
            "title": "Show HN: Microagentic Stacking \u2013 Manifesto for Reliable Agentic AI Architecture",
            "summary": "",
            "url": "https://github.com/ericmora/microagentic-stacking",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-31e66ce8",
            "type": "article",
            "title": "The many masks LLMs wear",
            "summary": "",
            "url": "https://www.understandingai.org/p/the-many-masks-that-llms-wear",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-eab9f32c",
            "type": "article",
            "title": "Show HN: AI agents that communicate via ultrasonic frequencies (96% cheaper)",
            "summary": "",
            "url": "https://github.com/Nil4s/swl-agent",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-6c41cb03",
            "type": "article",
            "title": "Show HN: Inject Ads into Your LLMs",
            "summary": "",
            "url": "https://github.com/Exorust/Adkit-MCP",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-2583afa8",
            "type": "article",
            "title": "Show HN: Google Search MCP for local LLMs \u2013 14 tools, no API key",
            "summary": "",
            "url": "https://github.com/VincentKaufmann/noapi-google-search-mcp",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-7c1f7c64",
            "type": "article",
            "title": "Show HN: Thoth \u2013 Obsidian AI Research Assistant",
            "summary": "",
            "url": "https://github.com/acertainKnight/project-thoth",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-b2bc6b6d",
            "type": "article",
            "title": "Show HN: Idea Forge \u2013 Multi-model product validation(validated an OpenClaw idea)",
            "summary": "",
            "url": "https://ideas.sparkngine.com/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-39c3f3e6",
            "type": "article",
            "title": "Simple email API for proton bridge",
            "summary": "",
            "url": "https://github.com/pgray/mayl",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-ff45626c",
            "type": "article",
            "title": "Harmless reward hacks generalize to shutdown evasion and dictatorship in GPT-4.1",
            "summary": "",
            "url": "https://arxiv.org/abs/2508.17511",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-fe2381bc",
            "type": "article",
            "title": "Google Nest camera video raises privacy questions",
            "summary": "",
            "url": "https://www.mynbc5.com/article/nancy-guthrie-fbi-nest-camera-video-raises-privacy-questions/70306538",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-8177f858",
            "type": "article",
            "title": "Ask HN: How to find joy in writing/learning about tech in this AI world?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46960408",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2497fd1b",
            "type": "article",
            "title": "God, Theology, and AI",
            "summary": "",
            "url": "https://rlafuente.com/posts/2026-2-1-on-god-and-machine-learning#",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2ed9ffa8",
            "type": "article",
            "title": "Show HN: We added AGENTS.md to 120 challenges so AI teaches instead of codes",
            "summary": "",
            "url": "https://www.frontendmentor.io/articles/agents-md-files-in-every-challenge",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-a8bc8060",
            "type": "article",
            "title": "Show HN: SuperLocalMemory \u2013 AI memory that stays on your machine, forever free",
            "summary": "",
            "url": "https://github.com/varun369/SuperLocalMemoryV2",
            "source": "hackernews",
            "date": "2026-02-07",
            "trendingScore": 50
        },
        {
            "id": "article-f18858e8",
            "type": "article",
            "title": "ML-Lib: Machine Learning Library Proposed for the Linux Kernel",
            "summary": "",
            "url": "https://www.phoronix.com/news/Linux-Kernel-ML-LIB-RFC",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-7221af3c",
            "type": "article",
            "title": "AI Development Company",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46909998",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-31345870",
            "type": "article",
            "title": "Why Most Machine Learning Projects Fail to Reach Production \u2013 InfoQ",
            "summary": "",
            "url": "https://www.infoq.com/articles/why-ml-projects-fail-production/",
            "source": "hackernews",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-5bfdb138",
            "type": "article",
            "title": "Show HN: Rowboat \u2013 AI coworker that turns your work into a knowledge graph (OSS)",
            "summary": "",
            "url": "https://github.com/rowboatlabs/rowboat",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 64
        },
        {
            "id": "article-8e34af62",
            "type": "article",
            "title": "Show HN: Energy Based Model solving nonograms",
            "summary": "",
            "url": "https://github.com/hirako2000/latent-energy",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2a63b432",
            "type": "article",
            "title": "A Complete Guide to Neural Network Optimizers",
            "summary": "",
            "url": "https://chizkidd.github.io//2026/01/22/neural-net-optimizers/",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-ed81c445",
            "type": "article",
            "title": "SpaceX-xAI Merger: Nobody's Talking About the von Neumann Elephant in the Room",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46933827",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-b079933d",
            "type": "article",
            "title": "Can graph neural networks for biology realistically run on edge devices?",
            "summary": "",
            "url": "https://doi.org/10.21203/rs.3.rs-8645211/v1",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-faec27b2",
            "type": "article",
            "title": "SMLL: Using 200MB of Neural Network to Save 400 Bytes",
            "summary": "",
            "url": "https://www.frankchiarulli.com/blog/smll/",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 51
        },
        {
            "id": "article-29a8aa5e",
            "type": "article",
            "title": "Hypernetworks: Neural Networks for Hierarchical Data",
            "summary": "",
            "url": "https://blog.sturdystatistics.com/posts/hnet_part_I/",
            "source": "hackernews",
            "date": "2026-02-05",
            "trendingScore": 59
        },
        {
            "id": "article-c2d508d8",
            "type": "article",
            "title": "Show HN: LayerClaw \u2013 Observability tool for PyTorch training",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46892694",
            "source": "hackernews",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-88c45b72",
            "type": "article",
            "title": "Show HN: Obsidian Visual Skills \u2013 Generate Canvas, Excalidraw, Mermaid from Text",
            "summary": "",
            "url": "https://github.com/axtonliu/axton-obsidian-visual-skills",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-c598274f",
            "type": "article",
            "title": "Claude Cowork produced a forensic report regarding Nancy Guthrie kidnapping",
            "summary": "",
            "url": "https://drive.google.com/file/d/1PNSNpB-QG1T3RhmduX8FnawcjYXTtcXN/view?usp=sharing",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-e344c5c7",
            "type": "article",
            "title": "Sabotage Risk Report: Claude Opus 4.6 [pdf]",
            "summary": "",
            "url": "https://www-cdn.anthropic.com/f21d93f21602ead5cdbecb8c8e1c765759d9e232.pdf",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-a21d4969",
            "type": "article",
            "title": "Ctoc: Cloc, but for Claude Token Counts",
            "summary": "",
            "url": "https://grohan.co/2026/02/10/ctoc/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-246ae78d",
            "type": "article",
            "title": "What Is Claude? Anthropic Doesn\u2019t Know, Either",
            "summary": "",
            "url": "https://www.newyorker.com/magazine/2026/02/16/what-is-claude-anthropic-doesnt-know-either",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f5a20d74",
            "type": "article",
            "title": "Ask HN: What is your monthly AI spending?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46968526",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-25eec862",
            "type": "article",
            "title": "How I used Claude Code in a real data journalism project",
            "summary": "",
            "url": "https://kschaul.com/post/2026/02/09/2026-02-09-ai-data-journalism/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-fffea7c8",
            "type": "article",
            "title": "Peon-ping \u2013 Claude Code notifications that uses Warcraft III Peon voice lines",
            "summary": "",
            "url": "https://peon-ping.vercel.app/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-adbec7c0",
            "type": "article",
            "title": "Exploring AI Driven Coding: Using Xcode 26.3 MCP Tools in Cursor, Claude, Codex",
            "summary": "",
            "url": "https://rudrank.com/exploring-xcode-using-mcp-tools-cursor-external-clients",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-bc59beb1",
            "type": "article",
            "title": "Hands-Free Claude Code with the Agent SDK",
            "summary": "",
            "url": "https://yberreby.com/posts/hands-free-claude-code/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-71ac63cf",
            "type": "article",
            "title": "Kokoro TTS Hook for Claude Code",
            "summary": "",
            "url": "https://git.sr.ht/~cg/claude-code-tts",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-1a273637",
            "type": "article",
            "title": "Google bans Gemini/Antigravity accounts used outside of Antigravity/Gemini-CLI",
            "summary": "",
            "url": "https://old.reddit.com/r/google_antigravity/comments/1qykskz/account_banned_for_using_open_claw/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f28970ff",
            "type": "article",
            "title": "Ask HN: Pro option missing from Gemini model selector?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46965941",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-95a603fe",
            "type": "article",
            "title": "Show HN: Cosmic CLI \u2013 Build, deploy, and manage apps from your terminal with AI",
            "summary": "",
            "url": "https://github.com/cosmicjs/cli",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d23302f2",
            "type": "article",
            "title": "Show HN: I wrote a prompt to stop Gemini from hallucinating",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46959803",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-6d7b2715",
            "type": "article",
            "title": "Show HN: Vibe-coded AI video clipper that runs in the browser",
            "summary": "",
            "url": "https://github.com/imgly/videoclipper",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-a650b5ce",
            "type": "article",
            "title": "Show HN: Snapfridge\u2013vision-based grocery assistant built with Lovable and Gemini",
            "summary": "",
            "url": "https://snapfridge.xyz/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-915eb595",
            "type": "article",
            "title": "Show HN: Agx \u2013 A Kanban board that runs your AI coding agents",
            "summary": "",
            "url": "https://github.com/ramarlina/agx",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2a916ff1",
            "type": "article",
            "title": "Show HN: A CLI tool to automate Git workflows using AI agents",
            "summary": "",
            "url": "https://github.com/leochiu-a/git-pr-ai",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9c6121b6",
            "type": "article",
            "title": "CLIProxyAPIPlus \u2013 use antigravity, Gemini CLI, & more with Claude Code / etc.",
            "summary": "",
            "url": "https://github.com/router-for-me/CLIProxyAPIPlus",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-c9c49722",
            "type": "article",
            "title": "AI Agents That Execute Business Workflows (Claude Code for ERP)",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46955034",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f39910dc",
            "type": "article",
            "title": "Letting Gemini Drive My Rover",
            "summary": "",
            "url": "http://martin.drashkov.com/2026/02/letting-gemini-drive-my-rover.html",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "topic-large-language-models",
            "type": "topic",
            "title": "Large Language Models",
            "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
            "connectionCount": 42
        },
        {
            "id": "topic-ai-reasoning",
            "type": "topic",
            "title": "AI Reasoning",
            "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
            "connectionCount": 18
        },
        {
            "id": "topic-nlp",
            "type": "topic",
            "title": "NLP",
            "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
            "connectionCount": 30
        },
        {
            "id": "topic-ai-agents",
            "type": "topic",
            "title": "AI Agents",
            "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
            "connectionCount": 27
        },
        {
            "id": "topic-diffusion-models",
            "type": "topic",
            "title": "Diffusion Models",
            "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
            "connectionCount": 2
        },
        {
            "id": "topic-model-efficiency",
            "type": "topic",
            "title": "Model Efficiency",
            "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
            "connectionCount": 5
        },
        {
            "id": "topic-multimodal-ai",
            "type": "topic",
            "title": "Multimodal AI",
            "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
            "connectionCount": 6
        },
        {
            "id": "topic-fine-tuning",
            "type": "topic",
            "title": "Fine-tuning",
            "summary": "Adapting pre-trained models to specific tasks or domains.",
            "connectionCount": 4
        },
        {
            "id": "topic-computer-vision",
            "type": "topic",
            "title": "Computer Vision",
            "summary": "AI systems for understanding and processing visual information from images and video.",
            "connectionCount": 10
        },
        {
            "id": "topic-ai-safety",
            "type": "topic",
            "title": "AI Safety",
            "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
            "connectionCount": 5
        },
        {
            "id": "topic-reinforcement-learning",
            "type": "topic",
            "title": "Reinforcement Learning",
            "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
            "connectionCount": 26
        },
        {
            "id": "topic-prompt-engineering",
            "type": "topic",
            "title": "Prompt Engineering",
            "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
            "connectionCount": 7
        },
        {
            "id": "topic-rag",
            "type": "topic",
            "title": "RAG",
            "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
            "connectionCount": 6
        },
        {
            "id": "org-google",
            "type": "organization",
            "title": "Google",
            "summary": "Google - AI research and development.",
            "connectionCount": 8
        },
        {
            "id": "org-apple",
            "type": "organization",
            "title": "Apple",
            "summary": "Apple - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-openai",
            "type": "organization",
            "title": "OpenAI",
            "summary": "OpenAI - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-anthropic",
            "type": "organization",
            "title": "Anthropic",
            "summary": "Anthropic - AI research and development.",
            "connectionCount": 3
        },
        {
            "id": "org-xai",
            "type": "organization",
            "title": "xAI",
            "summary": "xAI - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "model-gemini",
            "type": "model",
            "title": "Gemini",
            "summary": "Gemini AI model.",
            "connectionCount": 7
        },
        {
            "id": "model-chatgpt",
            "type": "model",
            "title": "ChatGPT",
            "summary": "ChatGPT AI model.",
            "connectionCount": 1
        },
        {
            "id": "model-claude",
            "type": "model",
            "title": "Claude",
            "summary": "Claude AI model.",
            "connectionCount": 13
        },
        {
            "id": "model-gpt-4",
            "type": "model",
            "title": "GPT-4",
            "summary": "GPT-4 AI model.",
            "connectionCount": 1
        }
    ],
    "edges": [
        {
            "source": "article-4e2348af",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e2348af",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e2348af",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-cbe7a7f3",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cbe7a7f3",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fc694bfa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-32cefdbb",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-32cefdbb",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-5c5168b9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5c5168b9",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ebe3eb0",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f3a26c90",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f23f74fa",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f23f74fa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d10f3bd2",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d10f3bd2",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a25d130b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a25d130b",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-a25d130b",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a25d130b",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1f71bc5f",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-35934f1e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-35934f1e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-aea92709",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c9b84994",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c9b84994",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-c9b84994",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-f29de023",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72518136",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-7cdf294e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b257351",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b257351",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a1d0fad6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-75fa300e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-75fa300e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-9fbda9c9",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1b11aa05",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a34306ca",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a34306ca",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-a34306ca",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-48d99f5d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-48d99f5d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-dccff92c",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-dccff92c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-dccff92c",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8b7e9847",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-8b7e9847",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-991e8495",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-991e8495",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-991e8495",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f20a6856",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f20a6856",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-f20a6856",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d08b34f5",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d08b34f5",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d08b34f5",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-d08b34f5",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1b747745",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-32b45ef9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-32b45ef9",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-32b45ef9",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-32b45ef9",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-faab3e2e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-faab3e2e",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-faab3e2e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-68717585",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-68717585",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-68717585",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-68717585",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6dbefeb3",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d247370e",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-d247370e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4bae6092",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4bae6092",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-4bae6092",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4bae6092",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-63a35fb0",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-63a35fb0",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8f7681c7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-8f7681c7",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-18be501e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff6acbb4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff6acbb4",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff6acbb4",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff6acbb4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7af1a410",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7af1a410",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7af1a410",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-17444c75",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-17444c75",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-17444c75",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-17444c75",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4f37efc6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4f37efc6",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-4f37efc6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-7bf91af0",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7bf91af0",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-7bf91af0",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1e64b33f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1e64b33f",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-828c66e8",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1eabfc9f",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d835c59",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a59b4d6",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a59b4d6",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-5f5ee2c2",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e3e028d7",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d7ce15dc",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-63da4d4a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1ca5a016",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-1ca5a016",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-1fbaa373",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-e33ec200",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cd3b4e61",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9b48a269",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-77a4448e",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-77a4448e",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-a3df4332",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a3df4332",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-536dd25a",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-6f83ea10",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6f83ea10",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9ec84ad",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bce70d36",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-bce70d36",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4499cfa1",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2866e138",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-2866e138",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9a066ce9",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-31e66ce8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-eab9f32c",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-6c41cb03",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2583afa8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2583afa8",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ff45626c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff45626c",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff45626c",
            "target": "model-gpt-4",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fe2381bc",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe2381bc",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8177f858",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ed9ffa8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a8bc8060",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8e34af62",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ed81c445",
            "target": "org-xai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-88c45b72",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c598274f",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e344c5c7",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-a21d4969",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-246ae78d",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-246ae78d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-25eec862",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fffea7c8",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-adbec7c0",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bc59beb1",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-bc59beb1",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-71ac63cf",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1a273637",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1a273637",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f28970ff",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-d23302f2",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-d23302f2",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-6d7b2715",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a650b5ce",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a650b5ce",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-915eb595",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-2a916ff1",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9c6121b6",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9c6121b6",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c9c49722",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-c9c49722",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f39910dc",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-reasoning",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-agents",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-rag",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-multimodal-ai",
            "target": "topic-computer-vision",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-agents",
            "target": "topic-prompt-engineering",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-model-efficiency",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-safety",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        }
    ]
};

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIChronicleData;
}
