// ================================================
// THE AI CHRONICLE - Knowledge Graph Data
// Auto-generated and updated daily via GitHub Actions
// Last updated: 2026-02-12
// ================================================

const AIChronicleData = {
    "metadata": {
        "lastUpdated": "2026-02-12T07:00:25.090903Z",
        "totalArticles": 138,
        "totalNodes": 162,
        "totalEdges": 240,
        "dateRange": {
            "start": "2026-02-05",
            "end": "2026-02-12"
        }
    },
    "nodes": [
        {
            "id": "article-524a6c67",
            "type": "article",
            "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
            "summary": "arXiv:2602.10324v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to direc",
            "url": "https://arxiv.org/abs/2602.10324",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-f45d64da",
            "type": "article",
            "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
            "summary": "arXiv:2602.10367v1 Announce Type: new Abstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, current",
            "url": "https://arxiv.org/abs/2602.10367",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a83b0b22",
            "type": "article",
            "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
            "summary": "arXiv:2602.10458v1 Announce Type: new Abstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we presen",
            "url": "https://arxiv.org/abs/2602.10458",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-2f80b3a4",
            "type": "article",
            "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators",
            "summary": "arXiv:2602.10467v1 Announce Type: new Abstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.g",
            "url": "https://arxiv.org/abs/2602.10467",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-78f5f85d",
            "type": "article",
            "title": "Abstraction Generation for Generalized Planning with Pretrained Large Language Models",
            "summary": "arXiv:2602.10485v1 Announce Type: new Abstract: Qualitative Numerical Planning (QNP) serves as an important abstraction model for generalized planning (GP), which aims to compute general plans that solve multiple instances at once. Recent works show that large language models (LLMs) can function as generalized planners. This work investigates whether LLMs can serve as QNP abstraction generators for GP problems and how to fix abstractions via automated debugging. We propose a prompt protocol: inp",
            "url": "https://arxiv.org/abs/2602.10485",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-c0ca6ced",
            "type": "article",
            "title": "Flow of Spans: Generalizing Language Models to Dynamic Span-Vocabulary via GFlowNets",
            "summary": "arXiv:2602.10583v1 Announce Type: new Abstract: Standard autoregressive language models generate text token-by-token from a fixed vocabulary, inducing a tree-structured state space when viewing token sampling as an action, which limits flexibility and expressiveness. Recent work introduces dynamic vocabulary by sampling retrieved text spans but overlooks that the same sentence can be composed of spans of varying lengths, lacking explicit modeling of the directed acyclic graph (DAG) state space. ",
            "url": "https://arxiv.org/abs/2602.10583",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a3c94a90",
            "type": "article",
            "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
            "summary": "arXiv:2602.10598v1 Announce Type: new Abstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with given",
            "url": "https://arxiv.org/abs/2602.10598",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b00e58d3",
            "type": "article",
            "title": "To Think or Not To Think, That is The Question for Large Reasoning Models in Theory of Mind Tasks",
            "summary": "arXiv:2602.10625v1 Announce Type: new Abstract: Theory of Mind (ToM) assesses whether models can infer hidden mental states such as beliefs, desires, and intentions, which is essential for natural social interaction. Although recent progress in Large Reasoning Models (LRMs) has boosted step-by-step inference in mathematics and coding, it is still underexplored whether this benefit transfers to socio-cognitive skills. We present a systematic study of nine advanced Large Language Models (LLMs), co",
            "url": "https://arxiv.org/abs/2602.10625",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-fb431736",
            "type": "article",
            "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization",
            "summary": "arXiv:2602.10635v1 Announce Type: new Abstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different h",
            "url": "https://arxiv.org/abs/2602.10635",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-7a4927be",
            "type": "article",
            "title": "Spend Search Where It Pays: Value-Guided Structured Sampling and Optimization for Generative Recommendation",
            "summary": "arXiv:2602.10699v1 Announce Type: new Abstract: Generative recommendation via autoregressive models has unified retrieval and ranking into a single conditional generation framework. However, fine-tuning these models with Reinforcement Learning (RL) often suffers from a fundamental probability-reward mismatch. Conventional likelihood-dominated decoding (e.g., beam search) exhibits a myopic bias toward locally probable prefixes, which causes two critical failures: (1) insufficient exploration, whe",
            "url": "https://arxiv.org/abs/2602.10699",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-919552de",
            "type": "article",
            "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act",
            "summary": "arXiv:2602.10802v1 Announce Type: new Abstract: Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure r",
            "url": "https://arxiv.org/abs/2602.10802",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b5fb10b1",
            "type": "article",
            "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
            "summary": "arXiv:2602.10814v1 Announce Type: new Abstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spannin",
            "url": "https://arxiv.org/abs/2602.10814",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-1114ab44",
            "type": "article",
            "title": "SynergyKGC: Reconciling Topological Heterogeneity in Knowledge Graph Completion via Topology-Aware Synergy",
            "summary": "arXiv:2602.10845v1 Announce Type: new Abstract: Knowledge Graph Completion (KGC) fundamentally hinges on the coherent fusion of pre-trained entity semantics with heterogeneous topological structures to facilitate robust relational reasoning. However, existing paradigms encounter a critical \"structural resolution mismatch,\" failing to reconcile divergent representational demands across varying graph densities, which precipitates structural noise interference in dense clusters and catastrophic rep",
            "url": "https://arxiv.org/abs/2602.10845",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-d746e751",
            "type": "article",
            "title": "Reinforcing Chain-of-Thought Reasoning with Self-Evolving Rubrics",
            "summary": "arXiv:2602.10885v1 Announce Type: new Abstract: Despite chain-of-thought (CoT) playing crucial roles in LLM reasoning, directly rewarding it is difficult: training a reward model demands heavy human labeling efforts, and static RMs struggle with evolving CoT distributions and reward hacking. These challenges motivate us to seek an autonomous CoT rewarding approach that requires no human annotation efforts and can evolve gradually. Inspired by recent self-evolving training methods, we propose \\te",
            "url": "https://arxiv.org/abs/2602.10885",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-10b49fa5",
            "type": "article",
            "title": "Can LLMs Cook Jamaican Couscous? A Study of Cultural Novelty in Recipe Generation",
            "summary": "arXiv:2602.10964v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly used to generate and shape cultural content, ranging from narrative writing to artistic production. While these models demonstrate impressive fluency and generative capacity, prior work has shown that they also exhibit systematic cultural biases, raising concerns about stereotyping, homogenization, and the erasure of culturally specific forms of expression. Understanding whether LLMs can meaningfully al",
            "url": "https://arxiv.org/abs/2602.10964",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-ab551c0c",
            "type": "article",
            "title": "CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion",
            "summary": "arXiv:2602.10999v1 Announce Type: new Abstract: Agentic coding requires agents to effectively interact with runtime environments, e.g., command line interfaces (CLI), so as to complete tasks like resolving dependency issues, fixing system problems, etc. But it remains underexplored how such environment-intensive tasks can be obtained at scale to enhance agents' capabilities. To address this, based on an analogy between the Dockerfile and the agentic task, we propose to employ agents to simulate ",
            "url": "https://arxiv.org/abs/2602.10999",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-4c70a8c2",
            "type": "article",
            "title": "GameDevBench: Evaluating Agentic Capabilities Through Game Development",
            "summary": "arXiv:2602.11103v1 Announce Type: new Abstract: Despite rapid progress on coding agents, progress on their multimodal counterparts has lagged behind. A key challenge is the scarcity of evaluation testbeds that combine the complexity of software development with the need for deep multimodal understanding. Game development provides such a testbed as agents must navigate large, dense codebases while manipulating intrinsically multimodal assets such as shaders, sprites, and animations within a visua",
            "url": "https://arxiv.org/abs/2602.11103",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-bf99193d",
            "type": "article",
            "title": "FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight",
            "summary": "arXiv:2602.11136v1 Announce Type: new Abstract: As LLM-based agents increasingly operate in high-stakes domains with real-world consequences, ensuring their behavioral safety becomes paramount. The dominant oversight paradigm, LLM-as-a-Judge, faces a fundamental dilemma: how can probabilistic systems reliably supervise other probabilistic systems without inheriting their failure modes? We argue that formal verification offers a principled escape from this dilemma, yet its adoption has been hinde",
            "url": "https://arxiv.org/abs/2602.11136",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-54f03866",
            "type": "article",
            "title": "Large Language Models Predict Functional Outcomes after Acute Ischemic Stroke",
            "summary": "arXiv:2602.10119v1 Announce Type: cross Abstract: Accurate prediction of functional outcomes after acute ischemic stroke can inform clinical decision-making and resource allocation. Prior work on modified Rankin Scale (mRS) prediction has relied primarily on structured variables (e.g., age, NIHSS) and conventional machine learning. The ability of large language models (LLMs) to infer future mRS scores directly from routine admission notes remains largely unexplored. We evaluated encoder (BERT, N",
            "url": "https://arxiv.org/abs/2602.10119",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-0acb33e5",
            "type": "article",
            "title": "A Practical Guide to Agentic AI Transition in Organizations",
            "summary": "arXiv:2602.10122v1 Announce Type: cross Abstract: Agentic AI represents a significant shift in how intelligence is applied within organizations, moving beyond AI-assisted tools toward autonomous systems capable of reasoning, decision-making, and coordinated action across workflows. As these systems mature, they have the potential to automate a substantial share of manual organizational processes, fundamentally reshaping how work is designed, executed, and governed. Although many organizations ha",
            "url": "https://arxiv.org/abs/2602.10122",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-cb2040a7",
            "type": "article",
            "title": "Towards Autonomous Mathematics Research",
            "summary": "arXiv:2602.10177v1 Announce Type: new Abstract: Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in",
            "url": "https://arxiv.org/abs/2602.10177",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-de7af22f",
            "type": "article",
            "title": "Signature-Kernel Based Evaluation Metrics for Robust Probabilistic and Tail-Event Forecasting",
            "summary": "arXiv:2602.10182v1 Announce Type: new Abstract: Probabilistic forecasting is increasingly critical across high-stakes domains, from finance and epidemiology to climate science. However, current evaluation frameworks lack a consensus metric and suffer from two critical flaws: they often assume independence across time steps or variables, and they demonstrably lack sensitivity to tail events, the very occurrences that are most pivotal in real-world decision-making. To address these limitations, we",
            "url": "https://arxiv.org/abs/2602.10182",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-220cbbf0",
            "type": "article",
            "title": "Versor: A Geometric Sequence Architecture",
            "summary": "arXiv:2602.10195v1 Announce Type: new Abstract: A novel sequence architecture design is introduced, Versor, which uses Conformal Geometric Algebra (CGA) in place of the traditional fundamental non-linear operations to achieve structural generalization and significant performance improvements on a variety of tasks, while offering improved interpretability and efficiency. By embedding states in the $Cl_{4,1}$ manifold and evolving them via geometric transformations (rotors), Versor natively repres",
            "url": "https://arxiv.org/abs/2602.10195",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-634a4f1b",
            "type": "article",
            "title": "Adaptive Optimization via Momentum on Variance-Normalized Gradients",
            "summary": "arXiv:2602.10204v1 Announce Type: new Abstract: We introduce MVN-Grad (Momentum on Variance-Normalized Gradients), an Adam-style optimizer that improves stability and performance by combining two complementary ideas: variance-based normalization and momentum applied after normalization. MVN-Grad scales each coordinate by an exponential moving average of gradient uncertainty and applies momentum to the resulting normalized gradients, eliminating the cross-time coupling between stale momentum and ",
            "url": "https://arxiv.org/abs/2602.10204",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-fe280630",
            "type": "article",
            "title": "Neural Network Quantum Field Theory from Transformer Architectures",
            "summary": "arXiv:2602.10209v1 Announce Type: new Abstract: We propose a neural-network construction of Euclidean scalar quantum field theories from transformer attention heads, defining $n$-point correlators by averaging over random network parameters in the NN-QFT framework. For a single attention head, shared random softmax weights couple different width coordinates and induce non-Gaussian field statistics that persist in the infinite-width limit $d_k\\to\\infty$. We compute the two-point function in an at",
            "url": "https://arxiv.org/abs/2602.10209",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-8965509b",
            "type": "article",
            "title": "How Much Reasoning Do Retrieval-Augmented Models Add beyond LLMs? A Benchmarking Framework for Multi-Hop Inference over Hybrid Knowledge",
            "summary": "arXiv:2602.10210v1 Announce Type: new Abstract: Large language models (LLMs) continue to struggle with knowledge-intensive questions that require up-to-date information and multi-hop reasoning. Augmenting LLMs with hybrid external knowledge, such as unstructured text and structured knowledge graphs, offers a promising alternative to costly continual pretraining. As such, reliable evaluation of their retrieval and reasoning capabilities becomes critical. However, many existing benchmarks increasi",
            "url": "https://arxiv.org/abs/2602.10210",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b6c9f103",
            "type": "article",
            "title": "Rank-Accuracy Trade-off for LoRA: A Gradient-Flow Analysis",
            "summary": "arXiv:2602.10212v1 Announce Type: new Abstract: Previous empirical studies have shown that LoRA achieves accuracy comparable to full-parameter methods on downstream fine-tuning tasks, even for rank-1 updates. By contrast, the theoretical underpinnings of the dependence of LoRA's accuracy on update rank remain relatively unexplored. In this work, we compare the accuracy of rank-r LoRA updates against full-parameter updates for fine-tuning tasks from a dynamical systems perspective. We perform gra",
            "url": "https://arxiv.org/abs/2602.10212",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-cf8bcd7b",
            "type": "article",
            "title": "ELROND: Exploring and decomposing intrinsic capabilities of diffusion models",
            "summary": "arXiv:2602.10216v1 Announce Type: new Abstract: A single text prompt passed to a diffusion model often yields a wide range of visual outputs determined solely by stochastic process, leaving users with no direct control over which specific semantic variations appear in the image. While existing unsupervised methods attempt to analyze these variations via output features, they omit the underlying generative process. In this work, we propose a framework to disentangle these semantic directions dire",
            "url": "https://arxiv.org/abs/2602.10216",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-6ac389f9",
            "type": "article",
            "title": "Temper-Then-Tilt: Principled Unlearning for Generative Models through Tempering and Classifier Guidance",
            "summary": "arXiv:2602.10217v1 Announce Type: new Abstract: We study machine unlearning in large generative models by framing the task as density ratio estimation to a target distribution rather than supervised fine-tuning. While classifier guidance is a standard approach for approximating this ratio and can succeed in general, we show it can fail to faithfully unlearn with finite samples when the forget set represents a sharp, concentrated data distribution. To address this, we introduce Temper-Then-Tilt U",
            "url": "https://arxiv.org/abs/2602.10217",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-39926193",
            "type": "article",
            "title": "Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models",
            "summary": "arXiv:2602.10224v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for enhancing the reasoning capabilities of Large Language Models (LLMs). Despite its efficacy, RLVR faces a meta-learning bottleneck: it lacks mechanisms for error attribution and experience internalization intrinsic to the human learning cycle beyond practice and verification, thereby limiting fine-grained credit assignment and reusable knowledge formation.",
            "url": "https://arxiv.org/abs/2602.10224",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-6e0fdc85",
            "type": "article",
            "title": "Self-Evolving Recommendation System: End-To-End Autonomous Model Optimization With LLM Agents",
            "summary": "arXiv:2602.10226v1 Announce Type: new Abstract: Optimizing large-scale machine learning systems, such as recommendation models for global video platforms, requires navigating a massive hyperparameter search space and, more critically, designing sophisticated optimizers, architectures, and reward functions to capture nuanced user behaviors. Achieving substantial improvements in these areas is a non-trivial task, traditionally relying on extensive manual iterations to test new hypotheses. We propo",
            "url": "https://arxiv.org/abs/2602.10226",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-2adb9094",
            "type": "article",
            "title": "PRISM: Differentially Private Synthetic Data with Structure-Aware Budget Allocation for Prediction",
            "summary": "arXiv:2602.10228v1 Announce Type: new Abstract: Differential privacy (DP) provides a mathematical guarantee limiting what an adversary can learn about any individual from released data. However, achieving this protection typically requires adding noise, and noise can accumulate when many statistics are measured. Existing DP synthetic data methods treat all features symmetrically, spreading noise uniformly even when the data will serve a specific prediction task. We develop a prediction-centric a",
            "url": "https://arxiv.org/abs/2602.10228",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a993472f",
            "type": "article",
            "title": "Frame-Level Internal Tool Use for Temporal Grounding in Audio LMs",
            "summary": "arXiv:2602.10230v1 Announce Type: new Abstract: Large audio language models are increasingly used for complex audio understanding tasks, but they struggle with temporal tasks that require precise temporal grounding, such as word alignment and speaker diarization. The standard approach, where we generate timestamps as sequences of text tokens, is computationally expensive and prone to hallucination, especially when processing audio lengths outside the model's training distribution. In this work, ",
            "url": "https://arxiv.org/abs/2602.10230",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-6ffcb061",
            "type": "article",
            "title": "Blockwise Advantage Estimation for Multi-Objective RL with Verifiable Rewards",
            "summary": "arXiv:2602.10231v1 Announce Type: new Abstract: Group Relative Policy Optimization (GRPO) assigns a single scalar advantage to all tokens in a completion. For structured generations with explicit segments and objectives, this couples unrelated reward signals across segments, leading to objective interference and misattributed credit. We propose Blockwise Advantage Estimation, a family of GRPO-compatible methods that assigns each objective its own advantage and applies it only to the tokens in th",
            "url": "https://arxiv.org/abs/2602.10231",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-ab4ab830",
            "type": "article",
            "title": "Risk-Equalized Differentially Private Synthetic Data: Protecting Outliers by Controlling Record-Level Influence",
            "summary": "arXiv:2602.10232v1 Announce Type: new Abstract: When synthetic data is released, some individuals are harder to protect than others. A patient with a rare disease combination or a transaction with unusual characteristics stands out from the crowd. Differential privacy provides worst-case guarantees, but empirical attacks -- particularly membership inference -- succeed far more often against such outliers, especially under moderate privacy budgets and with auxiliary information. This paper introd",
            "url": "https://arxiv.org/abs/2602.10232",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-76a0daeb",
            "type": "article",
            "title": "Modeling Programming Skills with Source Code Embeddings for Context-aware Exercise Recommendation",
            "summary": "arXiv:2602.10249v1 Announce Type: new Abstract: In this paper, we propose a context-aware recommender system that models students' programming skills using embeddings of the source code they submit throughout a course. These embeddings predict students' skills across multiple programming topics, producing profiles that are matched to the skills required by unseen homework problems. To generate recommendations, we compute the cosine similarity between student profiles and problem skill vectors, r",
            "url": "https://arxiv.org/abs/2602.10249",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-da6df449",
            "type": "article",
            "title": "Kernel-Based Learning of Chest X-ray Images for Predicting ICU Escalation among COVID-19 Patients",
            "summary": "arXiv:2602.10261v1 Announce Type: new Abstract: Kernel methods have been extensively utilized in machine learning for classification and prediction tasks due to their ability to capture complex non-linear data patterns. However, single kernel approaches are inherently limited, as they rely on a single type of kernel function (e.g., Gaussian kernel), which may be insufficient to fully represent the heterogeneity or multifaceted nature of real-world data. Multiple kernel learning (MKL) addresses t",
            "url": "https://arxiv.org/abs/2602.10261",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-538ce1af",
            "type": "article",
            "title": "From Classical to Topological Neural Networks Under Uncertainty",
            "summary": "arXiv:2602.10266v1 Announce Type: new Abstract: This chapter explores neural networks, topological data analysis, and topological deep learning techniques, alongside statistical Bayesian methods, for processing images, time series, and graphs to maximize the potential of artificial intelligence in the military domain. Throughout the chapter, we highlight practical applications spanning image, video, audio, and time-series recognition, fraud detection, and link prediction for graphical data, illu",
            "url": "https://arxiv.org/abs/2602.10266",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-19563cae",
            "type": "article",
            "title": "Linear-LLM-SCM: Benchmarking LLMs for Coefficient Elicitation in Linear-Gaussian Causal Models",
            "summary": "arXiv:2602.10282v1 Announce Type: new Abstract: Large language models (LLMs) have shown potential in identifying qualitative causal relations, but their ability to perform quantitative causal reasoning -- estimating effect sizes that parametrize functional relationships -- remains underexplored in continuous domains. We introduce Linear-LLM-SCM, a plug-and-play benchmarking framework for evaluating LLMs on linear Gaussian structural causal model (SCM) parametrization when the DAG is given. The f",
            "url": "https://arxiv.org/abs/2602.10282",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b82acbc1",
            "type": "article",
            "title": "Reviewing the Reviewer: Elevating Peer Review Quality through LLM-Guided Feedback",
            "summary": "arXiv:2602.10118v1 Announce Type: new Abstract: Peer review is central to scientific quality, yet reliance on simple heuristics -- lazy thinking -- has lowered standards. Prior work treats lazy thinking detection as a single-label task, but review segments may exhibit multiple issues, including broader clarity problems, or specificity issues. Turning detection into actionable improvements requires guideline-aware feedback, which is currently missing. We introduce an LLM-driven framework that dec",
            "url": "https://arxiv.org/abs/2602.10118",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-1e3e9df5",
            "type": "article",
            "title": "Latent Thoughts Tuning: Bridging Context and Reasoning with Fused Information in Latent Tokens",
            "summary": "arXiv:2602.10229v1 Announce Type: new Abstract: While explicit Chain-of-Thought (CoT) equips Large Language Models (LLMs) with strong reasoning capabilities, it requires models to verbalize every intermediate step in text tokens, constraining the model thoughts to the discrete vocabulary space. Recently, reasoning in continuous latent space has emerged as a promising alternative, enabling more robust inference and flexible computation beyond discrete token constraints. However, current latent pa",
            "url": "https://arxiv.org/abs/2602.10229",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-746bb08d",
            "type": "article",
            "title": "Learning to Evict from Key-Value Cache",
            "summary": "arXiv:2602.10238v1 Announce Type: new Abstract: The growing size of Large Language Models (LLMs) makes efficient inference challenging, primarily due to the memory demands of the autoregressive Key-Value (KV) cache. Existing eviction or compression methods reduce cost but rely on heuristics, such as recency or past attention scores, which serve only as indirect proxies for a token's future utility and introduce computational overhead. We reframe KV cache eviction as a reinforcement learning (RL)",
            "url": "https://arxiv.org/abs/2602.10238",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-dc7d4959",
            "type": "article",
            "title": "On Emergent Social World Models -- Evidence for Functional Integration of Theory of Mind and Pragmatic Reasoning in Language Models",
            "summary": "arXiv:2602.10298v1 Announce Type: new Abstract: This paper investigates whether LMs recruit shared computational mechanisms for general Theory of Mind (ToM) and language-specific pragmatic reasoning in order to contribute to the general question of whether LMs may be said to have emergent \"social world models\", i.e., representations of mental states that are repurposed across tasks (the functional integration hypothesis). Using behavioral evaluations and causal-mechanistic experiments via functi",
            "url": "https://arxiv.org/abs/2602.10298",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-bffb487e",
            "type": "article",
            "title": "Are More Tokens Rational? Inference-Time Scaling in Language Models as Adaptive Resource Rationality",
            "summary": "arXiv:2602.10329v1 Announce Type: new Abstract: Human reasoning is shaped by resource rationality -- optimizing performance under constraints. Recently, inference-time scaling has emerged as a powerful paradigm to improve the reasoning performance of Large Language Models by expanding test-time computation. Specifically, instruction-tuned (IT) models explicitly generate long reasoning steps during inference, whereas Large Reasoning Models (LRMs) are trained by reinforcement learning to discover ",
            "url": "https://arxiv.org/abs/2602.10329",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-eab527a4",
            "type": "article",
            "title": "The Subjectivity of Respect in Police Traffic Stops: Modeling Community Perspectives in Body-Worn Camera Footage",
            "summary": "arXiv:2602.10339v1 Announce Type: new Abstract: Traffic stops are among the most frequent police-civilian interactions, and body-worn cameras (BWCs) provide a unique record of how these encounters unfold. Respect is a central dimension of these interactions, shaping public trust and perceived legitimacy, yet its interpretation is inherently subjective and shaped by lived experience, rendering community-specific perspectives a critical consideration. Leveraging unprecedented access to Los Angeles",
            "url": "https://arxiv.org/abs/2602.10339",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-e26221a4",
            "type": "article",
            "title": "Geometry-Aware Decoding with Wasserstein-Regularized Truncation and Mass Penalties for Large Language Models",
            "summary": "arXiv:2602.10346v1 Announce Type: new Abstract: Large language models (LLMs) must balance diversity and creativity against logical coherence in open-ended generation. Existing truncation-based samplers are effective but largely heuristic, relying mainly on probability mass and entropy while ignoring semantic geometry of the token space. We present Top-W, a geometry-aware truncation rule that uses Wasserstein distance-defined over token-embedding geometry-to keep the cropped distribution close to",
            "url": "https://arxiv.org/abs/2602.10346",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-3dafefdc",
            "type": "article",
            "title": "When Less Is More? Diagnosing ASR Predictions in Sardinian via Layer-Wise Decoding",
            "summary": "arXiv:2602.10350v1 Announce Type: new Abstract: Recent studies have shown that intermediate layers in multilingual speech models often encode more phonetically accurate representations than the final output layer. In this work, we apply a layer-wise decoding strategy to a pretrained Wav2Vec2 model to investigate how phoneme-level predictions evolve across encoder layers, focusing on Campidanese Sardinian, a low-resource language. We show that truncating upper transformer layers leads to improved",
            "url": "https://arxiv.org/abs/2602.10350",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-7607010d",
            "type": "article",
            "title": "Learning Self-Interpretation from Interpretability Artifacts: Training Lightweight Adapters on Vector-Label Pairs",
            "summary": "arXiv:2602.10352v1 Announce Type: new Abstract: Self-interpretation methods prompt language models to describe their own internal states, but remain unreliable due to hyperparameter sensitivity. We show that training lightweight adapters on interpretability artifacts, while keeping the LM entirely frozen, yields reliable self-interpretation across tasks and model families. A scalar affine adapter with just $d_\\text{model}+1$ parameters suffices: trained adapters generate sparse autoencoder featu",
            "url": "https://arxiv.org/abs/2602.10352",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-133e2c88",
            "type": "article",
            "title": "Physically Interpretable AlphaEarth Foundation Model Embeddings Enable LLM-Based Land Surface Intelligence",
            "summary": "arXiv:2602.10354v1 Announce Type: new Abstract: Satellite foundation models produce dense embeddings whose physical interpretability remains poorly understood, limiting their integration into environmental decision systems. Using 12.1 million samples across the Continental United States (2017--2023), we first present a comprehensive interpretability analysis of Google AlphaEarth's 64-dimensional embeddings against 26 environmental variables spanning climate, vegetation, hydrology, temperature, a",
            "url": "https://arxiv.org/abs/2602.10354",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b11a3582",
            "type": "article",
            "title": "Autonomous Continual Learning of Computer-Use Agents for Environment Adaptation",
            "summary": "arXiv:2602.10356v1 Announce Type: new Abstract: Real-world digital environments are highly diverse and dynamic. These characteristics cause agents to frequently encounter unseen scenarios and distribution shifts, making continual learning in specific environments essential for computer-use agents (CUAs). However, a key challenge lies in obtaining high-quality and environment-grounded agent data without relying on costly human annotation. In this work, we introduce ACuRL, an Autonomous Curriculum",
            "url": "https://arxiv.org/abs/2602.10356",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-34db269f",
            "type": "article",
            "title": "The Alignment Bottleneck in Decomposition-Based Claim Verification",
            "summary": "arXiv:2602.10380v1 Announce Type: new Abstract: Structured claim decomposition is often proposed as a solution for verifying complex, multi-faceted claims, yet empirical results have been inconsistent. We argue that these inconsistencies stem from two overlooked bottlenecks: evidence alignment and sub-claim error profiles. To better understand these factors, we introduce a new dataset of real-world complex claims, featuring temporally bounded evidence and human-annotated sub-claim evidence spans",
            "url": "https://arxiv.org/abs/2602.10380",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-f70527c9",
            "type": "article",
            "title": "Triggers Hijack Language Circuits: A Mechanistic Analysis of Backdoor Behaviors in Large Language Models",
            "summary": "arXiv:2602.10382v1 Announce Type: new Abstract: Backdoor attacks pose significant security risks for Large Language Models (LLMs), yet the internal mechanisms by which triggers operate remain poorly understood. We present the first mechanistic analysis of language-switching backdoors, studying the GAPperon model family (1B, 8B, 24B parameters) which contains triggers injected during pretraining that cause output language switching. Using activation patching, we localize trigger formation to earl",
            "url": "https://arxiv.org/abs/2602.10382",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a0bfc7dd",
            "type": "article",
            "title": "When Tables Go Crazy: Evaluating Multimodal Models on French Financial Documents",
            "summary": "arXiv:2602.10384v1 Announce Type: new Abstract: Vision-language models (VLMs) perform well on many document understanding tasks, yet their reliability in specialized, non-English domains remains underexplored. This gap is especially critical in finance, where documents mix dense regulatory text, numerical tables, and visual charts, and where extraction errors can have real-world consequences. We introduce Multimodal Finance Eval, the first multimodal benchmark for evaluating French financial doc",
            "url": "https://arxiv.org/abs/2602.10384",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b52d8abf",
            "type": "article",
            "title": "Less is Enough: Synthesizing Diverse Data in Feature Space of LLMs",
            "summary": "arXiv:2602.10388v1 Announce Type: new Abstract: The diversity of post-training data is critical for effective downstream performance in large language models (LLMs). Many existing approaches to constructing post-training data quantify diversity using text-based metrics that capture linguistic variation, but such metrics provide only weak signals for the task-relevant features that determine downstream performance. In this work, we introduce Feature Activation Coverage (FAC) which measures data d",
            "url": "https://arxiv.org/abs/2602.10388",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-2c9de247",
            "type": "article",
            "title": "When are We Worried? Temporal Trends of Anxiety and What They Reveal about Us",
            "summary": "arXiv:2602.10400v1 Announce Type: new Abstract: In this short paper, we make use of a recently created lexicon of word-anxiety associations to analyze large amounts of US and Canadian social media data (tweets) to explore *when* we are anxious and what insights that reveals about us. We show that our levels of anxiety on social media exhibit systematic patterns of rise and fall during the day -- highest at 8am (in-line with when we have high cortisol levels in the body) and lowest around noon. A",
            "url": "https://arxiv.org/abs/2602.10400",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-ad24512e",
            "type": "article",
            "title": "EVOKE: Emotion Vocabulary Of Korean and English",
            "summary": "arXiv:2602.10414v1 Announce Type: new Abstract: This paper introduces EVOKE, a parallel dataset of emotion vocabulary in English and Korean. The dataset offers comprehensive coverage of emotion words in each language, in addition to many-to-many translations between words in the two languages and identification of language-specific emotion words. The dataset contains 1,427 Korean words and 1,399 English words, and we systematically annotate 819 Korean and 924 English adjectives and verbs. We als",
            "url": "https://arxiv.org/abs/2602.10414",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-5a91c75d",
            "type": "article",
            "title": "LATA: A Tool for LLM-Assisted Translation Annotation",
            "summary": "arXiv:2602.10454v1 Announce Type: new Abstract: The construction of high-quality parallel corpora for translation research has increasingly evolved from simple sentence alignment to complex, multi-layered annotation tasks. This methodological shift presents significant challenges for structurally divergent language pairs, such as Arabic--English, where standard automated tools frequently fail to capture deep linguistic shifts or semantic nuances. This paper introduces a novel, LLM-assisted inter",
            "url": "https://arxiv.org/abs/2602.10454",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-33d72718",
            "type": "article",
            "title": "Neuro-Symbolic Synergy for Interactive World Modeling",
            "summary": "arXiv:2602.10480v1 Announce Type: new Abstract: Large language models (LLMs) exhibit strong general-purpose reasoning capabilities, yet they frequently hallucinate when used as world models (WMs), where strict compliance with deterministic transition rules--particularly in corner cases--is essential. In contrast, Symbolic WMs provide logical consistency but lack semantic expressivity. To bridge this gap, we propose Neuro-Symbolic Synergy (NeSyS), a framework that integrates the probabilistic sem",
            "url": "https://arxiv.org/abs/2602.10480",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-36389a80",
            "type": "article",
            "title": "Canvas-of-Thought: Grounding Reasoning via Mutable Structured States",
            "summary": "arXiv:2602.10494v1 Announce Type: new Abstract: While Chain-of-Thought (CoT) prompting has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), relying solely on linear text sequences remains a bottleneck for complex tasks. We observe that even when auxiliary visual elements are interleaved, they are often treated as static snapshots within a one-dimensional, unstructured reasoning chain. We argue that such approaches treat reasoning history as an immuta",
            "url": "https://arxiv.org/abs/2602.10494",
            "source": "arxiv",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-35caebc0",
            "type": "article",
            "title": "9 fun questions to try asking Google Photos",
            "summary": "A collage of outdoor images, a blue icon that say \"Ask Photos,\" and examples of Ask Photos prompts.",
            "url": "https://blog.google/products-and-platforms/products/photos/ask-button-ask-photos-tips/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9eef7a37",
            "type": "article",
            "title": "Helping kids and teens learn and grow online on Safer Internet Day",
            "summary": "User profile on smartphone connected to security, media, and settings icons.",
            "url": "https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-2026-kids-teens/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e42f6ff4",
            "type": "article",
            "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
            "summary": "A collage of four images, the first of a woman with curly hair in front of a silver laptop, the second of the same woman and a man with short black hair speaking on a stairwell, the third of a the same man with glasses, and an aerial image of NTID",
            "url": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-828c66e8",
            "type": "article",
            "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
            "summary": "A woman outdoors in the snow looks at a tablet. A half pipe is behind her.",
            "url": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-f9c339ba",
            "type": "article",
            "title": "Watch our new Gemini ad ahead of football\u2019s biggest weekend",
            "summary": "A toddler in a blue and yellow striped shirt sits on a kitchen counter eating a red apple. Text in the corner reads: 'New Home, Google Gemini SB Commercial\u2019",
            "url": "https://blog.google/company-news/inside-google/company-announcements/gemini-ad-new-home/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-5d835c59",
            "type": "article",
            "title": "Transformers.js v4 Preview: Now Available on NPM!",
            "summary": "",
            "url": "https://huggingface.co/blog/transformersjs-v4",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-4b956a17",
            "type": "article",
            "title": "Introducing SyGra Studio",
            "summary": "",
            "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-26db947a",
            "type": "article",
            "title": "Is a secure AI assistant possible?",
            "summary": "AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That might explain why the&#8230;",
            "url": "https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/",
            "source": "blogs",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-5f5ee2c2",
            "type": "article",
            "title": "A \u201cQuitGPT\u201d campaign is urging people to cancel their ChatGPT subscriptions",
            "summary": "In September, Alfred Stephen, a freelance software developer in Singapore, purchased a ChatGPT Plus subscription, which costs $20 a month and offers more access to advanced models, to speed up his work. But he grew frustrated with the chatbot\u2019s coding abilities and its gushing, meandering replies. Then he came across a post on Reddit about&#8230;",
            "url": "https://www.technologyreview.com/2026/02/10/1132577/a-quitgpt-campaign-is-urging-people-to-cancel-chatgpt-subscriptions/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e3e028d7",
            "type": "article",
            "title": "Why the Moltbook frenzy was like Pok\u00e9mon",
            "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-d7ce15dc",
            "type": "article",
            "title": "Making AI Work, MIT Technology Review\u2019s new AI newsletter, is here",
            "summary": "For years, our newsroom has explored AI\u2019s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&#160; But how is AI actually being used in fields like health care, climate tech, education,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-63da4d4a",
            "type": "article",
            "title": "Moltbook was peak AI theater",
            "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on January 28 by Matt Schlicht,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
            "source": "blogs",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-4c5e5bb4",
            "type": "article",
            "title": "This is the most misunderstood graph in AI",
            "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;",
            "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-95413412",
            "type": "article",
            "title": "Show HN: The \"Vat of Fluid\" Model\u2013Solving 7Systems Paradoxes ViaFirst Principles",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46985626",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-8c183005",
            "type": "article",
            "title": "Digitizing the \"Shokunin\": How we encoded a Master's hammer strike into AI",
            "summary": "",
            "url": "https://yusukekaizen.substack.com/p/the-mathematics-of-intuition-how",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-79dd8258",
            "type": "article",
            "title": "Create professional presentations in minutes with AI",
            "summary": "",
            "url": "https://genppt.ai/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b9618236",
            "type": "article",
            "title": "Cache-aware prefill\u2013decode disaggregation \u2013 40% faster long-context LLM serving",
            "summary": "",
            "url": "https://www.together.ai/blog/cache-aware-disaggregated-inference",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-4eb70be9",
            "type": "article",
            "title": "AI Assisted Linguistic Synth:Mapping Proto-Sinaitic Roots in Voynich Manuscript",
            "summary": "",
            "url": "https://github.com/adrihd/voyters",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-413f4719",
            "type": "article",
            "title": "Show HN: Motiv\u00e9 \u2013 AI-generated cover letters tailored to job descriptions",
            "summary": "",
            "url": "https://motive8.ca",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-4f915fb2",
            "type": "article",
            "title": "Gokin update: major reliability improvements in the Go-native AI coding CLI",
            "summary": "",
            "url": "https://github.com/ginkida/gokin",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-aeee3fa4",
            "type": "article",
            "title": "How to Use Google Trends and SEO Tools to Brainstorm Blog Topics",
            "summary": "",
            "url": "https://kitful.ai/blog/how-to-use-google-trends-and-seo-tools-to-brainstorm-blog-topics",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-8e53ba9e",
            "type": "article",
            "title": "The \"Are You Sure?\" Problem: Why Your AI Keeps Changing Its Mind",
            "summary": "",
            "url": "https://www.randalolson.com/2026/02/07/the-are-you-sure-problem-why-your-ai-keeps-changing-its-mind/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a60f2da4",
            "type": "article",
            "title": "Deep Dive into New York City Air Traffic Control (2019)",
            "summary": "",
            "url": "https://josephgunnwriting.wordpress.com/2019/06/13/deep-dive-into-new-york-city-air-traffic-control-using-flightradar24/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-50bce0d2",
            "type": "article",
            "title": "Moltbook Looked Like an Emerging AI Society, but Humans Were Pulling the Strings",
            "summary": "",
            "url": "https://www.forbes.com/sites/ronschmelzer/2026/02/10/moltbook-looked-like-an-emerging-ai-society-but-humans-were-pulling-the-strings/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-dc4e53b8",
            "type": "article",
            "title": "Show HN: MoltHub \u2013 GitHub for AI Agents with Trust-Based Auto-Merge",
            "summary": "",
            "url": "https://molt-hub.org",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-596a6d1e",
            "type": "article",
            "title": "Show HN: Prompt Builder \u2013 A block-based editor for composing AI prompts",
            "summary": "",
            "url": "https://www.promptbuilder.space/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-687fbf3a",
            "type": "article",
            "title": "Show HN: Membrane, revisable memory for long lived AI agents",
            "summary": "",
            "url": "https://github.com/GustyCube/membrane",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-a8ba0e30",
            "type": "article",
            "title": "Show HN: 10-min AI threat model (STRIDE and MAESTRO), assumption-driven",
            "summary": "",
            "url": "https://raxit.ai/assessment",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-dbb832ad",
            "type": "article",
            "title": "Show HN: Consciousness Gateway \u2013 AI routing with consciousness-first alignment",
            "summary": "",
            "url": "https://github.com/Move37LLC/consciousness-gateway",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-ca5fdc96",
            "type": "article",
            "title": "Staying on Top in the Age of LLMs",
            "summary": "",
            "url": "https://andrasgerlits.medium.com/staying-on-top-in-the-age-of-llms-818400f8ff0a",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-57fe7260",
            "type": "article",
            "title": "Stripe HK: Approved, paid small sum, withheld $12k via dissolved entity",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46985510",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-b366e989",
            "type": "article",
            "title": "GLM-5 was trained entirely on Huawei chips",
            "summary": "",
            "url": "https://glm5.net/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 51
        },
        {
            "id": "article-292cf862",
            "type": "article",
            "title": "MIT's new fine-tuning method lets LLMs learn new skills without losing old ones",
            "summary": "",
            "url": "https://venturebeat.com/orchestration/mits-new-fine-tuning-method-lets-llms-learn-new-skills-without-losing-old",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-afdadb00",
            "type": "article",
            "title": "Biases in the Blind Spot: Detecting What LLMs Fail to Mention",
            "summary": "",
            "url": "https://arxiv.org/abs/2602.10117",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-6ac995dc",
            "type": "article",
            "title": "Show HN: 3D and World Models for Consistent AI Filmmaking",
            "summary": "",
            "url": "https://getartcraft.com/news/world-models-for-film",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-83647dc4",
            "type": "article",
            "title": "The Solution to Prompt Injection: Mapping SSL/TLS Trust Architecture onto LLMs [pdf]",
            "summary": "",
            "url": "https://solvingpromptinjection.com/wp-content/uploads/solution-to-prompt-injection.pdf",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-2f4f6780",
            "type": "article",
            "title": "The Problem with LLMs",
            "summary": "",
            "url": "https://www.deobald.ca/essays/2026-02-10-the-problem-with-llms/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 54
        },
        {
            "id": "article-08312fc4",
            "type": "article",
            "title": "Claude alarm clock wakes you when the 5h limit replenishes",
            "summary": "",
            "url": "https://twitter.com/tomaskafka/status/2021741104530378793",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-948a47f6",
            "type": "article",
            "title": "LLM \"reasoning\" continues to be deeply flawed",
            "summary": "",
            "url": "https://garymarcus.substack.com/p/breaking-llm-reasoning-continues",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-021ffece",
            "type": "article",
            "title": "Show HN: OpenHarness \u2013 A harness for open source projects built by AI agents",
            "summary": "",
            "url": "https://openharn.vercel.app",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-d98e1bdb",
            "type": "article",
            "title": "Warcraft III Peon Voice Notifications for Claude Code",
            "summary": "",
            "url": "https://github.com/tonyyont/peon-ping",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 58
        },
        {
            "id": "article-e69e44eb",
            "type": "article",
            "title": "Show HN:ProductFront-Streamlined product discovery platform for maximum exposure",
            "summary": "",
            "url": "https://www.productfront.tech",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-81e68aab",
            "type": "article",
            "title": "Show HN: Cross-platform audio notifications for Claude Code",
            "summary": "",
            "url": "https://github.com/ChanMeng666/claude-code-audio-hooks",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-afeaf6ad",
            "type": "article",
            "title": "Part 2 - AI Chat Evaluation of the Formal Language in He Xin's PEPC System",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46976391",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-8177f858",
            "type": "article",
            "title": "Ask HN: How to find joy in writing/learning about tech in this AI world?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46960408",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2497fd1b",
            "type": "article",
            "title": "God, Theology, and AI",
            "summary": "",
            "url": "https://rlafuente.com/posts/2026-2-1-on-god-and-machine-learning#",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2ed9ffa8",
            "type": "article",
            "title": "Show HN: We added AGENTS.md to 120 challenges so AI teaches instead of codes",
            "summary": "",
            "url": "https://www.frontendmentor.io/articles/agents-md-files-in-every-challenge",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-a8bc8060",
            "type": "article",
            "title": "Show HN: SuperLocalMemory \u2013 AI memory that stays on your machine, forever free",
            "summary": "",
            "url": "https://github.com/varun369/SuperLocalMemoryV2",
            "source": "hackernews",
            "date": "2026-02-07",
            "trendingScore": 50
        },
        {
            "id": "article-f18858e8",
            "type": "article",
            "title": "ML-Lib: Machine Learning Library Proposed for the Linux Kernel",
            "summary": "",
            "url": "https://www.phoronix.com/news/Linux-Kernel-ML-LIB-RFC",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-7221af3c",
            "type": "article",
            "title": "AI Development Company",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46909998",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-16bcd5b5",
            "type": "article",
            "title": "Chrome 146 Now in Beta with WebNN Origin Trial for Neural Networks in Browser",
            "summary": "",
            "url": "https://www.phoronix.com/news/Chrome-146-Beta",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-5bfdb138",
            "type": "article",
            "title": "Show HN: Rowboat \u2013 AI coworker that turns your work into a knowledge graph (OSS)",
            "summary": "",
            "url": "https://github.com/rowboatlabs/rowboat",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 69
        },
        {
            "id": "article-8e34af62",
            "type": "article",
            "title": "Show HN: Energy Based Model solving nonograms",
            "summary": "",
            "url": "https://github.com/hirako2000/latent-energy",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2a63b432",
            "type": "article",
            "title": "A Complete Guide to Neural Network Optimizers",
            "summary": "",
            "url": "https://chizkidd.github.io//2026/01/22/neural-net-optimizers/",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-ed81c445",
            "type": "article",
            "title": "SpaceX-xAI Merger: Nobody's Talking About the von Neumann Elephant in the Room",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46933827",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-b079933d",
            "type": "article",
            "title": "Can graph neural networks for biology realistically run on edge devices?",
            "summary": "",
            "url": "https://doi.org/10.21203/rs.3.rs-8645211/v1",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-faec27b2",
            "type": "article",
            "title": "SMLL: Using 200MB of Neural Network to Save 400 Bytes",
            "summary": "",
            "url": "https://www.frankchiarulli.com/blog/smll/",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 51
        },
        {
            "id": "article-29a8aa5e",
            "type": "article",
            "title": "Hypernetworks: Neural Networks for Hierarchical Data",
            "summary": "",
            "url": "https://blog.sturdystatistics.com/posts/hnet_part_I/",
            "source": "hackernews",
            "date": "2026-02-05",
            "trendingScore": 59
        },
        {
            "id": "article-6311db46",
            "type": "article",
            "title": "Reflections on Using Claude Code",
            "summary": "",
            "url": "http://ternarysearch.blogspot.com/2026/02/reflections-on-using-claude-code.html",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-85773b04",
            "type": "article",
            "title": "Show HN: Claude Remote",
            "summary": "",
            "url": "https://github.com/jamierpond/claude-remote",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-0aa5068c",
            "type": "article",
            "title": "Show HN: Agnix \u2013 lint your AI agent configs (Claude.md, skills, MCP, hooks)",
            "summary": "",
            "url": "https://github.com/avifenesh/agnix",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-48db4b63",
            "type": "article",
            "title": "20 Claude Code agents, one terminal: a tmux + AppleScript setup",
            "summary": "",
            "url": "https://pkarnal.com/blog/parallel-ai-agents",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-1d06e33e",
            "type": "article",
            "title": "Claude Code Doesn't Make You Better at Multitasking",
            "summary": "",
            "url": "https://writing.peercy.net/claude-code-doesnt-make-you-better-at-multitasking/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-f1c4cc1b",
            "type": "article",
            "title": "Claude Code Skill That Shares Noteworthy Moments to Slack",
            "summary": "",
            "url": "https://quickchat.ai/post/claude-code-skill-watches-coding-sessions-shares-to-slack",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-19760348",
            "type": "article",
            "title": "Claude's impact on older software engineers while listening to country music",
            "summary": "",
            "url": "https://suno.com/song/0d9b02a2-a709-4b2c-ba66-f62ff9306f79",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-bedc1410",
            "type": "article",
            "title": "Show HN: MemoryGate \u2013 Open-source persistent memory for AI agents via MCP",
            "summary": "",
            "url": "https://www.memorygate.ai",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-4cef243d",
            "type": "article",
            "title": "Show HN: Send Claude Code tasks to the Batch API at 50% off",
            "summary": "",
            "url": "https://github.com/s2-streamstore/claude-batch-toolkit",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 52
        },
        {
            "id": "article-f7419e5c",
            "type": "article",
            "title": "Apple reportedly pushing back Gemini-powered Siri features beyond iOS 26.4",
            "summary": "",
            "url": "https://9to5mac.com/2026/02/11/apple-reportedly-pushing-back-gemini-powered-siri-features-beyond-ios-26-4/",
            "source": "hackernews",
            "date": "2026-02-12",
            "trendingScore": 50
        },
        {
            "id": "article-7eaef3c7",
            "type": "article",
            "title": "Show HN: DevProof \u2013 Verified developer portfolios using Code Complexity and AI",
            "summary": "",
            "url": "https://dev-proof-portfolio.vercel.app",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-0c0fa02d",
            "type": "article",
            "title": "Show HN: Agent Alcove \u2013 Claude, GPT, and Gemini debate across forums",
            "summary": "",
            "url": "https://agentalcove.ai",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 55
        },
        {
            "id": "article-4b3366d3",
            "type": "article",
            "title": "Accelerating Mathematical and Scientific Discovery with Gemini Deep Think",
            "summary": "",
            "url": "https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 51
        },
        {
            "id": "article-5b9bebf1",
            "type": "article",
            "title": "How to Structure Inputs for Claude, ChatGPT, and Gemini",
            "summary": "",
            "url": "https://app.writtte.com/read/wKYzFmP",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-149c5f5e",
            "type": "article",
            "title": "Show HN: Auditi \u2013 open-source LLM tracing and evaluation platform",
            "summary": "",
            "url": "https://github.com/deduu/auditi",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-b35d6332",
            "type": "article",
            "title": "Gemini writes, Claude polishes, JetBrains rests: an agent development pipeline",
            "summary": "",
            "url": "https://ginkida.dev/en/posts/gemini-writes-claude-polishes-jetbrains-rests-my-agent-1",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-dca2e0c2",
            "type": "article",
            "title": "Show HN: Claudit \u2013 Claude Code Conversations as Git Notes, Automatically",
            "summary": "",
            "url": "https://github.com/re-cinq/claudit",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-2c27b936",
            "type": "article",
            "title": "Show HN: A Guided Learning LLM",
            "summary": "",
            "url": "https://adaptive.bounded.cc",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-1a273637",
            "type": "article",
            "title": "Google bans Gemini/Antigravity accounts used outside of Antigravity/Gemini-CLI",
            "summary": "",
            "url": "https://old.reddit.com/r/google_antigravity/comments/1qykskz/account_banned_for_using_open_claw/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-b2bc6b6d",
            "type": "article",
            "title": "Show HN: Idea Forge \u2013 Multi-model product validation(validated an OpenClaw idea)",
            "summary": "",
            "url": "https://ideas.sparkngine.com/",
            "source": "hackernews",
            "date": "2026-02-11",
            "trendingScore": 50
        },
        {
            "id": "article-f28970ff",
            "type": "article",
            "title": "Ask HN: Pro option missing from Gemini model selector?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46965941",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "topic-large-language-models",
            "type": "topic",
            "title": "Large Language Models",
            "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
            "connectionCount": 44
        },
        {
            "id": "topic-ai-agents",
            "type": "topic",
            "title": "AI Agents",
            "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
            "connectionCount": 24
        },
        {
            "id": "topic-ai-safety",
            "type": "topic",
            "title": "AI Safety",
            "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
            "connectionCount": 6
        },
        {
            "id": "topic-multimodal-ai",
            "type": "topic",
            "title": "Multimodal AI",
            "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
            "connectionCount": 5
        },
        {
            "id": "topic-model-efficiency",
            "type": "topic",
            "title": "Model Efficiency",
            "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
            "connectionCount": 2
        },
        {
            "id": "topic-computer-vision",
            "type": "topic",
            "title": "Computer Vision",
            "summary": "AI systems for understanding and processing visual information from images and video.",
            "connectionCount": 8
        },
        {
            "id": "topic-nlp",
            "type": "topic",
            "title": "NLP",
            "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
            "connectionCount": 31
        },
        {
            "id": "topic-reinforcement-learning",
            "type": "topic",
            "title": "Reinforcement Learning",
            "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
            "connectionCount": 31
        },
        {
            "id": "topic-ai-reasoning",
            "type": "topic",
            "title": "AI Reasoning",
            "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
            "connectionCount": 19
        },
        {
            "id": "topic-prompt-engineering",
            "type": "topic",
            "title": "Prompt Engineering",
            "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
            "connectionCount": 7
        },
        {
            "id": "topic-rag",
            "type": "topic",
            "title": "RAG",
            "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
            "connectionCount": 8
        },
        {
            "id": "topic-fine-tuning",
            "type": "topic",
            "title": "Fine-tuning",
            "summary": "Adapting pre-trained models to specific tasks or domains.",
            "connectionCount": 5
        },
        {
            "id": "topic-diffusion-models",
            "type": "topic",
            "title": "Diffusion Models",
            "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
            "connectionCount": 1
        },
        {
            "id": "org-cohere",
            "type": "organization",
            "title": "Cohere",
            "summary": "Cohere - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-aws",
            "type": "organization",
            "title": "AWS",
            "summary": "AWS - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-meta",
            "type": "organization",
            "title": "Meta",
            "summary": "Meta - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-google",
            "type": "organization",
            "title": "Google",
            "summary": "Google - AI research and development.",
            "connectionCount": 7
        },
        {
            "id": "org-apple",
            "type": "organization",
            "title": "Apple",
            "summary": "Apple - AI research and development.",
            "connectionCount": 3
        },
        {
            "id": "org-openai",
            "type": "organization",
            "title": "OpenAI",
            "summary": "OpenAI - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-anthropic",
            "type": "organization",
            "title": "Anthropic",
            "summary": "Anthropic - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-xai",
            "type": "organization",
            "title": "xAI",
            "summary": "xAI - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "model-gemini",
            "type": "model",
            "title": "Gemini",
            "summary": "Gemini AI model.",
            "connectionCount": 8
        },
        {
            "id": "model-chatgpt",
            "type": "model",
            "title": "ChatGPT",
            "summary": "ChatGPT AI model.",
            "connectionCount": 2
        },
        {
            "id": "model-claude",
            "type": "model",
            "title": "Claude",
            "summary": "Claude AI model.",
            "connectionCount": 15
        }
    ],
    "edges": [
        {
            "source": "article-524a6c67",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-524a6c67",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-f45d64da",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f45d64da",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a83b0b22",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f80b3a4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f80b3a4",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-78f5f85d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-78f5f85d",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-78f5f85d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c0ca6ced",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c0ca6ced",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c0ca6ced",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a3c94a90",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b00e58d3",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b00e58d3",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-fb431736",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-fb431736",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fb431736",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7a4927be",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-7a4927be",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-7a4927be",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7a4927be",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-919552de",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-b5fb10b1",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-b5fb10b1",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-b5fb10b1",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1114ab44",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1114ab44",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1114ab44",
            "target": "org-cohere",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-d746e751",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d746e751",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d746e751",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d746e751",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-10b49fa5",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-10b49fa5",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ab551c0c",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-ab551c0c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c70a8c2",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c70a8c2",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf99193d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf99193d",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf99193d",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf99193d",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-54f03866",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-0acb33e5",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-0acb33e5",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb2040a7",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb2040a7",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb2040a7",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-de7af22f",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-de7af22f",
            "target": "org-aws",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-220cbbf0",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-220cbbf0",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-634a4f1b",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe280630",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe280630",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-8965509b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-8965509b",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8965509b",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-8965509b",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6c9f103",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cf8bcd7b",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-cf8bcd7b",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-cf8bcd7b",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-cf8bcd7b",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-cf8bcd7b",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-6ac389f9",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6ac389f9",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-39926193",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-39926193",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-39926193",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-39926193",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-6e0fdc85",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6e0fdc85",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-6e0fdc85",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-6e0fdc85",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a993472f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a993472f",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a993472f",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-a993472f",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6ffcb061",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6ffcb061",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ab4ab830",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-76a0daeb",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-da6df449",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-da6df449",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-538ce1af",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-538ce1af",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-19563cae",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-19563cae",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b82acbc1",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1e3e9df5",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1e3e9df5",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1e3e9df5",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-746bb08d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-746bb08d",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc7d4959",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc7d4959",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc7d4959",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc7d4959",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc7d4959",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-bffb487e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-bffb487e",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-bffb487e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-bffb487e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-eab527a4",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-e26221a4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e26221a4",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e26221a4",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e26221a4",
            "target": "org-cohere",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-3dafefdc",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7607010d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7607010d",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-7607010d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-7607010d",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-133e2c88",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-133e2c88",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-133e2c88",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-b11a3582",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-b11a3582",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-34db269f",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-34db269f",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f70527c9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f70527c9",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0bfc7dd",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0bfc7dd",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0bfc7dd",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0bfc7dd",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0bfc7dd",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b52d8abf",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b52d8abf",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-b52d8abf",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ad24512e",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a91c75d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a91c75d",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a91c75d",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-33d72718",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-33d72718",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-33d72718",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-33d72718",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-36389a80",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-35caebc0",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-828c66e8",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5d835c59",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-26db947a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-26db947a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-26db947a",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5f5ee2c2",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e3e028d7",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d7ce15dc",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-63da4d4a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-b9618236",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b9618236",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-413f4719",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-aeee3fa4",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-dc4e53b8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-596a6d1e",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-687fbf3a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-dbb832ad",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-ca5fdc96",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-292cf862",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-292cf862",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-afdadb00",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6ac995dc",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-83647dc4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-83647dc4",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f4f6780",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-08312fc4",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-948a47f6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-948a47f6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-021ffece",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d98e1bdb",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-81e68aab",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8177f858",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ed9ffa8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a8bc8060",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8e34af62",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ed81c445",
            "target": "org-xai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-6311db46",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-85773b04",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0aa5068c",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-0aa5068c",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-48db4b63",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-48db4b63",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-48db4b63",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1d06e33e",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f1c4cc1b",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-19760348",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bedc1410",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-4cef243d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f7419e5c",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f7419e5c",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0c0fa02d",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-0c0fa02d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0c0fa02d",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4b3366d3",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5b9bebf1",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5b9bebf1",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5b9bebf1",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-149c5f5e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b35d6332",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-b35d6332",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-b35d6332",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-dca2e0c2",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-2c27b936",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1a273637",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1a273637",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f28970ff",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-reasoning",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-agents",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-rag",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-multimodal-ai",
            "target": "topic-computer-vision",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-agents",
            "target": "topic-prompt-engineering",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-model-efficiency",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-safety",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        }
    ]
};

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIChronicleData;
}
