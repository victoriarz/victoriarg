// ================================================
// THE AI CHRONICLE - Knowledge Graph Data
// Auto-generated and updated daily via GitHub Actions
// Last updated: 2026-01-12
// ================================================

const AIChronicleData = {
    "metadata": {
        "lastUpdated": "2026-01-12T06:34:53.054339Z",
        "totalArticles": 135,
        "totalNodes": 159,
        "totalEdges": 227,
        "dateRange": {
            "start": "2026-01-05",
            "end": "2026-01-12"
        }
    },
    "nodes": [
        {
            "id": "article-37c8c6d9",
            "type": "article",
            "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring",
            "summary": "arXiv:2601.05256v1 Announce Type: new Abstract: Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observat",
            "url": "https://arxiv.org/abs/2601.05256",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-4895640b",
            "type": "article",
            "title": "Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing",
            "summary": "arXiv:2601.05298v1 Announce Type: new Abstract: Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge grap",
            "url": "https://arxiv.org/abs/2601.05298",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-10b50d27",
            "type": "article",
            "title": "Effects of personality steering on cooperative behavior in Large Language Model agents",
            "summary": "arXiv:2601.05302v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based o",
            "url": "https://arxiv.org/abs/2601.05302",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-6070e3fc",
            "type": "article",
            "title": "Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings",
            "summary": "arXiv:2601.05330v1 Announce Type: new Abstract: Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hin",
            "url": "https://arxiv.org/abs/2601.05330",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-1d780a59",
            "type": "article",
            "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models",
            "summary": "arXiv:2601.05376v1 Announce Type: new Abstract: Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\\ cautious)",
            "url": "https://arxiv.org/abs/2601.05376",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-5d64e072",
            "type": "article",
            "title": "Conformity and Social Impact on AI Agents",
            "summary": "arXiv:2601.05384v1 Announce Type: new Abstract: As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence a",
            "url": "https://arxiv.org/abs/2601.05384",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-63e27bbf",
            "type": "article",
            "title": "On the Effect of Cheating in Chess",
            "summary": "arXiv:2601.05386v1 Announce Type: new Abstract: Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\\footnote{Needless to say, the goal o",
            "url": "https://arxiv.org/abs/2601.05386",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-872ddb50",
            "type": "article",
            "title": "ART: Adaptive Reasoning Trees for Explainable Claim Verification",
            "summary": "arXiv:2601.05455v1 Announce Type: new Abstract: Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim ver",
            "url": "https://arxiv.org/abs/2601.05455",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-caffb91a",
            "type": "article",
            "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering",
            "summary": "arXiv:2601.05465v1 Announce Type: new Abstract: Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails ",
            "url": "https://arxiv.org/abs/2601.05465",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-ada945d8",
            "type": "article",
            "title": "MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis",
            "summary": "arXiv:2601.05483v1 Announce Type: new Abstract: Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust ana",
            "url": "https://arxiv.org/abs/2601.05483",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e0a07ee7",
            "type": "article",
            "title": "The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm",
            "summary": "arXiv:2601.05500v1 Announce Type: new Abstract: Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for ev",
            "url": "https://arxiv.org/abs/2601.05500",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-b9721c72",
            "type": "article",
            "title": "Explainable AI: Learning from the Learners",
            "summary": "arXiv:2601.05525v1 Announce Type: new Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction o",
            "url": "https://arxiv.org/abs/2601.05525",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e6c8f2af",
            "type": "article",
            "title": "Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making",
            "summary": "arXiv:2601.05529v1 Announce Type: new Abstract: One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we",
            "url": "https://arxiv.org/abs/2601.05529",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-f1c2f2b7",
            "type": "article",
            "title": "WildSci: Advancing Scientific Reasoning from In-the-Wild Literature",
            "summary": "arXiv:2601.05567v1 Announce Type: new Abstract: Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we intr",
            "url": "https://arxiv.org/abs/2601.05567",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-796fa6df",
            "type": "article",
            "title": "Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models",
            "summary": "arXiv:2601.05570v1 Announce Type: new Abstract: Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid \"Boy Scout\" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a \"transparency tax\" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general",
            "url": "https://arxiv.org/abs/2601.05570",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-006b7823",
            "type": "article",
            "title": "Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection",
            "summary": "arXiv:2601.05578v1 Announce Type: new Abstract: E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effective",
            "url": "https://arxiv.org/abs/2601.05578",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-6e1c142e",
            "type": "article",
            "title": "A Causal Information-Flow Framework for Unbiased Learning-to-Rank",
            "summary": "arXiv:2601.05590v1 Announce Type: new Abstract: In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) m",
            "url": "https://arxiv.org/abs/2601.05590",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-6da6f35d",
            "type": "article",
            "title": "Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion",
            "summary": "arXiv:2601.05629v1 Announce Type: new Abstract: Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such",
            "url": "https://arxiv.org/abs/2601.05629",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-31c37dbb",
            "type": "article",
            "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models",
            "summary": "arXiv:2601.05637v1 Announce Type: new Abstract: As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a ",
            "url": "https://arxiv.org/abs/2601.05637",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-b381c6f2",
            "type": "article",
            "title": "HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation",
            "summary": "arXiv:2601.05656v1 Announce Type: new Abstract: High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution aw",
            "url": "https://arxiv.org/abs/2601.05656",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-d21b4d4f",
            "type": "article",
            "title": "MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs",
            "summary": "arXiv:2601.05296v1 Announce Type: new Abstract: The pervasive \"memory wall\" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GP",
            "url": "https://arxiv.org/abs/2601.05296",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-2f9758e6",
            "type": "article",
            "title": "TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning",
            "summary": "arXiv:2601.05300v1 Announce Type: new Abstract: Reasoning oriented large language models often expose explicit \"thinking\" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treat",
            "url": "https://arxiv.org/abs/2601.05300",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-1cf85eaa",
            "type": "article",
            "title": "Ontology Neural Networks for Topologically Conditioned Constraint Satisfaction",
            "summary": "arXiv:2601.05304v1 Announce Type: new Abstract: Neuro-symbolic reasoning systems face fundamental challenges in maintaining semantic coherence while satisfying physical and logical constraints. Building upon our previous work on Ontology Neural Networks, we present an enhanced framework that integrates topological conditioning with gradient stabilization mechanisms. The approach employs Forman-Ricci curvature to capture graph topology, Deep Delta Learning for stable rank-one perturbations during",
            "url": "https://arxiv.org/abs/2601.05304",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-9e96211a",
            "type": "article",
            "title": "When the Server Steps In: Calibrated Updates for Fair Federated Learning",
            "summary": "arXiv:2601.05352v1 Announce Type: new Abstract: Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been propose",
            "url": "https://arxiv.org/abs/2601.05352",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-f2d6cbd8",
            "type": "article",
            "title": "GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting",
            "summary": "arXiv:2601.05353v1 Announce Type: new Abstract: Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role",
            "url": "https://arxiv.org/abs/2601.05353",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-5d5cd078",
            "type": "article",
            "title": "The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection",
            "summary": "arXiv:2601.05371v1 Announce Type: new Abstract: Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distance",
            "url": "https://arxiv.org/abs/2601.05371",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3243b3d4",
            "type": "article",
            "title": "Inverting Non-Injective Functions with Twin Neural Network Regression",
            "summary": "arXiv:2601.05378v1 Announce Type: new Abstract: Non-injective functions are not invertible. However, non-injective functions can be restricted to sub-domains on which they are locally injective and surjective and thus invertible if the dimensionality between input and output spaces are the same. Further, even if the dimensionalities do not match it is often possible to choose a preferred solution from many possible solutions. Twin neural network regression is naturally capable of incorporating t",
            "url": "https://arxiv.org/abs/2601.05378",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e1fed3f4",
            "type": "article",
            "title": "Imitation Learning for Combinatorial Optimisation under Uncertainty",
            "summary": "arXiv:2601.05383v1 Announce Type: new Abstract: Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \\emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a ",
            "url": "https://arxiv.org/abs/2601.05383",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e06e568e",
            "type": "article",
            "title": "DynaSTy: A Framework for SpatioTemporal Node Attribute Prediction in Dynamic Graphs",
            "summary": "arXiv:2601.05391v1 Announce Type: new Abstract: Accurate multistep forecasting of node-level attributes on dynamic graphs is critical for applications ranging from financial trust networks to biological networks. Existing spatiotemporal graph neural networks typically assume a static adjacency matrix. In this work, we propose an end-to-end dynamic edge-biased spatiotemporal model that ingests a multi-dimensional timeseries of node attributes and a timeseries of adjacency matrices, to predict mul",
            "url": "https://arxiv.org/abs/2601.05391",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-a0b22b5a",
            "type": "article",
            "title": "Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning",
            "summary": "arXiv:2601.05407v1 Announce Type: new Abstract: Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To a",
            "url": "https://arxiv.org/abs/2601.05407",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-f44bc866",
            "type": "article",
            "title": "Efficient Inference for Noisy LLM-as-a-Judge Evaluation",
            "summary": "arXiv:2601.05420v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly used as automatic evaluators of generative AI outputs, a paradigm often referred to as \"LLM-as-a-judge.\" In practice, LLM judges are imperfect predictions for the underlying truth and can exhibit systematic, non-random errors. Two main approaches have recently been proposed to address this issue: (i) direct measurementerror correction based on misclassification models such as Rogan-Gladen-style estimato",
            "url": "https://arxiv.org/abs/2601.05420",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-da7f5df8",
            "type": "article",
            "title": "Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion",
            "summary": "arXiv:2601.05431v1 Announce Type: new Abstract: Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields,",
            "url": "https://arxiv.org/abs/2601.05431",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-5867e175",
            "type": "article",
            "title": "RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models",
            "summary": "arXiv:2601.05451v1 Announce Type: new Abstract: Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We ",
            "url": "https://arxiv.org/abs/2601.05451",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-06f63276",
            "type": "article",
            "title": "Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning",
            "summary": "arXiv:2601.05474v1 Announce Type: new Abstract: Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, th",
            "url": "https://arxiv.org/abs/2601.05474",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-ba3cc0f2",
            "type": "article",
            "title": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization",
            "summary": "arXiv:2601.05475v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we ex",
            "url": "https://arxiv.org/abs/2601.05475",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-c598cd65",
            "type": "article",
            "title": "Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection",
            "summary": "arXiv:2601.05501v1 Announce Type: new Abstract: Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO me",
            "url": "https://arxiv.org/abs/2601.05501",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-dc38f0d2",
            "type": "article",
            "title": "Over-Searching in Search-Augmented Large Language Models",
            "summary": "arXiv:2601.05503v1 Announce Type: new Abstract: Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, mo",
            "url": "https://arxiv.org/abs/2601.05503",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-bfec6874",
            "type": "article",
            "title": "Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management",
            "summary": "arXiv:2601.05521v1 Announce Type: new Abstract: The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose",
            "url": "https://arxiv.org/abs/2601.05521",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-d1b743b8",
            "type": "article",
            "title": "DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis",
            "summary": "arXiv:2601.05527v1 Announce Type: new Abstract: Accurate and efficient multivariate time series (MTS) analysis is increasingly critical for a wide range of intelligent applications. Within this realm, Transformers have emerged as the predominant architecture due to their strong ability to capture pairwise dependencies. However, Transformer-based models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment in long-term and lar",
            "url": "https://arxiv.org/abs/2601.05527",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-f69ad819",
            "type": "article",
            "title": "Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts",
            "summary": "arXiv:2601.05537v1 Announce Type: new Abstract: Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) ",
            "url": "https://arxiv.org/abs/2601.05537",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-c5b7ce34",
            "type": "article",
            "title": "Enhancing Foundation Models in Transaction Understanding with LLM-based Sentence Embeddings",
            "summary": "arXiv:2601.05271v1 Announce Type: new Abstract: The ubiquity of payment networks generates vast transactional data encoding rich consumer and merchant behavioral patterns. Recent foundation models for transaction analysis process tabular data sequentially but rely on index-based representations for categorical merchant fields, causing substantial semantic information loss by converting rich textual data into discrete tokens. While Large Language Models (LLMs) can address this limitation through ",
            "url": "https://arxiv.org/abs/2601.05271",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-b55d27ff",
            "type": "article",
            "title": "The Table of Media Bias Elements: A sentence-level taxonomy of media bias types and propaganda techniques",
            "summary": "arXiv:2601.05358v1 Announce Type: new Abstract: Public debates about \"left-\" or \"right-wing\" news overlook the fact that bias is usually conveyed by concrete linguistic manoeuvres that transcend any single political spectrum. We therefore shift the focus from where an outlet allegedly stands to how partiality is expressed in individual sentences. Drawing on 26,464 sentences collected from newsroom corpora, user submissions and our own browsing, we iteratively combine close-reading, interdiscipli",
            "url": "https://arxiv.org/abs/2601.05358",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-873eb473",
            "type": "article",
            "title": "Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models",
            "summary": "arXiv:2601.05366v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chi",
            "url": "https://arxiv.org/abs/2601.05366",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-fe12d86d",
            "type": "article",
            "title": "Same Claim, Different Judgment: Benchmarking Scenario-Induced Bias in Multilingual Financial Misinformation Detection",
            "summary": "arXiv:2601.05403v1 Announce Type: new Abstract: Large language models (LLMs) have been widely applied across various domains of finance. Since their training data are largely derived from human-authored corpora, LLMs may inherit a range of human biases. Behavioral biases can lead to instability and uncertainty in decision-making, particularly when processing financial information. However, existing research on LLM bias has mainly focused on direct questioning or simplified, general-purpose setti",
            "url": "https://arxiv.org/abs/2601.05403",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-d43f2e3d",
            "type": "article",
            "title": "Glitter: Visualizing Lexical Surprisal for Readability in Administrative Texts",
            "summary": "arXiv:2601.05411v1 Announce Type: new Abstract: This work investigates how measuring information entropy of text can be used to estimate its readability. We propose a visualization framework that can be used to approximate information entropy of text using multiple language models and visualize the result. The end goal is to use this method to estimate and improve readability and clarity of administrative or bureaucratic texts. Our toolset is available as a libre software on https://github.com/u",
            "url": "https://arxiv.org/abs/2601.05411",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-855d59f3",
            "type": "article",
            "title": "Large Language Models Are Bad Dice Players: LLMs Struggle to Generate Random Numbers from Statistical Distributions",
            "summary": "arXiv:2601.05414v1 Announce Type: new Abstract: As large language models (LLMs) transition from chat interfaces to integral components of stochastic pipelines across domains like educational assessment and synthetic data construction, the ability to faithfully sample from specified probability distributions has become a functional requirement rather than a theoretical curiosity. We present the first large-scale, statistically powered audit of native probabilistic sampling in frontier LLMs, bench",
            "url": "https://arxiv.org/abs/2601.05414",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-c4ecc2be",
            "type": "article",
            "title": "Tracing Moral Foundations in Large Language Models",
            "summary": "arXiv:2601.05437v1 Announce Type: new Abstract: Large language models (LLMs) often produce human-like moral judgments, but it is unclear whether this reflects an internal conceptual structure or superficial ``moral mimicry.'' Using Moral Foundations Theory (MFT) as an analytic framework, we study how moral foundations are encoded, organized, and expressed within two instruction-tuned LLMs: Llama-3.1-8B-Instruct and Qwen2.5-7B-Instruct. We employ a multi-level approach combining (i) layer-wise an",
            "url": "https://arxiv.org/abs/2601.05437",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-422d26d6",
            "type": "article",
            "title": "Do LLMs Need Inherent Reasoning Before Reinforcement Learning? A Study in Korean Self-Correction",
            "summary": "arXiv:2601.05459v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate strong reasoning and self-correction abilities in high-resource languages like English, but their performance remains limited in low-resource languages such as Korean. In this study, we investigate whether reinforcement learning (RL) can enhance Korean reasoning abilities to a degree comparable to English. Our findings reveal that RL alone yields limited improvements when applied to models lacking inherent K",
            "url": "https://arxiv.org/abs/2601.05459",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-47325ff7",
            "type": "article",
            "title": "Towards Valid Student Simulation with Large Language Models",
            "summary": "arXiv:2601.05473v1 Announce Type: new Abstract: This paper presents a conceptual and methodological framework for large language model (LLM) based student simulation in educational settings. The authors identify a core failure mode, termed the \"competence paradox\" in which broadly capable LLMs are asked to emulate partially knowledgeable learners, leading to unrealistic error patterns and learning dynamics. To address this, the paper reframes student simulation as a constrained generation proble",
            "url": "https://arxiv.org/abs/2601.05473",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e06c6bc4",
            "type": "article",
            "title": "The Facade of Truth: Uncovering and Mitigating LLM Susceptibility to Deceptive Evidence",
            "summary": "arXiv:2601.05478v1 Announce Type: new Abstract: To reliably assist human decision-making, LLMs must maintain factual internal beliefs against misleading injections. While current models resist explicit misinformation, we uncover a fundamental vulnerability to sophisticated, hard-to-falsify evidence. To systematically probe this weakness, we introduce MisBelief, a framework that generates misleading evidence via collaborative, multi-round interactions among multi-role LLMs. This process mimics su",
            "url": "https://arxiv.org/abs/2601.05478",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-bf049c68",
            "type": "article",
            "title": "MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards",
            "summary": "arXiv:2601.05488v1 Announce Type: new Abstract: Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that ",
            "url": "https://arxiv.org/abs/2601.05488",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3e0969b1",
            "type": "article",
            "title": "FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse",
            "summary": "arXiv:2601.05505v1 Announce Type: new Abstract: The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly ",
            "url": "https://arxiv.org/abs/2601.05505",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e79d776a",
            "type": "article",
            "title": "CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems",
            "summary": "arXiv:2601.05520v1 Announce Type: new Abstract: Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \\textbf{CHisAgent}, a multi-agent LLM framework for hist",
            "url": "https://arxiv.org/abs/2601.05520",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-0ddeacbb",
            "type": "article",
            "title": "Double: Breaking the Acceleration Limit via Double Retrieval Speculative Parallelism",
            "summary": "arXiv:2601.05524v1 Announce Type: new Abstract: Parallel Speculative Decoding (PSD) accelerates traditional Speculative Decoding (SD) by overlapping draft generation with verification. However, it remains hampered by two fundamental challenges: (1) a theoretical speedup ceiling dictated by the speed ratio between the draft and target models, and (2) high computational waste and pipeline stall due to mid-sequence token rejections of early errors. To address these limitations, we introduce \\textsc",
            "url": "https://arxiv.org/abs/2601.05524",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-02abe0dd",
            "type": "article",
            "title": "Closing the Modality Reasoning Gap for Speech Large Language Models",
            "summary": "arXiv:2601.05543v1 Announce Type: new Abstract: Although speech large language models have achieved notable progress, a substantial modality reasoning gap remains: their reasoning performance on speech inputs is markedly weaker than on text. This gap could be associated with representational drift across Transformer layers and behavior deviations in long-chain reasoning. To address this issue, we introduce TARS, a reinforcement-learning framework that aligns text-conditioned and speech-condition",
            "url": "https://arxiv.org/abs/2601.05543",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3019577c",
            "type": "article",
            "title": "Can Large Language Models Differentiate Harmful from Argumentative Essays? Steps Toward Ethical Essay Scoring",
            "summary": "arXiv:2601.05545v1 Announce Type: new Abstract: This study addresses critical gaps in Automated Essay Scoring (AES) systems and Large Language Models (LLMs) with regard to their ability to effectively identify and score harmful essays. Despite advancements in AES technology, current models often overlook ethically and morally problematic elements within essays, erroneously assigning high scores to essays that may propagate harmful opinions. In this study, we introduce the Harmful Essay Detection",
            "url": "https://arxiv.org/abs/2601.05545",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-aad9cf5e",
            "type": "article",
            "title": "Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation",
            "summary": "arXiv:2601.05548v1 Announce Type: new Abstract: In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not on",
            "url": "https://arxiv.org/abs/2601.05548",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-59b71ca7",
            "type": "article",
            "title": "ReasonAny: Incorporating Reasoning Capability to Any Model via Simple and Effective Model Merging",
            "summary": "arXiv:2601.05560v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) with long chain-of-thought reasoning have recently achieved remarkable success. Yet, equipping domain-specialized models with such reasoning capabilities, referred to as \"Reasoning + X\", remains a significant challenge. While model merging offers a promising training-free solution, existing methods often suffer from a destructive performance collapse: existing methods tend to both weaken reasoning depth and compromise ",
            "url": "https://arxiv.org/abs/2601.05560",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3ece35d7",
            "type": "article",
            "title": "Can large language models interpret unstructured chat data on dynamic group decision-making processes? Evidence on joint destination choice",
            "summary": "arXiv:2601.05582v1 Announce Type: new Abstract: Social activities result from complex joint activity-travel decisions between group members. While observing the decision-making process of these activities is difficult via traditional travel surveys, the advent of new types of data, such as unstructured chat data, can help shed some light on these complex processes. However, interpreting these decision-making processes requires inferring both explicit and implicit factors. This typically involves",
            "url": "https://arxiv.org/abs/2601.05582",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-2f19a554",
            "type": "article",
            "title": "ACR: Adaptive Context Refactoring via Context Refactoring Operators for Multi-Turn Dialogue",
            "summary": "arXiv:2601.05589v1 Announce Type: new Abstract: Large Language Models (LLMs) have shown remarkable performance in multi-turn dialogue. However, in multi-turn dialogue, models still struggle to stay aligned with what has been established earlier, follow dependencies across many turns, and avoid drifting into incorrect facts as the interaction grows longer. Existing approaches primarily focus on extending the context window, introducing external memory, or applying context compression, yet these m",
            "url": "https://arxiv.org/abs/2601.05589",
            "source": "arxiv",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-423ae0f6",
            "type": "article",
            "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
            "summary": "",
            "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
            "source": "blogs",
            "date": "2026-01-05",
            "trendingScore": 50
        },
        {
            "id": "article-650e8a5e",
            "type": "article",
            "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
            "summary": "",
            "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
            "source": "blogs",
            "date": "2026-01-05",
            "trendingScore": 50
        },
        {
            "id": "article-0ba59559",
            "type": "article",
            "title": "LLMs contain a LOT of parameters. But what\u2019s a parameter?",
            "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. I am writing this because one of my editors woke up in the middle of the night and scribbled on a bedside notepad: \u201cWhat is a&#8230;",
            "url": "https://www.technologyreview.com/2026/01/07/1130795/what-even-is-a-parameter/",
            "source": "blogs",
            "date": "2026-01-07",
            "trendingScore": 50
        },
        {
            "id": "article-f2318d54",
            "type": "article",
            "title": "Why AI predictions are so hard",
            "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. Sometimes AI feels like a niche topic to write about, but then the holidays happen, and I hear relatives of all ages talking about cases of chatbot-induced psychosis, blaming rising electricity prices&#8230;",
            "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
            "source": "blogs",
            "date": "2026-01-06",
            "trendingScore": 50
        },
        {
            "id": "article-8bdc2f5a",
            "type": "article",
            "title": "What\u2019s next for AI in 2026",
            "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In an industry in constant flux, sticking your neck out to predict what\u2019s coming next may seem reckless. (AI bubble? What AI bubble?) But for the&#8230;",
            "url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/",
            "source": "blogs",
            "date": "2026-01-05",
            "trendingScore": 50
        },
        {
            "id": "article-36e9e7eb",
            "type": "article",
            "title": "AI in RollerCoaster Tycoon",
            "summary": "",
            "url": "https://labs.ramp.com/rct",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-ff371ae0",
            "type": "article",
            "title": "Are the YouTube channel Courts and Crimes's shorts AI-generated deep fakes?",
            "summary": "",
            "url": "https://skeptics.stackexchange.com/questions/60423/are-the-youtube-channel-courts-crimess-shorts-ai-generated-deep-fakes",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-a1210e6a",
            "type": "article",
            "title": "Show HN: OpenAI FM \u2013 Zero-setup AI voice tool(Inspired by repo)",
            "summary": "",
            "url": "https://openai-fm.org/",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-d3786b5c",
            "type": "article",
            "title": "Show HN: AgentWatch \u2013 A terminal dashboard for monitoring AI Agent costs",
            "summary": "",
            "url": "https://github.com/Tarunjit45/agentwatch",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-95c67fee",
            "type": "article",
            "title": "Show HN: Remember Me AI (FULL RELEASE) \u2013 40x cost reduction in AI memory systems",
            "summary": "",
            "url": "https://github.com/merchantmoh-debug/Remember-Me-AI",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3d9fad49",
            "type": "article",
            "title": "Pixwit.ai is an AI-powered video creation platform",
            "summary": "",
            "url": "https://pixwit.ai",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-257badc6",
            "type": "article",
            "title": "Ask HN: Has anyone built payment flows inside AI voice calls?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46584015",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-401d14bf",
            "type": "article",
            "title": "Show HN: Pointa \u2013 Point-and-click annotations for AI coding agents (open source)",
            "summary": "",
            "url": "https://www.pointa.dev/",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-025db33f",
            "type": "article",
            "title": "Show HN: App Logo AI \u2013 Your generated application logo",
            "summary": "",
            "url": "https://applogoai.com/",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-554c53ba",
            "type": "article",
            "title": "Everybody's Got a Claim",
            "summary": "",
            "url": "https://ipcopilot.ai/2026/01/03/everybodys-got-a-claim/",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-2257c18c",
            "type": "article",
            "title": "Show HN: AI Cleaner\uff1aPhone Cleaner and Storage Analyzer App",
            "summary": "",
            "url": "https://ai-cleaner.net/",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-6172762c",
            "type": "article",
            "title": "Ask HN: How to automate aesthetic photo cropping? (CV/AI)",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46583569",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-88849612",
            "type": "article",
            "title": "Show HN: The Thiele Machine \u2013 Coq-Verified Computational Model Beyond Turing",
            "summary": "",
            "url": "https://github.com/sethirus/The-Thiele-Machine",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-490753f2",
            "type": "article",
            "title": "Critical Analysis of Air Up's Scientific Marketing Claims",
            "summary": "",
            "url": "https://zenodo.org/records/18197315",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-e7aac3fb",
            "type": "article",
            "title": "AI models were given four weeks of therapy: the results worried researchers",
            "summary": "",
            "url": "https://www.nature.com/articles/d41586-025-04112-2",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-5c41942f",
            "type": "article",
            "title": "Show HN: Neurop Forge \u2013 AI executes verified blocks instead of writing code",
            "summary": "",
            "url": "https://github.com/Louw115/neurop-forge",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-ff393e73",
            "type": "article",
            "title": "Show HN: Personal news curator running 24/7 on a Raspberry Pi 4 with local LLM",
            "summary": "",
            "url": "https://life-of-utkarsh.medium.com/pushing-the-limits-running-local-llms-and-a-24-7-personal-news-curator-on-4gb-of-ram-c55f9498bf3c",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-695cc9ec",
            "type": "article",
            "title": "Show HN: `tc` like `wc` but for LLM tokens",
            "summary": "",
            "url": "https://github.com/jamierpond/tokencount",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-cd31e8ae",
            "type": "article",
            "title": "Training an LLM to Play Diplomacy with RL",
            "summary": "",
            "url": "https://www.benglickenhaus.com/blog/diplomacy_rl_part_1",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-3abfec7e",
            "type": "article",
            "title": "Show HN: An LLM-optimized programming language",
            "summary": "",
            "url": "https://github.com/ImJasonH/ImJasonH/blob/main/articles/llm-programming-language.md",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 52
        },
        {
            "id": "article-30b1d09e",
            "type": "article",
            "title": "Show HN: What if AI agents had Zodiac personalities?",
            "summary": "",
            "url": "https://github.com/baturyilmaz/what-if-ai-agents-had-zodiac-personalities",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 52
        },
        {
            "id": "article-b3ccf3c5",
            "type": "article",
            "title": "Ask HN: Cursor (LLM) Costs",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46581528",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-ba69e031",
            "type": "article",
            "title": "Embrace your lack: on Pluribus and LLMs",
            "summary": "",
            "url": "https://hollisrobbinsanecdotal.substack.com/p/embrace-your-lack",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-6bac011e",
            "type": "article",
            "title": "Git considers SHA-256, Rust, LLMs, and more (2025)",
            "summary": "",
            "url": "https://lwn.net/Articles/1042172/",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-a854b65d",
            "type": "article",
            "title": "LLMs \u2013 Part 2: Order Matters \u2013 Positional Encoding",
            "summary": "",
            "url": "https://vasupasupuleti.substack.com/p/llms-part-2-order-matters-positional",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-e26f9d01",
            "type": "article",
            "title": "LLMs \u2013 Part 1: Tokenization and Embeddings",
            "summary": "",
            "url": "https://vasupasupuleti.substack.com/p/llms-part-1-tokenization-and-embeddings",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-f4098ff2",
            "type": "article",
            "title": "Gh-Dash \u2013 GitHub PR Dashboard for Claude Code",
            "summary": "",
            "url": "https://github.com/jakozloski/claude-code-gh-dash",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-80d6f0a2",
            "type": "article",
            "title": "Barista: Serving up fresh stats for your Claude Code sessions",
            "summary": "",
            "url": "https://github.com/pstuart/pstuart/tree/main/barista",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-c26dcda6",
            "type": "article",
            "title": "Show HN: Yuanzai World \u2013 LLM RPGs with branching world-lines",
            "summary": "",
            "url": "https://www.yuanzai.world/",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 53
        },
        {
            "id": "article-fe031f22",
            "type": "article",
            "title": "MIT Non-AI License",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46562867",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 51
        },
        {
            "id": "article-33084c11",
            "type": "article",
            "title": "Ask HN: Which career is most future-secure in the AI era?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46524710",
            "source": "hackernews",
            "date": "2026-01-07",
            "trendingScore": 50
        },
        {
            "id": "article-a84ab669",
            "type": "article",
            "title": "Why machine learning fails at prioritization problems",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46521799",
            "source": "hackernews",
            "date": "2026-01-07",
            "trendingScore": 50
        },
        {
            "id": "article-d7fb0d6f",
            "type": "article",
            "title": "Show HN: Symbolic Circuit Distillation: prove program to LLM circuit equivalence",
            "summary": "",
            "url": "https://github.com/neelsomani/symbolic-circuit-distillation",
            "source": "hackernews",
            "date": "2026-01-06",
            "trendingScore": 51
        },
        {
            "id": "article-9165c26c",
            "type": "article",
            "title": "\"I love you\" \"too\": LLM Attention Explained",
            "summary": "",
            "url": "https://kaamvaam.com/machine-learning-ai/llm-attention-explanation/",
            "source": "hackernews",
            "date": "2026-01-06",
            "trendingScore": 50
        },
        {
            "id": "article-56419b49",
            "type": "article",
            "title": "Week 5 in Data Science: Image recognition neural network with 90% accuracy",
            "summary": "",
            "url": "https://igorstechnoclub.com/deep-learning-transfer-learning/",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 50
        },
        {
            "id": "article-3fa69ddb",
            "type": "article",
            "title": "One pixel attack for fooling deep neural networks",
            "summary": "",
            "url": "https://arxiv.org/abs/1710.08864",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 50
        },
        {
            "id": "article-ce5db6d2",
            "type": "article",
            "title": "Ask HN: What if the AI scaling plateau is just a \"false dip\"?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46552562",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "article-5ac75435",
            "type": "article",
            "title": "Phenomenon of \"Grokking\" in Neural Networks",
            "summary": "",
            "url": "https://twitter.com/godofprompt/status/2008458571928002948",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "article-4297fa33",
            "type": "article",
            "title": "How to Fool a Neural Network",
            "summary": "",
            "url": "https://briefer.cloud/blog/posts/fooling-neural-networks/",
            "source": "hackernews",
            "date": "2026-01-08",
            "trendingScore": 50
        },
        {
            "id": "article-8bfd8eaf",
            "type": "article",
            "title": "Show HN: ScrollMind \u2013 A visual engineering guide to AI that fits in your feed",
            "summary": "",
            "url": "https://scrollmind.ai",
            "source": "hackernews",
            "date": "2026-01-06",
            "trendingScore": 50
        },
        {
            "id": "article-5b17ee09",
            "type": "article",
            "title": "Practically Utilizing Neural Networks in CPU-Based Production Rendering (JCGT)",
            "summary": "",
            "url": "https://jcgt.org/published/0015/01/01/",
            "source": "hackernews",
            "date": "2026-01-06",
            "trendingScore": 50
        },
        {
            "id": "article-f38bf4fb",
            "type": "article",
            "title": "Training a Hamiltonian Neural Network",
            "summary": "",
            "url": "https://ritog.github.io/posts/hamiltonian_nn/",
            "source": "hackernews",
            "date": "2026-01-06",
            "trendingScore": 50
        },
        {
            "id": "article-949fbb3d",
            "type": "article",
            "title": "Visualizing neural network inference in 3D with WebGL and ONNX",
            "summary": "",
            "url": "https://www.erikjs.com/blog/building-neural-network-visualizer",
            "source": "hackernews",
            "date": "2026-01-05",
            "trendingScore": 50
        },
        {
            "id": "article-f8751a91",
            "type": "article",
            "title": "The Definitive Guide to Claude Code",
            "summary": "",
            "url": "https://jpcaparas.medium.com/the-definitive-guide-to-claude-code-from-first-install-to-production-workflows-6d37a6d33e40",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-031eb57c",
            "type": "article",
            "title": "Letting Claude Play Text Adventures",
            "summary": "",
            "url": "https://borretti.me/article/letting-claude-play-text-adventures",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-72e27d8e",
            "type": "article",
            "title": "Ask HN: Claude Code Degradation",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46583878",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-adfbc2de",
            "type": "article",
            "title": "Advancing Claude in healthcare and the life sciences",
            "summary": "",
            "url": "https://www.anthropic.com/news/healthcare-life-sciences",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 50
        },
        {
            "id": "article-8e1ab35b",
            "type": "article",
            "title": "Anthropic bans xAI from using Claude in Cursor",
            "summary": "",
            "url": "https://xcancel.com/kyliebytes/status/2009686466746822731",
            "source": "hackernews",
            "date": "2026-01-12",
            "trendingScore": 51
        },
        {
            "id": "article-70a497e3",
            "type": "article",
            "title": "Show HN: I built Sonars in 3 weeks to see if AI coding is useful for my company",
            "summary": "",
            "url": "https://sonars.dev",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-5673e1f6",
            "type": "article",
            "title": "Claude Coding A Blog Pipeline",
            "summary": "",
            "url": "https://clabs.org/blog/ClaudeCodingABlogPipeline",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-7cec3a68",
            "type": "article",
            "title": "How I Used Claude Code Subagents to Create an 18-Month Roadmap in 2 Hours",
            "summary": "",
            "url": "https://zachwills.net/how-i-built-an-18-month-ai-roadmap-in-2-hours/",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-3c7cbb07",
            "type": "article",
            "title": "Show HN: Pi-coding-agent: Emacs front end for AI-assisted coding",
            "summary": "",
            "url": "https://github.com/dnouri/pi-coding-agent",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-965bcfb1",
            "type": "article",
            "title": "guys why does armenian completely break Claude",
            "summary": "",
            "url": "https://twitter.com/dyushag/status/1993143599286886525",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 59
        },
        {
            "id": "article-92e28c98",
            "type": "article",
            "title": "Show HN: Worldview, persistent strategic context for Claude Code",
            "summary": "",
            "url": "https://www.extremeclarity.ai/worldview",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-350f3e2b",
            "type": "article",
            "title": "Turn off annoying progress messages in Claude Code?",
            "summary": "",
            "url": "https://github.com/anthropics/claude-code/issues/6814",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-77b059e0",
            "type": "article",
            "title": "Anthropic: Developing a Claude Code competitor using Claude Code is banned",
            "summary": "",
            "url": "https://twitter.com/SIGKITTEN/status/2009697031422652461",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 77
        },
        {
            "id": "article-83a6397a",
            "type": "article",
            "title": "Claude Code Orchestrator \u2013 Parallel AI Development with Multiple Claude Sessions",
            "summary": "",
            "url": "https://github.com/reshashi/claude-orchestrator",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-7ff7eb41",
            "type": "article",
            "title": "Ask HN: How are you balancing AI coding tools with junior developers growth?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46577832",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-e5b30aec",
            "type": "article",
            "title": "Show HN: IDE that works with Claude Code and Antigravity subscription",
            "summary": "",
            "url": "https://nucleus.terramind.com",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-abc18515",
            "type": "article",
            "title": "Why Gemini 3 Flash is the model OpenAI is afraid of",
            "summary": "",
            "url": "https://blog.brokk.ai/why-gemini-3-flash-is-the-model-openai-is-afraid-of/",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-7e0ffec3",
            "type": "article",
            "title": "Show HN: I auto-generate alt text using Gemini 3 Flash",
            "summary": "",
            "url": "https://sarthakmishra.com/blog/automating-image-alt-text",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-720b10fd",
            "type": "article",
            "title": "How to Disable Gemini on Android, Gmail, Chrome, Photos, & Google Apps",
            "summary": "",
            "url": "https://tuta.com/blog/how-to-disable-gemini-on-android",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-d2219d5c",
            "type": "article",
            "title": "Non-terminating response loop in Gemini Chat interface",
            "summary": "",
            "url": "https://gemini.google.com/share/03b40438aaa0",
            "source": "hackernews",
            "date": "2026-01-11",
            "trendingScore": 50
        },
        {
            "id": "article-72021b91",
            "type": "article",
            "title": "Show HN: I used Claude Code to discover connections between 100 books",
            "summary": "",
            "url": "https://trails.pieterma.es/",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 97
        },
        {
            "id": "article-1d22a634",
            "type": "article",
            "title": "Show HN: Sigma Runtime \u2013 model-agnostic identity control for LLMs",
            "summary": "",
            "url": "https://github.com/sigmastratum/documentation/blob/bf473712ada5a9204a65434e46860b03d5fbf8fe/sigma-runtime/SR-EI-0412/README.md",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 50
        },
        {
            "id": "article-5e35ca79",
            "type": "article",
            "title": "Gemini: I can't help with that. Try asking something else about this video",
            "summary": "",
            "url": "https://www.youtube.com/watch?v=g-QyFIu8Zbc",
            "source": "hackernews",
            "date": "2026-01-10",
            "trendingScore": 50
        },
        {
            "id": "article-5dc1434a",
            "type": "article",
            "title": "Show HN: I built a tool to create LLM Tier Lists based on real tasks",
            "summary": "",
            "url": "https://promt.oshn-ai.com/community/004471c6-b508-4ae8-a7cd-20ce6ab4ad65",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "article-bbcb5282",
            "type": "article",
            "title": "Show HN: DocuFlow \u2013 open-source event-driven AI invoice ingestion pipeline",
            "summary": "",
            "url": "https://github.com/Shashank0701-byte/docuflow",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "article-f074af5e",
            "type": "article",
            "title": "Initial Thoughts on Gmail with Gemini?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46557053",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "article-0119ed65",
            "type": "article",
            "title": "Show HN: PromptStash \u2013 Save and Reuse AI Prompts Across ChatGPT, Claude, Gemini",
            "summary": "",
            "url": "https://chromewebstore.google.com/detail/promptstash-ai-prompt-man/ocgkponbnolpgobllplcamfobolbjbcj",
            "source": "hackernews",
            "date": "2026-01-09",
            "trendingScore": 50
        },
        {
            "id": "topic-large-language-models",
            "type": "topic",
            "title": "Large Language Models",
            "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
            "connectionCount": 53
        },
        {
            "id": "topic-ai-agents",
            "type": "topic",
            "title": "AI Agents",
            "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
            "connectionCount": 15
        },
        {
            "id": "topic-rag",
            "type": "topic",
            "title": "RAG",
            "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
            "connectionCount": 15
        },
        {
            "id": "topic-nlp",
            "type": "topic",
            "title": "NLP",
            "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
            "connectionCount": 37
        },
        {
            "id": "topic-ai-safety",
            "type": "topic",
            "title": "AI Safety",
            "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
            "connectionCount": 5
        },
        {
            "id": "topic-reinforcement-learning",
            "type": "topic",
            "title": "Reinforcement Learning",
            "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
            "connectionCount": 24
        },
        {
            "id": "topic-multimodal-ai",
            "type": "topic",
            "title": "Multimodal AI",
            "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
            "connectionCount": 1
        },
        {
            "id": "topic-ai-reasoning",
            "type": "topic",
            "title": "AI Reasoning",
            "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
            "connectionCount": 16
        },
        {
            "id": "topic-prompt-engineering",
            "type": "topic",
            "title": "Prompt Engineering",
            "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
            "connectionCount": 4
        },
        {
            "id": "topic-computer-vision",
            "type": "topic",
            "title": "Computer Vision",
            "summary": "AI systems for understanding and processing visual information from images and video.",
            "connectionCount": 4
        },
        {
            "id": "topic-fine-tuning",
            "type": "topic",
            "title": "Fine-tuning",
            "summary": "Adapting pre-trained models to specific tasks or domains.",
            "connectionCount": 2
        },
        {
            "id": "topic-model-efficiency",
            "type": "topic",
            "title": "Model Efficiency",
            "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
            "connectionCount": 6
        },
        {
            "id": "org-meta",
            "type": "organization",
            "title": "Meta",
            "summary": "Meta - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-xai",
            "type": "organization",
            "title": "xAI",
            "summary": "xAI - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-cohere",
            "type": "organization",
            "title": "Cohere",
            "summary": "Cohere - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-nvidia",
            "type": "organization",
            "title": "NVIDIA",
            "summary": "NVIDIA - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-openai",
            "type": "organization",
            "title": "OpenAI",
            "summary": "OpenAI - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-anthropic",
            "type": "organization",
            "title": "Anthropic",
            "summary": "Anthropic - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-google",
            "type": "organization",
            "title": "Google",
            "summary": "Google - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "model-llama",
            "type": "model",
            "title": "Llama",
            "summary": "Llama AI model.",
            "connectionCount": 1
        },
        {
            "id": "model-claude",
            "type": "model",
            "title": "Claude",
            "summary": "Claude AI model.",
            "connectionCount": 17
        },
        {
            "id": "model-grok",
            "type": "model",
            "title": "Grok",
            "summary": "Grok AI model.",
            "connectionCount": 1
        },
        {
            "id": "model-gemini",
            "type": "model",
            "title": "Gemini",
            "summary": "Gemini AI model.",
            "connectionCount": 7
        },
        {
            "id": "model-chatgpt",
            "type": "model",
            "title": "ChatGPT",
            "summary": "ChatGPT AI model.",
            "connectionCount": 1
        }
    ],
    "edges": [
        {
            "source": "article-37c8c6d9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-37c8c6d9",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-37c8c6d9",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-4895640b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4895640b",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-10b50d27",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-10b50d27",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-10b50d27",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6070e3fc",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-6070e3fc",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1d780a59",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1d780a59",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-1d780a59",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1d780a59",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d64e072",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d64e072",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d64e072",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-872ddb50",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-872ddb50",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-872ddb50",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-872ddb50",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-caffb91a",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-caffb91a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-caffb91a",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-caffb91a",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-caffb91a",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ada945d8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ada945d8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-ada945d8",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-ada945d8",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ada945d8",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e0a07ee7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e0a07ee7",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e0a07ee7",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b9721c72",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b9721c72",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-b9721c72",
            "target": "org-xai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e6c8f2af",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e6c8f2af",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-f1c2f2b7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f1c2f2b7",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f1c2f2b7",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-796fa6df",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-796fa6df",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-796fa6df",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-006b7823",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-006b7823",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-006b7823",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-6da6f35d",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-6da6f35d",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-31c37dbb",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-31c37dbb",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-31c37dbb",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-31c37dbb",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-b381c6f2",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b381c6f2",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-b381c6f2",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-b381c6f2",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-d21b4d4f",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f9758e6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f9758e6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f9758e6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f9758e6",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1cf85eaa",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-1cf85eaa",
            "target": "org-cohere",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f2d6cbd8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f2d6cbd8",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-f2d6cbd8",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fed3f4",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e06e568e",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0b22b5a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0b22b5a",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0b22b5a",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f44bc866",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f44bc866",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-f44bc866",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-da7f5df8",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-da7f5df8",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-5867e175",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5867e175",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5867e175",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-06f63276",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-ba3cc0f2",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ba3cc0f2",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ba3cc0f2",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c598cd65",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c598cd65",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c598cd65",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c598cd65",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc38f0d2",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc38f0d2",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc38f0d2",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-dc38f0d2",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-bfec6874",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-bfec6874",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-bfec6874",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d1b743b8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f69ad819",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-f69ad819",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c5b7ce34",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c5b7ce34",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-b55d27ff",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-873eb473",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-873eb473",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe12d86d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe12d86d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fe12d86d",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d43f2e3d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d43f2e3d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-855d59f3",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-855d59f3",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c4ecc2be",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c4ecc2be",
            "target": "model-llama",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-422d26d6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-422d26d6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-422d26d6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-47325ff7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-47325ff7",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-47325ff7",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e06c6bc4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e06c6bc4",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf049c68",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf049c68",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf049c68",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-bf049c68",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-3e0969b1",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-3e0969b1",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-3e0969b1",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-3e0969b1",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e79d776a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e79d776a",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e79d776a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-e79d776a",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e79d776a",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-0ddeacbb",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-0ddeacbb",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-0ddeacbb",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-02abe0dd",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-02abe0dd",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-02abe0dd",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-02abe0dd",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-3019577c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-3019577c",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-aad9cf5e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-59b71ca7",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-3ece35d7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f19a554",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f19a554",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-2f19a554",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-423ae0f6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-423ae0f6",
            "target": "org-nvidia",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0ba59559",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-0ba59559",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff371ae0",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a1210e6a",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-d3786b5c",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-3d9fad49",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-401d14bf",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-025db33f",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-2257c18c",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-2257c18c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-ff393e73",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-695cc9ec",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-cd31e8ae",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-cd31e8ae",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-3abfec7e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-30b1d09e",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-b3ccf3c5",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ba69e031",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6bac011e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-a854b65d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e26f9d01",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f4098ff2",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-80d6f0a2",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c26dcda6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c26dcda6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d7fb0d6f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d7fb0d6f",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-9165c26c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-56419b49",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-5ac75435",
            "target": "model-grok",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8bfd8eaf",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f8751a91",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-031eb57c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-031eb57c",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-72e27d8e",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-adfbc2de",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8e1ab35b",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8e1ab35b",
            "target": "org-xai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8e1ab35b",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5673e1f6",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-7cec3a68",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7cec3a68",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-3c7cbb07",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-965bcfb1",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-92e28c98",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-92e28c98",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-92e28c98",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-350f3e2b",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-77b059e0",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-77b059e0",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-83a6397a",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e5b30aec",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-abc18515",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-abc18515",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-7e0ffec3",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-7e0ffec3",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-720b10fd",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-720b10fd",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-d2219d5c",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-72021b91",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1d22a634",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5e35ca79",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-5e35ca79",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-5dc1434a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f074af5e",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0119ed65",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-0119ed65",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0119ed65",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0119ed65",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-reasoning",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-agents",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-rag",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-multimodal-ai",
            "target": "topic-computer-vision",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-agents",
            "target": "topic-prompt-engineering",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-model-efficiency",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-safety",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        }
    ]
};

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIChronicleData;
}
