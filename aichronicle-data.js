// ================================================
// THE AI CHRONICLE - Knowledge Graph Data
// Auto-generated and updated daily via GitHub Actions
// Last updated: 2026-02-10
// ================================================

const AIChronicleData = {
    "metadata": {
        "lastUpdated": "2026-02-10T07:02:16.753380Z",
        "totalArticles": 138,
        "totalNodes": 160,
        "totalEdges": 229,
        "dateRange": {
            "start": "2026-02-03",
            "end": "2026-02-10"
        }
    },
    "nodes": [
        {
            "id": "article-4e2348af",
            "type": "article",
            "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
            "summary": "arXiv:2602.07032v1 Announce Type: new Abstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually co",
            "url": "https://arxiv.org/abs/2602.07032",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-cbe7a7f3",
            "type": "article",
            "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
            "summary": "arXiv:2602.07034v1 Announce Type: new Abstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Exi",
            "url": "https://arxiv.org/abs/2602.07034",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-7da7b9d6",
            "type": "article",
            "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
            "summary": "arXiv:2602.07035v1 Announce Type: new Abstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAct",
            "url": "https://arxiv.org/abs/2602.07035",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-fc694bfa",
            "type": "article",
            "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
            "summary": "arXiv:2602.07040v1 Announce Type: new Abstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to in",
            "url": "https://arxiv.org/abs/2602.07040",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9f4197a3",
            "type": "article",
            "title": "Theory of Space: Can Foundation Models Construct Spatial Beliefs through Active Exploration?",
            "summary": "arXiv:2602.07055v1 Announce Type: new Abstract: Spatial embodied intelligence requires agents to act to acquire information under partial observability. While multimodal foundation models excel at passive perception, their capacity for active, self-directed exploration remains understudied. We propose Theory of Space, defined as an agent's ability to actively acquire information through self-directed, active exploration and to construct, revise, and exploit a spatial belief from sequential, part",
            "url": "https://arxiv.org/abs/2602.07055",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-654cc34f",
            "type": "article",
            "title": "ANCHOR: Branch-Point Data Generation for GUI Agents",
            "summary": "arXiv:2602.07153v1 Announce Type: new Abstract: End-to-end GUI agents for real desktop environments require large amounts of high-quality interaction data, yet collecting human demonstrations is expensive and existing synthetic pipelines often suffer from limited task diversity or noisy, goal-drifting trajectories. We present a trajectory expansion framework Anchor that bootstraps scalable desktop supervision from a small set of verified seed demonstrations. Starting from each seed, we identify ",
            "url": "https://arxiv.org/abs/2602.07153",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-32cefdbb",
            "type": "article",
            "title": "PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents",
            "summary": "arXiv:2602.07187v1 Announce Type: new Abstract: Advanced large language model agents typically adopt self-reflection for improving performance, where agents iteratively analyze past actions to correct errors. However, existing reflective approaches are inherently retrospective: agents act, observe failure, and only then attempt to recover. In this work, we introduce PreFlect, a prospective reflection mechanism that shifts the paradigm from post hoc correction to pre-execution foresight by critic",
            "url": "https://arxiv.org/abs/2602.07187",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-5c5168b9",
            "type": "article",
            "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
            "summary": "arXiv:2602.07238v1 Announce Type: new Abstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-",
            "url": "https://arxiv.org/abs/2602.07238",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f297f39a",
            "type": "article",
            "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
            "summary": "arXiv:2602.07253v1 Announce Type: new Abstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer visio",
            "url": "https://arxiv.org/abs/2602.07253",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e1fdcfbe",
            "type": "article",
            "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
            "summary": "arXiv:2602.07259v1 Announce Type: new Abstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how m",
            "url": "https://arxiv.org/abs/2602.07259",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2ebe3eb0",
            "type": "article",
            "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
            "summary": "arXiv:2602.07267v1 Announce Type: new Abstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completion",
            "url": "https://arxiv.org/abs/2602.07267",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9d4302c9",
            "type": "article",
            "title": "TermiGen: High-Fidelity Environment and Robust Trajectory Synthesis for Terminal Agents",
            "summary": "arXiv:2602.07274v1 Announce Type: new Abstract: Executing complex terminal tasks remains a significant challenge for open-weight LLMs, constrained by two fundamental limitations. First, high-fidelity, executable training environments are scarce: environments synthesized from real-world repositories are not diverse and scalable, while trajectories synthesized by LLMs suffer from hallucinations. Second, standard instruction tuning uses expert trajectories that rarely exhibit simple mistakes common",
            "url": "https://arxiv.org/abs/2602.07274",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f3a26c90",
            "type": "article",
            "title": "Steer2Adapt: Dynamically Composing Steering Vectors Elicits Efficient Adaptation of LLMs",
            "summary": "arXiv:2602.07276v1 Announce Type: new Abstract: Activation steering has emerged as a promising approach for efficiently adapting large language models (LLMs) to downstream behaviors. However, most existing steering methods rely on a single static direction per task or concept, making them inflexible under task variation and inadequate for complex tasks that require multiple coordinated capabilities. To address this limitation, we propose STEER2ADAPT, a lightweight framework that adapts LLMs by c",
            "url": "https://arxiv.org/abs/2602.07276",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-63b5018d",
            "type": "article",
            "title": "Adaptive Scaffolding for Cognitive Engagement in an Intelligent Tutoring System",
            "summary": "arXiv:2602.07308v1 Announce Type: new Abstract: The ICAP framework defines four cognitive engagement levels: Passive, Active, Constructive, and Interactive, where increased cognitive engagement can yield improved learning. However, personalizing learning activities that elicit the optimal level of cognitive engagement remains a key challenge in intelligent tutoring systems (ITS). In this work, we develop and evaluate a system that adaptively scaffolds cognitive engagement by dynamically selectin",
            "url": "https://arxiv.org/abs/2602.07308",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-310c6cc4",
            "type": "article",
            "title": "RAPiD: Real-time Deterministic Trajectory Planning via Diffusion Behavior Priors for Safe and Efficient Autonomous Driving",
            "summary": "arXiv:2602.07339v1 Announce Type: new Abstract: Diffusion-based trajectory planners have demonstrated strong capability for modeling the multimodal nature of human driving behavior, but their reliance on iterative stochastic sampling poses critical challenges for real-time, safety-critical deployment. In this work, we present RAPiD, a deterministic policy extraction framework that distills a pretrained diffusion-based planner into an efficient policy while eliminating diffusion sampling. Using s",
            "url": "https://arxiv.org/abs/2602.07339",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e813294f",
            "type": "article",
            "title": "SupChain-Bench: Benchmarking Large Language Models for Real-World Supply Chain Management",
            "summary": "arXiv:2602.07342v1 Announce Type: new Abstract: Large language models (LLMs) have shown promise in complex reasoning and tool-based decision making, motivating their application to real-world supply chain management. However, supply chain workflows require reliable long-horizon, multi-step orchestration grounded in domain-specific procedures, which remains challenging for current models. To systematically evaluate LLM performance in this setting, we introduce SupChain-Bench, a unified real-world",
            "url": "https://arxiv.org/abs/2602.07342",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f23f74fa",
            "type": "article",
            "title": "W&D:Scaling Parallel Tool Calling for Efficient Deep Research Agents",
            "summary": "arXiv:2602.07359v1 Announce Type: new Abstract: Deep research agents have emerged as powerful tools for automating complex intellectual tasks through multi-step reasoning and web-based information seeking. While recent efforts have successfully enhanced these agents by scaling depth through increasing the number of sequential thinking and tool calls, the potential of scaling width via parallel tool calling remains largely unexplored. In this work, we propose the Wide and Deep research agent, a f",
            "url": "https://arxiv.org/abs/2602.07359",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d10f3bd2",
            "type": "article",
            "title": "NAAMSE: Framework for Evolutionary Security Evaluation of Agents",
            "summary": "arXiv:2602.07391v1 Announce Type: new Abstract: AI agents are increasingly deployed in production, yet their security evaluations remain bottlenecked by manual red-teaming or static benchmarks that fail to model adaptive, multi-turn adversaries. We propose NAAMSE, an evolutionary framework that reframes agent security evaluation as a feedback-driven optimization problem. Our system employs a single autonomous agent that orchestrates a lifecycle of genetic prompt mutation, hierarchical corpus exp",
            "url": "https://arxiv.org/abs/2602.07391",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e5058201",
            "type": "article",
            "title": "VGAS: Value-Guided Action-Chunk Selection for Few-Shot Vision-Language-Action Adaptation",
            "summary": "arXiv:2602.07399v1 Announce Type: new Abstract: Vision--Language--Action (VLA) models bridge multimodal reasoning with physical control, but adapting them to new tasks with scarce demonstrations remains unreliable. While fine-tuned VLA policies often produce semantically plausible trajectories, failures often arise from unresolved geometric ambiguities, where near-miss action candidates lead to divergent execution outcomes under limited supervision. We study few-shot VLA adaptation from a \\emph{",
            "url": "https://arxiv.org/abs/2602.07399",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-72c66faa",
            "type": "article",
            "title": "Progressive Multi-Agent Reasoning for Biological Perturbation Prediction",
            "summary": "arXiv:2602.07408v1 Announce Type: new Abstract: Predicting gene regulation responses to biological perturbations requires reasoning about underlying biological causalities. While large language models (LLMs) show promise for such tasks, they are often overwhelmed by the entangled nature of high-dimensional perturbation results. Moreover, recent works have primarily focused on genetic perturbations in single-cell experiments, leaving bulk-cell chemical perturbations, which is central to drug disc",
            "url": "https://arxiv.org/abs/2602.07408",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-72bc3687",
            "type": "article",
            "title": "Attractor Patch Networks: Reducing Catastrophic Forgetting with Routed Low-Rank Patch Experts",
            "summary": "arXiv:2602.06993v1 Announce Type: new Abstract: Transformers achieve strong language modeling accuracy, yet their position-wise feed-forward networks (FFNs) are dense, globally shared, and typically updated end to end. These properties create two practical tensions. First, dense FFNs spend the same compute on every token regardless of context, and they allocate capacity uniformly even when language exhibits highly clustered context structure. Second, continual learning, in the sense of updating ",
            "url": "https://arxiv.org/abs/2602.06993",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e1dba9bb",
            "type": "article",
            "title": "Neural Sabermetrics with World Model: Play-by-play Predictive Modeling with Large Language Model",
            "summary": "arXiv:2602.07030v1 Announce Type: new Abstract: Classical sabermetrics has profoundly shaped baseball analytics by summarizing long histories of play into compact statistics. While these metrics are invaluable for valuation and retrospective analysis, they do not define a generative model of how baseball games unfold pitch by pitch, leaving most existing approaches limited to single-step prediction or post-hoc analysis. In this work, we present Neural Sabermetrics with World Model, a Large Langu",
            "url": "https://arxiv.org/abs/2602.07030",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-02020214",
            "type": "article",
            "title": "Lagged backward-compatible physics-informed neural networks for unsaturated soil consolidation analysis",
            "summary": "arXiv:2602.07031v1 Announce Type: new Abstract: This study develops a Lagged Backward-Compatible Physics-Informed Neural Network (LBC-PINN) for simulating and inverting one-dimensional unsaturated soil consolidation under long-term loading. To address the challenges of coupled air and water pressure dissipation across multi-scale time domains, the framework integrates logarithmic time segmentation, lagged compatibility loss enforcement, and segment-wise transfer learning. In forward analysis, th",
            "url": "https://arxiv.org/abs/2602.07031",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-87b2eade",
            "type": "article",
            "title": "TransConv-DDPM: Enhanced Diffusion Model for Generating Time-Series Data in Healthcare",
            "summary": "arXiv:2602.07033v1 Announce Type: new Abstract: The lack of real-world data in clinical fields poses a major obstacle in training effective AI models for diagnostic and preventive tools in medicine. Generative AI has shown promise in increasing data volume and enhancing model training, particularly in computer vision and natural language processing (NLP) domains. However, generating physiological time-series data, a common type in medical AI applications, presents unique challenges due to its in",
            "url": "https://arxiv.org/abs/2602.07033",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d6e92594",
            "type": "article",
            "title": "AVERE: Improving Audiovisual Emotion Reasoning with Preference Optimization",
            "summary": "arXiv:2602.07054v1 Announce Type: new Abstract: Emotion understanding is essential for building socially intelligent agents. Although recent multimodal large language models have shown strong performance on this task, two key challenges remain - spurious associations between emotions and irrelevant audiovisual cues, and hallucinations of audiovisual cues driven by text priors in the language model backbone. To quantify and understand these issues, we introduce EmoReAlM, a benchmark designed to e",
            "url": "https://arxiv.org/abs/2602.07054",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-35a61125",
            "type": "article",
            "title": "TACIT: Transformation-Aware Capturing of Implicit Thought",
            "summary": "arXiv:2602.07061v1 Announce Type: new Abstract: We present TACIT (Transformation-Aware Capturing of Implicit Thought), a diffusion-based transformer for interpretable visual reasoning. Unlike language-based reasoning systems, TACIT operates entirely in pixel space using rectified flow, enabling direct visualization of the reasoning process at each inference step. We demonstrate the approach on maze-solving, where the model learns to transform images of unsolved mazes into solutions. Key results ",
            "url": "https://arxiv.org/abs/2602.07061",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-55d18ed3",
            "type": "article",
            "title": "Video-based Music Generation",
            "summary": "arXiv:2602.07063v1 Announce Type: new Abstract: As the volume of video content on the internet grows rapidly, finding a suitable soundtrack remains a significant challenge. This thesis presents EMSYNC (EMotion and SYNChronization), a fast, free, and automatic solution that generates music tailored to the input video, enabling content creators to enhance their productions without composing or licensing music. Our model creates music that is emotionally and rhythmically synchronized with the video",
            "url": "https://arxiv.org/abs/2602.07063",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-462c786d",
            "type": "article",
            "title": "Hybrid Dual-Path Linear Transformations for Efficient Transformer Architectures",
            "summary": "arXiv:2602.07070v1 Announce Type: new Abstract: Standard Transformer architectures rely heavily on dense linear transformations, treating feature projection as a monolithic, full-rank operation. We argue that this formulation is inefficient and lacks the structural inductive bias necessary for distinguishing between local feature preservation and global context integration. To address this, we introduce the Hybrid Dual-Path Linear (HDPL) operator, which decomposes the affine transformation into ",
            "url": "https://arxiv.org/abs/2602.07070",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9af6cac5",
            "type": "article",
            "title": "The Optimal Token Baseline: Variance Reduction for Long-Horizon LLM-RL",
            "summary": "arXiv:2602.07078v1 Announce Type: new Abstract: Reinforcement Learning (RL) for Large Language Models (LLMs) often suffers from training collapse in long-horizon tasks due to exploding gradient variance. To mitigate this, a baseline is commonly introduced for advantage computation; however, traditional value models remain difficult to optimize, and standard group-based baselines overlook sequence heterogeneity. Although classic optimal baseline theory can achieve global variance reduction, it ne",
            "url": "https://arxiv.org/abs/2602.07078",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-5ad74a28",
            "type": "article",
            "title": "Attention-Driven Framework for Non-Rigid Medical Image Registration",
            "summary": "arXiv:2602.07088v1 Announce Type: new Abstract: Deformable medical image registration is a fundamental task in medical image analysis with applications in disease diagnosis, treatment planning, and image-guided interventions. Despite significant advances in deep learning based registration methods, accurately aligning images with large deformations while preserving anatomical plausibility remains a challenging task. In this paper, we propose a novel Attention-Driven Framework for Non-Rigid Medic",
            "url": "https://arxiv.org/abs/2602.07088",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-6af04419",
            "type": "article",
            "title": "Finding Connections: Membership Inference Attacks for the Multi-Table Synthetic Data Setting",
            "summary": "arXiv:2602.07126v1 Announce Type: new Abstract: Synthetic tabular data has gained attention for enabling privacy-preserving data sharing. While substantial progress has been made in single-table synthetic generation where data are modeled at the row or item level, most real-world data exists in relational databases where a user's information spans items across multiple interconnected tables. Recent advances in synthetic relational data generation have emerged to address this complexity, yet rele",
            "url": "https://arxiv.org/abs/2602.07126",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-cfa13284",
            "type": "article",
            "title": "Landscaper: Understanding Loss Landscapes Through Multi-Dimensional Topological Analysis",
            "summary": "arXiv:2602.07135v1 Announce Type: new Abstract: Loss landscapes are a powerful tool for understanding neural network optimization and generalization, yet traditional low-dimensional analyses often miss complex topological features. We present Landscaper, an open-source Python package for arbitrary-dimensional loss landscape analysis. Landscaper combines Hessian-based subspace construction with topological data analysis to reveal geometric structures such as basin hierarchy and connectivity. A ke",
            "url": "https://arxiv.org/abs/2602.07135",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-c3d6fcd7",
            "type": "article",
            "title": "Featured Reproducing Kernel Banach Spaces for Learning and Neural Networks",
            "summary": "arXiv:2602.07141v1 Announce Type: new Abstract: Reproducing kernel Hilbert spaces provide a foundational framework for kernel-based learning, where regularization and interpolation problems admit finite-dimensional solutions through classical representer theorems. Many modern learning models, however -- including fixed-architecture neural networks equipped with non-quadratic norms -- naturally give rise to non-Hilbertian geometries that fall outside this setting. In Banach spaces, continuity of ",
            "url": "https://arxiv.org/abs/2602.07141",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-3b6a88e2",
            "type": "article",
            "title": "BONSAI: Bayesian Optimization with Natural Simplicity and Interpretability",
            "summary": "arXiv:2602.07144v1 Announce Type: new Abstract: Bayesian optimization (BO) is a popular technique for sample-efficient optimization of black-box functions. In many applications, the parameters being tuned come with a carefully engineered default configuration, and practitioners only want to deviate from this default when necessary. Standard BO, however, does not aim to minimize deviation from the default and, in practice, often pushes weakly relevant parameters to the boundary of the search spac",
            "url": "https://arxiv.org/abs/2602.07144",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-ecbed925",
            "type": "article",
            "title": "Convex Dominance in Deep Learning I: A Scaling Law of Loss and Learning Rate",
            "summary": "arXiv:2602.07145v1 Announce Type: new Abstract: Deep learning has non-convex loss landscape and its optimization dynamics is hard to analyze or control. Nevertheless, the dynamics can be empirically convex-like across various tasks, models, optimizers, hyperparameters, etc. In this work, we examine the applicability of convexity and Lipschitz continuity in deep learning, in order to precisely control the loss dynamics via the learning rate schedules. We illustrate that deep learning quickly beco",
            "url": "https://arxiv.org/abs/2602.07145",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-904d2a6f",
            "type": "article",
            "title": "On Randomness in Agentic Evals",
            "summary": "arXiv:2602.07150v1 Announce Type: new Abstract: Agentic systems are evaluated on benchmarks where agents interact with environments to solve tasks. Most papers report a pass@1 score computed from a single run per task, assuming this gives a reliable performance estimate. We test this assumption by collecting 60,000 agentic trajectories on SWE-Bench-Verified, spanning three models and two scaffolds. We find substantial variance: single-run pass@1 estimates vary by 2.2 to 6.0 percentage points dep",
            "url": "https://arxiv.org/abs/2602.07150",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-8d91fda0",
            "type": "article",
            "title": "Beyond Pooling: Matching for Robust Generalization under Data Heterogeneity",
            "summary": "arXiv:2602.07154v1 Announce Type: new Abstract: Pooling heterogeneous datasets across domains is a common strategy in representation learning, but naive pooling can amplify distributional asymmetries and yield biased estimators, especially in settings where zero-shot generalization is required. We propose a matching framework that selects samples relative to an adaptive centroid and iteratively refines the representation distribution. The double robustness and the propensity score matching for t",
            "url": "https://arxiv.org/abs/2602.07154",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d248a2cc",
            "type": "article",
            "title": "Mimetic Initialization of MLPs",
            "summary": "arXiv:2602.07156v1 Announce Type: new Abstract: Mimetic initialization uses pretrained models as case studies of good initialization, using observations of structures in trained weights to inspire new, simple initialization techniques. So far, it has been applied only to spatial mixing layers, such convolutional, self-attention, and state space layers. In this work, we present the first attempt to apply the method to channel mixing layers, namely multilayer perceptrons (MLPs). Our extremely simp",
            "url": "https://arxiv.org/abs/2602.07156",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2ca81ae6",
            "type": "article",
            "title": "Learning Nonlinear Systems In-Context: From Synthetic Data to Real-World Motor Control",
            "summary": "arXiv:2602.07173v1 Announce Type: new Abstract: LLMs have shown strong in-context learning (ICL) abilities, but have not yet been extended to signal processing systems. Inspired by their design, we have proposed for the first time ICL using transformer models applicable to motor feedforward control, a critical task where classical PI and physics-based methods struggle with nonlinearities and complex load conditions. We propose a transformer based model architecture that separates signal represen",
            "url": "https://arxiv.org/abs/2602.07173",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f5dc0f81",
            "type": "article",
            "title": "Latent Target Score Matching, with an application to Simulation-Based Inference",
            "summary": "arXiv:2602.07189v1 Announce Type: new Abstract: Denoising score matching (DSM) for training diffusion models may suffer from high variance at low noise levels. Target Score Matching (TSM) mitigates this when clean data scores are available, providing a low-variance objective. In many applications clean scores are inaccessible due to the presence of latent variables, leaving only joint signals exposed. We propose Latent Target Score Matching (LTSM), an extension of TSM to leverage joint scores fo",
            "url": "https://arxiv.org/abs/2602.07189",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-b6e92a01",
            "type": "article",
            "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models",
            "summary": "arXiv:2602.06973v1 Announce Type: new Abstract: While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese",
            "url": "https://arxiv.org/abs/2602.06973",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-885788b2",
            "type": "article",
            "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents",
            "summary": "arXiv:2602.06975v1 Announce Type: new Abstract: Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechA",
            "url": "https://arxiv.org/abs/2602.06975",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-61f42d30",
            "type": "article",
            "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks",
            "summary": "arXiv:2602.06976v1 Announce Type: new Abstract: The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this pape",
            "url": "https://arxiv.org/abs/2602.06976",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-4b791738",
            "type": "article",
            "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model",
            "summary": "arXiv:2602.07120v1 Announce Type: new Abstract: Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by ",
            "url": "https://arxiv.org/abs/2602.07120",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-4e1dc040",
            "type": "article",
            "title": "Free Energy Mixer",
            "summary": "arXiv:2602.07160v1 Announce Type: new Abstract: Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yie",
            "url": "https://arxiv.org/abs/2602.07160",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-826f8d2c",
            "type": "article",
            "title": "Your Language Model Secretly Contains Personality Subnetworks",
            "summary": "arXiv:2602.07164v1 Announce Type: new Abstract: Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already hav",
            "url": "https://arxiv.org/abs/2602.07164",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-ffe5ca3d",
            "type": "article",
            "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI",
            "summary": "arXiv:2602.07176v1 Announce Type: new Abstract: Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technolo",
            "url": "https://arxiv.org/abs/2602.07176",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-5d9975a7",
            "type": "article",
            "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs",
            "summary": "arXiv:2602.07181v1 Announce Type: new Abstract: User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' sign",
            "url": "https://arxiv.org/abs/2602.07181",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d9b3ad24",
            "type": "article",
            "title": "Long-Context Long-Form Question Answering for Legal Domain",
            "summary": "arXiv:2602.07190v1 Announce Type: new Abstract: Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be compreh",
            "url": "https://arxiv.org/abs/2602.07190",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f0847c2f",
            "type": "article",
            "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities",
            "summary": "arXiv:2602.07211v1 Announce Type: new Abstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understand",
            "url": "https://arxiv.org/abs/2602.07211",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-1629767c",
            "type": "article",
            "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice",
            "summary": "arXiv:2602.07319v1 Announce Type: new Abstract: Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sens",
            "url": "https://arxiv.org/abs/2602.07319",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-535bd1d7",
            "type": "article",
            "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation",
            "summary": "arXiv:2602.07338v1 Announce Type: new Abstract: Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior",
            "url": "https://arxiv.org/abs/2602.07338",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e91d83cc",
            "type": "article",
            "title": "ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations",
            "summary": "arXiv:2602.07361v1 Announce Type: new Abstract: Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting rema",
            "url": "https://arxiv.org/abs/2602.07361",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-057d7937",
            "type": "article",
            "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling",
            "summary": "arXiv:2602.07374v1 Announce Type: new Abstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approa",
            "url": "https://arxiv.org/abs/2602.07374",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2895c2f4",
            "type": "article",
            "title": "Efficient Post-Training Pruning of Large Language Models with Statistical Correction",
            "summary": "arXiv:2602.07375v1 Announce Type: new Abstract: Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning frame",
            "url": "https://arxiv.org/abs/2602.07375",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-85e81948",
            "type": "article",
            "title": "Do Large Language Models Reflect Demographic Pluralism in Safety?",
            "summary": "arXiv:2602.07376v1 Announce Type: new Abstract: Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from",
            "url": "https://arxiv.org/abs/2602.07376",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9229043d",
            "type": "article",
            "title": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified",
            "summary": "arXiv:2602.07381v1 Announce Type: new Abstract: Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis C",
            "url": "https://arxiv.org/abs/2602.07381",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-edcc7f72",
            "type": "article",
            "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi",
            "summary": "arXiv:2602.07382v1 Announce Type: new Abstract: Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely",
            "url": "https://arxiv.org/abs/2602.07382",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-eb12b02b",
            "type": "article",
            "title": "Measuring cross-language intelligibility between Romance languages with computational tools",
            "summary": "arXiv:2602.07447v1 Announce Type: new Abstract: We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthograph",
            "url": "https://arxiv.org/abs/2602.07447",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-1383447e",
            "type": "article",
            "title": "DLLM Agent: See Farther, Run Faster",
            "summary": "arXiv:2602.07451v1 Announce Type: new Abstract: Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, an",
            "url": "https://arxiv.org/abs/2602.07451",
            "source": "arxiv",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9eef7a37",
            "type": "article",
            "title": "Helping kids and teens learn and grow online on Safer Internet Day",
            "summary": "User profile on smartphone connected to security, media, and settings icons.",
            "url": "https://blog.google/innovation-and-ai/technology/safety-security/safer-internet-day-2026-kids-teens/",
            "source": "blogs",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-e42f6ff4",
            "type": "article",
            "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
            "summary": "A collage of four images, the first of a woman with curly hair in front of a silver laptop, the second of the same woman and a man with short black hair speaking on a stairwell, the third of a the same man with glasses, and an aerial image of NTID",
            "url": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-828c66e8",
            "type": "article",
            "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
            "summary": "A woman outdoors in the snow looks at a tablet. A half pipe is behind her.",
            "url": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-f9c339ba",
            "type": "article",
            "title": "Watch our new Gemini ad ahead of football\u2019s biggest weekend",
            "summary": "A toddler in a blue and yellow striped shirt sits on a kitchen counter eating a red apple. Text in the corner reads: 'New Home, Google Gemini SB Commercial\u2019",
            "url": "https://blog.google/company-news/inside-google/company-announcements/gemini-ad-new-home/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-1eabfc9f",
            "type": "article",
            "title": "The latest AI news we announced in January",
            "summary": "mp4 showing a carousel of images including a card reading \"Help that's made for you\"",
            "url": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-5d835c59",
            "type": "article",
            "title": "Transformers.js v4 Preview: Now Available on NPM!",
            "summary": "",
            "url": "https://huggingface.co/blog/transformersjs-v4",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-4b956a17",
            "type": "article",
            "title": "Introducing SyGra Studio",
            "summary": "",
            "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-5a59b4d6",
            "type": "article",
            "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3\u2019s Top Model",
            "summary": "",
            "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-54a2e4d6",
            "type": "article",
            "title": "Community Evals: Because we're done trusting black-box leaderboards over the community",
            "summary": "",
            "url": "https://huggingface.co/blog/community-evals",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-bb1053f9",
            "type": "article",
            "title": "H Company's new Holo2 model takes the lead in UI Localization",
            "summary": "",
            "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
            "source": "blogs",
            "date": "2026-02-03",
            "trendingScore": 50
        },
        {
            "id": "article-74bdaef6",
            "type": "article",
            "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
            "summary": "",
            "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
            "source": "blogs",
            "date": "2026-02-03",
            "trendingScore": 50
        },
        {
            "id": "article-a0998dd5",
            "type": "article",
            "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
            "summary": "",
            "url": "https://huggingface.co/blog/Photoroom/prx-part2",
            "source": "blogs",
            "date": "2026-02-03",
            "trendingScore": 50
        },
        {
            "id": "article-e3e028d7",
            "type": "article",
            "title": "Why the Moltbook frenzy was like Pok\u00e9mon",
            "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-d7ce15dc",
            "type": "article",
            "title": "Making AI Work, MIT Technology Review\u2019s new AI newsletter, is here",
            "summary": "For years, our newsroom has explored AI\u2019s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&#160; But how is AI actually being used in fields like health care, climate tech, education,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/",
            "source": "blogs",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-63da4d4a",
            "type": "article",
            "title": "Moltbook was peak AI theater",
            "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on January 28 by Matt Schlicht,&#8230;",
            "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
            "source": "blogs",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-4c5e5bb4",
            "type": "article",
            "title": "This is the most misunderstood graph in AI",
            "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;",
            "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
            "source": "blogs",
            "date": "2026-02-05",
            "trendingScore": 50
        },
        {
            "id": "article-1ca5a016",
            "type": "article",
            "title": "From guardrails to governance: A CEO\u2019s guide for securing agentic systems",
            "summary": "The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;",
            "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
            "source": "blogs",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-24046667",
            "type": "article",
            "title": "AI Coding Is a Framework\u2013Use It Like a Library",
            "summary": "",
            "url": "https://www.piglei.com/articles/en-ai-coding-is-a-framework/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-ca0b9d01",
            "type": "article",
            "title": "Show HN: Pincer-MCP \u2013 Stop AI agents from reading their own credentials",
            "summary": "",
            "url": "https://github.com/VouchlyAI/Pincer-MCP",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-75dd7d1d",
            "type": "article",
            "title": "Are we in an AI Bubble? A researched thesis detailing both sides.",
            "summary": "",
            "url": "https://www.cjroth.com/blog/2026-02-10-are-we-in-an-ai-bubble",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-5103ffef",
            "type": "article",
            "title": "Ask HN: How much did you spend on AI last month?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46956019",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d4e124a8",
            "type": "article",
            "title": "Show HN: Self-Healing AI Agents with Claude Code as Doctor",
            "summary": "",
            "url": "https://github.com/Ramsbaby/openclaw-self-healing",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-ded76e08",
            "type": "article",
            "title": "Show HN: MCP Orchestrator \u2013 Spawn parallel AI sub-agents from one prompt",
            "summary": "",
            "url": "https://github.com/Ask149/orchestrator",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-915eb595",
            "type": "article",
            "title": "Show HN: Agx \u2013 A Kanban board that runs your AI coding agents",
            "summary": "",
            "url": "https://github.com/ramarlina/agx",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-91528481",
            "type": "article",
            "title": "Why Every Business Must Engage with AI \u2013 and How to Do It Right",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46955823",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2d5f195d",
            "type": "article",
            "title": "Show HN: PicoClaw \u2013 lightweight OpenClaw-style AI bot in one Go binary",
            "summary": "",
            "url": "https://github.com/mosaxiv/picoclaw",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2a916ff1",
            "type": "article",
            "title": "Show HN: A CLI tool to automate Git workflows using AI agents",
            "summary": "",
            "url": "https://github.com/leochiu-a/git-pr-ai",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-430b8e59",
            "type": "article",
            "title": "Use AI to find movies and TV shows on your streaming services",
            "summary": "",
            "url": "https://pickalready.com",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-52408662",
            "type": "article",
            "title": "GenAI Go SDK for AI",
            "summary": "",
            "url": "https://50984e11.maruel-ca.pages.dev/post/genai-v0.1.0/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-6ff8393f",
            "type": "article",
            "title": "Show HN: I built an AI-powered late-night call-in radio show from my RV",
            "summary": "",
            "url": "https://lukeattheroost.com",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-8bd965fb",
            "type": "article",
            "title": "We chose a pipeline over speech-to-speech for evaluative voice AI",
            "summary": "",
            "url": "https://productfit.substack.com/p/why-speech-to-speech-apis-fail-when",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-a75b6f4d",
            "type": "article",
            "title": "AI Doesn't Reduce Work\u2013It Intensifies It",
            "summary": "",
            "url": "https://simonwillison.net/2026/Feb/9/ai-intensifies-work/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-5126159f",
            "type": "article",
            "title": "A one-prompt attack that breaks LLM safety alignment",
            "summary": "",
            "url": "https://www.microsoft.com/en-us/security/blog/2026/02/09/prompt-attack-breaks-llm-safety/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-18088db6",
            "type": "article",
            "title": "LLMs Refuse High-Cost Attacks but Stay Vulnerable to Cheap, Real-World Harm",
            "summary": "",
            "url": "https://expectedharm.github.io/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-4f5ab6cc",
            "type": "article",
            "title": "The Vocabulary Priming Confound in LLM Evaluation [pdf]",
            "summary": "",
            "url": "https://github.com/Palmerschallon/Dharma_Code/blob/main/paper/vocab_priming_confound.pdf",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-fa8a257f",
            "type": "article",
            "title": "Show HN: I built an Customized LLM with RAG for Singapore",
            "summary": "",
            "url": "https://github.com/adityaprasad-sudo/Explore-Singapore",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f9711e43",
            "type": "article",
            "title": "Agentic Tool Patterns \u2013 54 patterns for building tools LLM agents can use",
            "summary": "",
            "url": "https://blog.arcade.dev/mcp-tool-patterns",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-d41d637e",
            "type": "article",
            "title": "Some Thoughts on LLM Coding",
            "summary": "",
            "url": "https://blog.dave.tf/post/coding-agents/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-f96c6524",
            "type": "article",
            "title": "Show HN: Axiom \u2013 Open-source AI research agent that runs locally (C#, Ollama)",
            "summary": "",
            "url": "https://github.com/DynamicCSharp/hex-dynamics",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-7242cb8f",
            "type": "article",
            "title": "Show HN: Hybrid Orchestrator \u2013 Reliable AI agents for finance",
            "summary": "",
            "url": "https://github.com/pavelsukhachev/hybrid-orchestrator",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-072c7c4b",
            "type": "article",
            "title": "Show HN: YAML-based security framework for CDN edge (CloudFront / Cloudflare)",
            "summary": "",
            "url": "https://github.com/albert-einshutoin/cdn-security-framework",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-7a9bba34",
            "type": "article",
            "title": "Can you rewire your brain?",
            "summary": "",
            "url": "https://aeon.co/essays/what-the-metaphor-of-rewiring-gets-wrong-about-neuroplasticity",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-590cae55",
            "type": "article",
            "title": "Tailscale Domain Mgmt. Gateway",
            "summary": "",
            "url": "https://github.com/adrianosela/tsdmg",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2497fd1b",
            "type": "article",
            "title": "God, Theology, and AI",
            "summary": "",
            "url": "https://rlafuente.com/posts/2026-2-1-on-god-and-machine-learning#",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2ed9ffa8",
            "type": "article",
            "title": "Show HN: We added AGENTS.md to 120 challenges so AI teaches instead of codes",
            "summary": "",
            "url": "https://www.frontendmentor.io/articles/agents-md-files-in-every-challenge",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-8d88c1c8",
            "type": "article",
            "title": "Show HN: Forge \u2013 3MB Rust binary that coordinates multi-AI coding agents via MCP",
            "summary": "",
            "url": "https://github.com/nxtg-ai/forge-orchestrator",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-a20ff559",
            "type": "article",
            "title": "Show HN: I built an open-source Gmail productivity app that auto-labels emails",
            "summary": "",
            "url": "https://github.com/Lakshay1509/NeatMail",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-a8bc8060",
            "type": "article",
            "title": "Show HN: SuperLocalMemory \u2013 AI memory that stays on your machine, forever free",
            "summary": "",
            "url": "https://github.com/varun369/SuperLocalMemoryV2",
            "source": "hackernews",
            "date": "2026-02-07",
            "trendingScore": 50
        },
        {
            "id": "article-f18858e8",
            "type": "article",
            "title": "ML-Lib: Machine Learning Library Proposed for the Linux Kernel",
            "summary": "",
            "url": "https://www.phoronix.com/news/Linux-Kernel-ML-LIB-RFC",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-7221af3c",
            "type": "article",
            "title": "AI Development Company",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46909998",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 50
        },
        {
            "id": "article-31345870",
            "type": "article",
            "title": "Why Most Machine Learning Projects Fail to Reach Production \u2013 InfoQ",
            "summary": "",
            "url": "https://www.infoq.com/articles/why-ml-projects-fail-production/",
            "source": "hackernews",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-1e0c4924",
            "type": "article",
            "title": "Wave: Python Domain-Specific Language for High Performance Machine Learning",
            "summary": "",
            "url": "https://github.com/iree-org/wave",
            "source": "hackernews",
            "date": "2026-02-03",
            "trendingScore": 50
        },
        {
            "id": "article-2a63b432",
            "type": "article",
            "title": "A Complete Guide to Neural Network Optimizers",
            "summary": "",
            "url": "https://chizkidd.github.io//2026/01/22/neural-net-optimizers/",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-ed81c445",
            "type": "article",
            "title": "SpaceX-xAI Merger: Nobody's Talking About the von Neumann Elephant in the Room",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46933827",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-b079933d",
            "type": "article",
            "title": "Can graph neural networks for biology realistically run on edge devices?",
            "summary": "",
            "url": "https://doi.org/10.21203/rs.3.rs-8645211/v1",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-faec27b2",
            "type": "article",
            "title": "SMLL: Using 200MB of Neural Network to Save 400 Bytes",
            "summary": "",
            "url": "https://www.frankchiarulli.com/blog/smll/",
            "source": "hackernews",
            "date": "2026-02-06",
            "trendingScore": 51
        },
        {
            "id": "article-29a8aa5e",
            "type": "article",
            "title": "Hypernetworks: Neural Networks for Hierarchical Data",
            "summary": "",
            "url": "https://blog.sturdystatistics.com/posts/hnet_part_I/",
            "source": "hackernews",
            "date": "2026-02-05",
            "trendingScore": 59
        },
        {
            "id": "article-c2d508d8",
            "type": "article",
            "title": "Show HN: LayerClaw \u2013 Observability tool for PyTorch training",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46892694",
            "source": "hackernews",
            "date": "2026-02-04",
            "trendingScore": 50
        },
        {
            "id": "article-8f8616b9",
            "type": "article",
            "title": "Understanding Neural Network, Visually",
            "summary": "",
            "url": "https://visualrambling.space/neural-network/",
            "source": "hackernews",
            "date": "2026-02-03",
            "trendingScore": 84
        },
        {
            "id": "article-2e78e20e",
            "type": "article",
            "title": "Claude /fast mode consumes money fast",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46955265",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9c6121b6",
            "type": "article",
            "title": "CLIProxyAPIPlus \u2013 use antigravity, Gemini CLI, & more with Claude Code / etc.",
            "summary": "",
            "url": "https://github.com/router-for-me/CLIProxyAPIPlus",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-c9c49722",
            "type": "article",
            "title": "AI Agents That Execute Business Workflows (Claude Code for ERP)",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46955034",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-369c37c1",
            "type": "article",
            "title": "I gave an AI access to my psychology. Documenting the experiment",
            "summary": "",
            "url": "https://github.com/lout33/claude_life_assistant",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-2f8e990e",
            "type": "article",
            "title": "Show HN: K8s controller to sandbox Claude Code (merged 47 PRs to itself)",
            "summary": "",
            "url": "https://github.com/axon-core/axon",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9db8f2c7",
            "type": "article",
            "title": "AI Wrote My Project, an Nginx Engineer Rebuilt the Architecture",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46954755",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-6d21eaa4",
            "type": "article",
            "title": "Show HN: remolt.dev \u2013 Sandboxed AI coding sessions in the browser",
            "summary": "",
            "url": "https://remolt.dev",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-9ac34807",
            "type": "article",
            "title": "Show HN: Clog \u2013 Track and compare your Claude Code usage",
            "summary": "",
            "url": "https://clog.sh",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-30468976",
            "type": "article",
            "title": "Show HN: I made a Claude Code guide that's a Win95 desktop with games",
            "summary": "",
            "url": "https://gabezen.com/guide/",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-3f671654",
            "type": "article",
            "title": "Show HN: Claude SEO \u2013 12 open-source SEO tools for Claude Code",
            "summary": "",
            "url": "https://github.com/AgriciDaniel/claude-seo",
            "source": "hackernews",
            "date": "2026-02-10",
            "trendingScore": 50
        },
        {
            "id": "article-c39e6253",
            "type": "article",
            "title": "Show HN: Codedocent \u2013 Turn any codebase into visual blocks with plain English",
            "summary": "",
            "url": "https://github.com/clanker-lover/codedocent",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-f39910dc",
            "type": "article",
            "title": "Letting Gemini Drive My Rover",
            "summary": "",
            "url": "http://martin.drashkov.com/2026/02/letting-gemini-drive-my-rover.html",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-e499f3fe",
            "type": "article",
            "title": "Show HN: A pipeline to render and serve web components dynamically via LLM",
            "summary": "",
            "url": "https://github.com/pilifs/Terminal-Value",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-7878cba7",
            "type": "article",
            "title": "Show HN: Sales Agent Benchmark \u2013 SWE-Bench for sales AI agents (open source)",
            "summary": "",
            "url": "https://sales-agent-benchmarks.fly.dev/benchmark",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-897b0bfb",
            "type": "article",
            "title": "Agentic Vision in Gemini 3 Flash",
            "summary": "",
            "url": "https://blog.google/innovation-and-ai/technology/developers-tools/agentic-vision-gemini-3-flash/",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-9b69fb41",
            "type": "article",
            "title": "Gemini 3 Flash Preview: Inconsistent thought_signature",
            "summary": "",
            "url": "https://discuss.ai.google.dev/t/gemini-3-flash-preview-inconsistent-thought-signature-generation-in-parallel-function-calls-causes-400-errors-and-potential-silent-data-loss/118936",
            "source": "hackernews",
            "date": "2026-02-09",
            "trendingScore": 50
        },
        {
            "id": "article-73e2e616",
            "type": "article",
            "title": "Show HN: ZTGI Safety Gateway for LLM Safety",
            "summary": "",
            "url": "https://github.com/capterr/ztgi-safety-gateway",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-b188a750",
            "type": "article",
            "title": "Show HN: Parametric Hubris \u2013 Beating GPT-5 on SimpleQA with forced retrieval",
            "summary": "",
            "url": "https://dev.thelastrag.de/veritas_benchmark",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "article-bde4197c",
            "type": "article",
            "title": "Show HN: Intervu \u2013 Free, BYOK Interview Prep (Groq/Gemini/OpenAI)",
            "summary": "",
            "url": "https://www.intervu.cc/",
            "source": "hackernews",
            "date": "2026-02-08",
            "trendingScore": 50
        },
        {
            "id": "topic-large-language-models",
            "type": "topic",
            "title": "Large Language Models",
            "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
            "connectionCount": 39
        },
        {
            "id": "topic-ai-reasoning",
            "type": "topic",
            "title": "AI Reasoning",
            "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
            "connectionCount": 13
        },
        {
            "id": "topic-nlp",
            "type": "topic",
            "title": "NLP",
            "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
            "connectionCount": 31
        },
        {
            "id": "topic-ai-agents",
            "type": "topic",
            "title": "AI Agents",
            "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
            "connectionCount": 32
        },
        {
            "id": "topic-diffusion-models",
            "type": "topic",
            "title": "Diffusion Models",
            "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
            "connectionCount": 6
        },
        {
            "id": "topic-model-efficiency",
            "type": "topic",
            "title": "Model Efficiency",
            "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
            "connectionCount": 6
        },
        {
            "id": "topic-multimodal-ai",
            "type": "topic",
            "title": "Multimodal AI",
            "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
            "connectionCount": 6
        },
        {
            "id": "topic-fine-tuning",
            "type": "topic",
            "title": "Fine-tuning",
            "summary": "Adapting pre-trained models to specific tasks or domains.",
            "connectionCount": 4
        },
        {
            "id": "topic-computer-vision",
            "type": "topic",
            "title": "Computer Vision",
            "summary": "AI systems for understanding and processing visual information from images and video.",
            "connectionCount": 13
        },
        {
            "id": "topic-ai-safety",
            "type": "topic",
            "title": "AI Safety",
            "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
            "connectionCount": 9
        },
        {
            "id": "topic-reinforcement-learning",
            "type": "topic",
            "title": "Reinforcement Learning",
            "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
            "connectionCount": 21
        },
        {
            "id": "topic-prompt-engineering",
            "type": "topic",
            "title": "Prompt Engineering",
            "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
            "connectionCount": 9
        },
        {
            "id": "topic-rag",
            "type": "topic",
            "title": "RAG",
            "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
            "connectionCount": 8
        },
        {
            "id": "org-anthropic",
            "type": "organization",
            "title": "Anthropic",
            "summary": "Anthropic - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-google",
            "type": "organization",
            "title": "Google",
            "summary": "Google - AI research and development.",
            "connectionCount": 3
        },
        {
            "id": "org-apple",
            "type": "organization",
            "title": "Apple",
            "summary": "Apple - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-openai",
            "type": "organization",
            "title": "OpenAI",
            "summary": "OpenAI - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-xai",
            "type": "organization",
            "title": "xAI",
            "summary": "xAI - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "model-gemini",
            "type": "model",
            "title": "Gemini",
            "summary": "Gemini AI model.",
            "connectionCount": 6
        },
        {
            "id": "model-claude",
            "type": "model",
            "title": "Claude",
            "summary": "Claude AI model.",
            "connectionCount": 8
        },
        {
            "id": "model-llama",
            "type": "model",
            "title": "Llama",
            "summary": "Llama AI model.",
            "connectionCount": 1
        },
        {
            "id": "model-gpt-5",
            "type": "model",
            "title": "GPT-5",
            "summary": "GPT-5 AI model.",
            "connectionCount": 1
        }
    ],
    "edges": [
        {
            "source": "article-4e2348af",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e2348af",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e2348af",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-cbe7a7f3",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cbe7a7f3",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-7da7b9d6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fc694bfa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9f4197a3",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-654cc34f",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-32cefdbb",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-32cefdbb",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-5c5168b9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5c5168b9",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f297f39a",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1fdcfbe",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ebe3eb0",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9d4302c9",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f3a26c90",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-310c6cc4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e813294f",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f23f74fa",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f23f74fa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d10f3bd2",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d10f3bd2",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e5058201",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-72c66faa",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-72bc3687",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-72bc3687",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1dba9bb",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1dba9bb",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1dba9bb",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-02020214",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-87b2eade",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-87b2eade",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-87b2eade",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-87b2eade",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-87b2eade",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d6e92594",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d6e92594",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d6e92594",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-d6e92594",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d6e92594",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-35a61125",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-35a61125",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-35a61125",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-35a61125",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-55d18ed3",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-55d18ed3",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-462c786d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-462c786d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-9af6cac5",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-9af6cac5",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5ad74a28",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-6af04419",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-6af04419",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cfa13284",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cfa13284",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-3b6a88e2",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-904d2a6f",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-8d91fda0",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-8d91fda0",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ca81ae6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ca81ae6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ca81ae6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f5dc0f81",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-f5dc0f81",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6e92a01",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6e92a01",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6e92a01",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6e92a01",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-b6e92a01",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-885788b2",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-885788b2",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-885788b2",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-61f42d30",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b791738",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b791738",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e1dc040",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e1dc040",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-826f8d2c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-826f8d2c",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-826f8d2c",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-826f8d2c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-826f8d2c",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ffe5ca3d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d9975a7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d9975a7",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d9975a7",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d9975a7",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-d9b3ad24",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-d9b3ad24",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f0847c2f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f0847c2f",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-1629767c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1629767c",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1629767c",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-535bd1d7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e91d83cc",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e91d83cc",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-e91d83cc",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e91d83cc",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-057d7937",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-057d7937",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-2895c2f4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-2895c2f4",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-85e81948",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9229043d",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-9229043d",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-9229043d",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-9229043d",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-edcc7f72",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-1383447e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e42f6ff4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-828c66e8",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f9c339ba",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1eabfc9f",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-5d835c59",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a59b4d6",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-5a59b4d6",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0998dd5",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-a0998dd5",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e3e028d7",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d7ce15dc",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-63da4d4a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4c5e5bb4",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1ca5a016",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-1ca5a016",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-ca0b9d01",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d4e124a8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d4e124a8",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ded76e08",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-ded76e08",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-915eb595",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-2a916ff1",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-5126159f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5126159f",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-5126159f",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-18088db6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-18088db6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-18088db6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4f5ab6cc",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-fa8a257f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-fa8a257f",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-f9711e43",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f9711e43",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d41d637e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f96c6524",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-f96c6524",
            "target": "model-llama",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-7242cb8f",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-2ed9ffa8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-8d88c1c8",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a8bc8060",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ed81c445",
            "target": "org-xai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-2e78e20e",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9c6121b6",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9c6121b6",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c9c49722",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-c9c49722",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-2f8e990e",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9ac34807",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-30468976",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-3f671654",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-f39910dc",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e499f3fe",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7878cba7",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-897b0bfb",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-897b0bfb",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-897b0bfb",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9b69fb41",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-73e2e616",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-73e2e616",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-b188a750",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-b188a750",
            "target": "model-gpt-5",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bde4197c",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bde4197c",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-reasoning",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-agents",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-rag",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-multimodal-ai",
            "target": "topic-computer-vision",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-agents",
            "target": "topic-prompt-engineering",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-model-efficiency",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-safety",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        }
    ]
};

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIChronicleData;
}
