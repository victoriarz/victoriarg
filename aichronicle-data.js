// ================================================
// THE AI CHRONICLE - Knowledge Graph Data
// Auto-generated and updated daily via GitHub Actions
// Last updated: 2026-01-21
// ================================================

const AIChronicleData = {
    "metadata": {
        "lastUpdated": "2026-01-21T06:34:57.822657Z",
        "totalArticles": 145,
        "totalNodes": 172,
        "totalEdges": 243,
        "dateRange": {
            "start": "2026-01-14",
            "end": "2026-01-21"
        }
    },
    "nodes": [
        {
            "id": "article-ee750791",
            "type": "article",
            "title": "MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?",
            "summary": "arXiv:2601.11559v1 Announce Type: new Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes",
            "url": "https://arxiv.org/abs/2601.11559",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-c8e1fb1f",
            "type": "article",
            "title": "A Mind Cannot Be Smeared Across Time",
            "summary": "arXiv:2601.11620v1 Announce Type: new Abstract: Whether machines can be conscious depends not only on what they compute, but \\emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal se",
            "url": "https://arxiv.org/abs/2601.11620",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-c91c0549",
            "type": "article",
            "title": "Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models",
            "summary": "arXiv:2601.11622v1 Announce Type: new Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer",
            "url": "https://arxiv.org/abs/2601.11622",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ca974260",
            "type": "article",
            "title": "Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance",
            "summary": "arXiv:2601.11625v1 Announce Type: new Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consiste",
            "url": "https://arxiv.org/abs/2601.11625",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-e1c17b47",
            "type": "article",
            "title": "PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement",
            "summary": "arXiv:2601.11747v1 Announce Type: new Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas desig",
            "url": "https://arxiv.org/abs/2601.11747",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-5afaf0e6",
            "type": "article",
            "title": "Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles",
            "summary": "arXiv:2601.11781v1 Announce Type: new Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) v",
            "url": "https://arxiv.org/abs/2601.11781",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-5e3fa748",
            "type": "article",
            "title": "A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation",
            "summary": "arXiv:2601.11792v1 Announce Type: new Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (I",
            "url": "https://arxiv.org/abs/2601.11792",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-a869becd",
            "type": "article",
            "title": "Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic",
            "summary": "arXiv:2601.11809v1 Announce Type: new Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change de",
            "url": "https://arxiv.org/abs/2601.11809",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-cb967b9e",
            "type": "article",
            "title": "POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation",
            "summary": "arXiv:2601.11816v1 Announce Type: new Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked dir",
            "url": "https://arxiv.org/abs/2601.11816",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-808c7113",
            "type": "article",
            "title": "AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept",
            "summary": "arXiv:2601.11825v1 Announce Type: new Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge gr",
            "url": "https://arxiv.org/abs/2601.11825",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-55bec34c",
            "type": "article",
            "title": "Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic",
            "summary": "arXiv:2601.11840v1 Announce Type: new Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor. We present CodeLogician, a neurosymbolic agent for precise analysis of s",
            "url": "https://arxiv.org/abs/2601.11840",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-4baeba5e",
            "type": "article",
            "title": "Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority",
            "summary": "arXiv:2601.11850v1 Announce Type: new Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. ",
            "url": "https://arxiv.org/abs/2601.11850",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-509c3a60",
            "type": "article",
            "title": "MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment",
            "summary": "arXiv:2601.11885v1 Announce Type: new Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph tra",
            "url": "https://arxiv.org/abs/2601.11885",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-59e9cc5b",
            "type": "article",
            "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems",
            "summary": "arXiv:2601.11903v1 Announce Type: new Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present A",
            "url": "https://arxiv.org/abs/2601.11903",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-7242e263",
            "type": "article",
            "title": "LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning",
            "summary": "arXiv:2601.11905v1 Announce Type: new Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized",
            "url": "https://arxiv.org/abs/2601.11905",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-03401201",
            "type": "article",
            "title": "Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart",
            "summary": "arXiv:2601.11940v1 Announce Type: new Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root er",
            "url": "https://arxiv.org/abs/2601.11940",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-7c10b92b",
            "type": "article",
            "title": "Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement",
            "summary": "arXiv:2601.11974v1 Announce Type: new Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-ev",
            "url": "https://arxiv.org/abs/2601.11974",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-cd89a890",
            "type": "article",
            "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion",
            "summary": "arXiv:2601.11979v1 Announce Type: new Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often ar",
            "url": "https://arxiv.org/abs/2601.11979",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-9b4dec1e",
            "type": "article",
            "title": "Kernel-Based Learning of Safety Barriers",
            "summary": "arXiv:2601.12002v1 Announce Type: new Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety v",
            "url": "https://arxiv.org/abs/2601.12002",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-c4219dd6",
            "type": "article",
            "title": "Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats",
            "summary": "arXiv:2601.12014v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to ",
            "url": "https://arxiv.org/abs/2601.12014",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-418db2e4",
            "type": "article",
            "title": "CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration",
            "summary": "arXiv:2601.11556v1 Announce Type: new Abstract: Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item inv",
            "url": "https://arxiv.org/abs/2601.11556",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-96fdaaea",
            "type": "article",
            "title": "AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control",
            "summary": "arXiv:2601.11568v1 Announce Type: new Abstract: Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($\\rho$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $\\rho$ to progressively reduce memory",
            "url": "https://arxiv.org/abs/2601.11568",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-6de3b920",
            "type": "article",
            "title": "Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces",
            "summary": "arXiv:2601.11572v1 Announce Type: new Abstract: We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonst",
            "url": "https://arxiv.org/abs/2601.11572",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-e37c4dc9",
            "type": "article",
            "title": "GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment",
            "summary": "arXiv:2601.11574v1 Announce Type: new Abstract: Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy grad",
            "url": "https://arxiv.org/abs/2601.11574",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-fc52275a",
            "type": "article",
            "title": "Hindsight Preference Replay Improves Preference-Conditioned Multi-Objective Reinforcement Learning",
            "summary": "arXiv:2601.11604v1 Announce Type: new Abstract: Multi-objective reinforcement learning (MORL) enables agents to optimize vector-valued rewards while respecting user preferences. CAPQL, a preference-conditioned actor-critic method, achieves this by conditioning on weight vectors w and restricts data usage to the specific preferences under which it was collected, leaving off-policy data from other preferences unused. We introduce Hindsight Preference Replay (HPR), a simple and general replay augme",
            "url": "https://arxiv.org/abs/2601.11604",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-d65f2810",
            "type": "article",
            "title": "A Multimodal Data Processing Pipeline for MIMIC-IV Dataset",
            "summary": "arXiv:2601.11606v1 Announce Type: new Abstract: The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, the",
            "url": "https://arxiv.org/abs/2601.11606",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-86048130",
            "type": "article",
            "title": "Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction",
            "summary": "arXiv:2601.11609v1 Announce Type: new Abstract: Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).",
            "url": "https://arxiv.org/abs/2601.11609",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-72945253",
            "type": "article",
            "title": "Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home",
            "summary": "arXiv:2601.11611v1 Announce Type: new Abstract: With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes dat",
            "url": "https://arxiv.org/abs/2601.11611",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-402cbeab",
            "type": "article",
            "title": "A Review on Machine Learning Approaches for the Prediction of Glucose Levels and Hypogylcemia",
            "summary": "arXiv:2601.11615v1 Announce Type: new Abstract: Type 1 Diabetes (T1D) is an autoimmune disease leading to insulin insufficiency. Thus, patients require lifelong insulin therapy, which has a side effect of hypoglycemia. Hypoglycemia is a critical state of decreased blood glucose levels (BGL) below 70 mg/dL and is associated with increased risk of mortality. Machine learning (ML) models can improve diabetes management by predicting hypoglycemia and providing optimal prevention methods. ML models a",
            "url": "https://arxiv.org/abs/2601.11615",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-0e16a322",
            "type": "article",
            "title": "Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective",
            "summary": "arXiv:2601.11616v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) architectures are commonly motivated by efficiency and conditional computation, but their effect on the geometry of learned functions and representations remains poorly characterized. In this work, we study MoEs through a geometric lens, interpreting routing as a form of soft partitioning of the representation space into overlapping local charts. We introduce a Dual Jacobian-PCA Spectral Geometry probe. It analyzes local fu",
            "url": "https://arxiv.org/abs/2601.11616",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-7824794b",
            "type": "article",
            "title": "Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention",
            "summary": "arXiv:2601.11618v1 Announce Type: new Abstract: Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and theref",
            "url": "https://arxiv.org/abs/2601.11618",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-427ebd4b",
            "type": "article",
            "title": "NoiseFormer -- Noise Diffused Symmetric Attention Transformer",
            "summary": "arXiv:2601.11619v1 Announce Type: new Abstract: Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increa",
            "url": "https://arxiv.org/abs/2601.11619",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-162c5b29",
            "type": "article",
            "title": "Verifying Physics-Informed Neural Network Fidelity using Classical Fisher Information from Differentiable Dynamical System",
            "summary": "arXiv:2601.11638v1 Announce Type: new Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for solving differential equations and modeling physical systems by embedding physical laws into the learning process. However, rigorously quantifying how well a PINN captures the complete dynamical behavior of the system, beyond simple trajectory prediction, remains a challenge. This paper proposes a novel experimental framework to address this by employing Fisher information",
            "url": "https://arxiv.org/abs/2601.11638",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-6a8aa192",
            "type": "article",
            "title": "Global Optimization By Gradient from Hierarchical Score-Matching Spaces",
            "summary": "arXiv:2601.11639v1 Announce Type: new Abstract: Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By ",
            "url": "https://arxiv.org/abs/2601.11639",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-6e058ba7",
            "type": "article",
            "title": "Size is Not the Solution: Deformable Convolutions for Effective Physics Aware Deep Learning",
            "summary": "arXiv:2601.11657v1 Announce Type: new Abstract: Physics-aware deep learning (PADL) enables rapid prediction of complex physical systems, yet current convolutional neural network (CNN) architectures struggle with highly nonlinear flows. While scaling model size addresses complexity in broader AI, this approach yields diminishing returns for physics modeling. Drawing inspiration from Hybrid Lagrangian-Eulerian (HLE) numerical methods, we introduce deformable physics-aware recurrent convolutions (D",
            "url": "https://arxiv.org/abs/2601.11657",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-29d11910",
            "type": "article",
            "title": "Machine learning model for predicting surface wettability in laser-textured metal alloys",
            "summary": "arXiv:2601.11661v1 Announce Type: new Abstract: Surface wettability, governed by both topography and chemistry, plays a critical role in applications such as heat transfer, lubrication, microfluidics, and surface coatings. In this study, we present a machine learning (ML) framework capable of accurately predicting the wettability of laser-textured metal alloys using experimentally derived morphological and chemical features. Superhydrophilic and superhydrophobic surfaces were fabricated on AA606",
            "url": "https://arxiv.org/abs/2601.11661",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ea565150",
            "type": "article",
            "title": "Activation Sensitivity as a Unifying Principle for Post-Training Quantization",
            "summary": "arXiv:2601.11663v1 Announce Type: new Abstract: Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, thes",
            "url": "https://arxiv.org/abs/2601.11663",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-0415fb26",
            "type": "article",
            "title": "Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction",
            "summary": "arXiv:2601.11667v1 Announce Type: new Abstract: Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: tra",
            "url": "https://arxiv.org/abs/2601.11667",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-905b0a64",
            "type": "article",
            "title": "IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning",
            "summary": "arXiv:2601.11669v1 Announce Type: new Abstract: Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement ",
            "url": "https://arxiv.org/abs/2601.11669",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ff087ff7",
            "type": "article",
            "title": "A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning",
            "summary": "arXiv:2601.11670v1 Announce Type: new Abstract: Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a pri",
            "url": "https://arxiv.org/abs/2601.11670",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-9c9497ef",
            "type": "article",
            "title": "Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths",
            "summary": "arXiv:2601.11564v1 Announce Type: new Abstract: The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volum",
            "url": "https://arxiv.org/abs/2601.11564",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-0fee3d0b",
            "type": "article",
            "title": "Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings",
            "summary": "arXiv:2601.11565v1 Announce Type: new Abstract: As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production ",
            "url": "https://arxiv.org/abs/2601.11565",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ab07b3ac",
            "type": "article",
            "title": "Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology",
            "summary": "arXiv:2601.11567v1 Announce Type: new Abstract: Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), ",
            "url": "https://arxiv.org/abs/2601.11567",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-8e051fdc",
            "type": "article",
            "title": "An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT",
            "summary": "arXiv:2601.11573v1 Announce Type: new Abstract: Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer ",
            "url": "https://arxiv.org/abs/2601.11573",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-e85800ec",
            "type": "article",
            "title": "Concept Attractors in LLMs and their Applications",
            "summary": "arXiv:2601.11575v1 Announce Type: new Abstract: Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a w",
            "url": "https://arxiv.org/abs/2601.11575",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-d026d8ba",
            "type": "article",
            "title": "LimAgents: Multi-Agent LLMs for Generating Research Limitations",
            "summary": "arXiv:2601.11578v1 Announce Type: new Abstract: Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial",
            "url": "https://arxiv.org/abs/2601.11578",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-c224b7d9",
            "type": "article",
            "title": "Bielik 11B v3: Multilingual Large Language Model for European Languages",
            "summary": "arXiv:2601.11579v1 Announce Type: new Abstract: We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcem",
            "url": "https://arxiv.org/abs/2601.11579",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-33b98c96",
            "type": "article",
            "title": "Speculative Decoding: Performance or Illusion?",
            "summary": "arXiv:2601.11580v1 Announce Type: new Abstract: Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-T",
            "url": "https://arxiv.org/abs/2601.11580",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ea6df1b6",
            "type": "article",
            "title": "Enhancing the QA Model through a Multi-domain Debiasing Framework",
            "summary": "arXiv:2601.11581v1 Announce Type: new Abstract: Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, w",
            "url": "https://arxiv.org/abs/2601.11581",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-86454263",
            "type": "article",
            "title": "Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents",
            "summary": "arXiv:2601.11585v1 Announce Type: new Abstract: Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually ",
            "url": "https://arxiv.org/abs/2601.11585",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-992029d3",
            "type": "article",
            "title": "Towards AGI A Pragmatic Approach Towards Self Evolving Agent",
            "summary": "arXiv:2601.11658v1 Announce Type: new Abstract: Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task",
            "url": "https://arxiv.org/abs/2601.11658",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-4cb52a50",
            "type": "article",
            "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search",
            "summary": "arXiv:2601.11722v1 Announce Type: new Abstract: Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented ",
            "url": "https://arxiv.org/abs/2601.11722",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-be476cfe",
            "type": "article",
            "title": "Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era",
            "summary": "arXiv:2601.11739v1 Announce Type: new Abstract: LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback",
            "url": "https://arxiv.org/abs/2601.11739",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-4b9b6cab",
            "type": "article",
            "title": "LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text",
            "summary": "arXiv:2601.11746v1 Announce Type: new Abstract: Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Lang",
            "url": "https://arxiv.org/abs/2601.11746",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-adb62bd4",
            "type": "article",
            "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation",
            "summary": "arXiv:2601.11758v1 Announce Type: new Abstract: Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-dom",
            "url": "https://arxiv.org/abs/2601.11758",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-9069f128",
            "type": "article",
            "title": "Industry-Aligned Granular Topic Modeling",
            "summary": "arXiv:2601.11762v1 Announce Type: new Abstract: Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling met",
            "url": "https://arxiv.org/abs/2601.11762",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-4da9c8f8",
            "type": "article",
            "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models",
            "summary": "arXiv:2601.11776v1 Announce Type: new Abstract: Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a ful",
            "url": "https://arxiv.org/abs/2601.11776",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-37d20f54",
            "type": "article",
            "title": "Translation as a Scalable Proxy for Multilingual Evaluation",
            "summary": "arXiv:2601.11778v1 Announce Type: new Abstract: The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can tran",
            "url": "https://arxiv.org/abs/2601.11778",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-f569cfbc",
            "type": "article",
            "title": "Beyond Tokens: Concept-Level Training Objectives for LLMs",
            "summary": "arXiv:2601.11791v1 Announce Type: new Abstract: The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \\textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize val",
            "url": "https://arxiv.org/abs/2601.11791",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-58ca41f5",
            "type": "article",
            "title": "TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit",
            "summary": "arXiv:2601.11819v1 Announce Type: new Abstract: Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Alth",
            "url": "https://arxiv.org/abs/2601.11819",
            "source": "arxiv",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-95c475fd",
            "type": "article",
            "title": "Building a community-led future for AI in film with Sundance Institute",
            "summary": "Illustration of a cinematographer filming with a professional video camera mounted on a tripod, positioned next to a studio light and a film clapboard.",
            "url": "https://blog.google/company-news/outreach-and-initiatives/google-org/sundance-institute-ai-education/",
            "source": "blogs",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-0976a6e6",
            "type": "article",
            "title": "How Nano Banana got its name",
            "summary": "A Nano Banana-generated image showing yellow bananas spelling out 'Nano Banana' on a bed of additional yellow bananas",
            "url": "https://blog.google/products-and-platforms/products/gemini/how-nano-banana-got-its-name/",
            "source": "blogs",
            "date": "2026-01-15",
            "trendingScore": 50
        },
        {
            "id": "article-1c3efbc3",
            "type": "article",
            "title": "Learners and educators are AI\u2019s new \u201csuper users\u201d",
            "summary": "Teacher using a computer with students",
            "url": "https://blog.google/products-and-platforms/products/education/our-life-with-ai-2025/",
            "source": "blogs",
            "date": "2026-01-15",
            "trendingScore": 50
        },
        {
            "id": "article-82f3872c",
            "type": "article",
            "title": "Introducing Community Benchmarks on Kaggle",
            "summary": "A drawing of three people working on laptops, with one person's screen showing \"Kaggle Benchmark Results\" with \"Gemini XXXX\" and a large \"PASS\" checkmark.1",
            "url": "https://blog.google/innovation-and-ai/technology/developers-tools/kaggle-community-benchmarks/",
            "source": "blogs",
            "date": "2026-01-14",
            "trendingScore": 50
        },
        {
            "id": "article-0489375a",
            "type": "article",
            "title": "Announcing the winner of the Global AI Film Award",
            "summary": "Zoubeir Jlassi reacts with surprise on stage at the AI Film Awards for the film \"Lily\" by Zoubeir Jlassi. He stands by a trophy podium while Anthony Nakache claps. The background shows the film's title and poster.",
            "url": "https://blog.google/company-news/inside-google/around-the-globe/google-middle-east/winner-of-the-global-ai-film-award/",
            "source": "blogs",
            "date": "2026-01-14",
            "trendingScore": 50
        },
        {
            "id": "article-a81d7cf6",
            "type": "article",
            "title": "AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality",
            "summary": "",
            "url": "https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face",
            "source": "blogs",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-63594910",
            "type": "article",
            "title": "Differential Transformer V2",
            "summary": "",
            "url": "https://huggingface.co/blog/microsoft/diff-attn-v2",
            "source": "blogs",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-4d1007eb",
            "type": "article",
            "title": "Introducing Waypoint-1: Real-time interactive video diffusion from Overworld",
            "summary": "",
            "url": "https://huggingface.co/blog/waypoint-1",
            "source": "blogs",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-f04c2f02",
            "type": "article",
            "title": "Open Responses: What you need to know",
            "summary": "",
            "url": "https://huggingface.co/blog/open-responses",
            "source": "blogs",
            "date": "2026-01-15",
            "trendingScore": 50
        },
        {
            "id": "article-651872a0",
            "type": "article",
            "title": "The era of agentic chaos and how data will save us",
            "summary": "AI agents are moving beyond coding assistants and customer service chatbots into the operational core of the enterprise. The ROI is promising, but autonomy without alignment is a recipe for chaos. Business leaders need to lay the essential foundations now. The agent explosion is coming Agents are independently handling end-to-end processes across lead generation, supply&#8230;",
            "url": "https://www.technologyreview.com/2026/01/20/1130911/the-era-of-agentic-chaos-and-how-data-will-save-us/",
            "source": "blogs",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-f2497feb",
            "type": "article",
            "title": "The UK government is backing AI that can run its own lab experiments",
            "summary": "A number of startups and universities that are building \u201cAI scientists\u201d to design and run experiments in the lab, including robot biologists and chemists, have just won extra funding from the UK government agency that funds moonshot R&#38;D. The competition, set up by ARIA (the Advanced Research and Invention Agency), gives a clear sense of&#8230;",
            "url": "https://www.technologyreview.com/2026/01/20/1131462/the-uk-government-is-backing-ai-scientists-that-can-run-their-own-experiments/",
            "source": "blogs",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-c0152437",
            "type": "article",
            "title": "Going beyond pilots with composable and sovereign AI",
            "summary": "Today marks an inflection point for enterprise AI adoption. Despite billions invested in generative AI, only 5% of integrated pilots deliver measurable business value and nearly one in two companies abandons AI initiatives before reaching production. The bottleneck is not the models themselves. What\u2019s holding enterprises back is the surrounding infrastructure: Limited data accessibility, rigid&#8230;",
            "url": "https://www.technologyreview.com/2026/01/19/1131422/going-beyond-pilots-with-composable-and-sovereign-ai/",
            "source": "blogs",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-37680259",
            "type": "article",
            "title": "Amthropic CEO claims we are 1yr away where AI can do everything SWEs",
            "summary": "",
            "url": "https://twitter.com/i/status/2013682941201678804",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ad9c360f",
            "type": "article",
            "title": "Curl removes bug bounties because of AI slop",
            "summary": "",
            "url": "https://etn.se/index.php/nyheter/72808-curl-removes-bug-bounties.html",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-3742bcc8",
            "type": "article",
            "title": "Understanding Modern AI Is Understanding Embeddings: A Guide for Non-Programmers",
            "summary": "",
            "url": "https://sgnt.ai/p/embeddings-explainer/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-a6348962",
            "type": "article",
            "title": "Show HN: Upgrade from Ralph to Eric for a more autonomous AI",
            "summary": "",
            "url": "https://dbuild.dev/blog/black-hole-from-ralph-to-eric/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-deb8dd33",
            "type": "article",
            "title": "88x31 badge for gen-AI free, 100% human-made works",
            "summary": "",
            "url": "https://aspiz.uk/100percenthuman/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-0f2a3f8c",
            "type": "article",
            "title": "Deutsche Bank says the 'honeymoon is over' for AI \u2013 CNBC",
            "summary": "",
            "url": "https://www.cnbc.com/2026/01/20/deutsche-bank-says-the-honeymoon-is-over-for-ai.html",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-410fc383",
            "type": "article",
            "title": "Google Health AI Overviews Cite YouTube More Than Any Hospital Site",
            "summary": "",
            "url": "https://www.searchenginejournal.com/google-health-ai-overviews-cite-youtube-more-than-any-hospital-site/565110/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-160debc1",
            "type": "article",
            "title": "Can AI Pass Freshman CS? [video]",
            "summary": "",
            "url": "https://www.youtube.com/watch?v=56HJQm5nb0U",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-e59d80ad",
            "type": "article",
            "title": "Air Force One Returns to Joint Base Andrews After 'Minor Electrical Issue'",
            "summary": "",
            "url": "https://www.wsj.com/livecoverage/greenland-trump-tariffs-trade-eu/card/air-force-one-returns-to-joint-base-andrews-after-experiencing-minor-electrical-issue--ORkHbCJhNU4we2wnjKD1",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-c6bef148",
            "type": "article",
            "title": "Incremental AI Adoption for E-Commerce \u2013 Arcturus Labs",
            "summary": "",
            "url": "http://arcturus-labs.com/blog/2026/01/18/incremental-ai-adoption-for-e-commerce/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-bde1b65e",
            "type": "article",
            "title": "Is PSA airlines network down anywhere besides DCA?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46700647",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-7be6f9a6",
            "type": "article",
            "title": "AI startup Humans& raises $480M at $4.5B valuation in seed round",
            "summary": "",
            "url": "https://www.reuters.com/business/ai-startup-humans-raises-480-million-45-billion-valuation-seed-round-2026-01-20/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-17e42680",
            "type": "article",
            "title": "\"AI has taught us that people are excited to replace human beings\"",
            "summary": "",
            "url": "https://www.theguardian.com/technology/2026/jan/19/ed-zitron-on-big-tech-backlash-boom-and-bust-ai-has-taught-us-that-people-are-excited-to-replace-human-beings",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-346f1d09",
            "type": "article",
            "title": "Show HN: LLM-Powered Writing: Trends, Advantages, and Curation to Notion",
            "summary": "",
            "url": "https://blackeagle.cozyai.chat/blog/curate-to-notion.html",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-bdd0bdf2",
            "type": "article",
            "title": "Subject-based weight routing for LLMs (27 days before DeepSeek Engram)",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46701371",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ba5b9f6f",
            "type": "article",
            "title": "LLM architecture has evolved from GPT-2 to GPT-OSS (2025)",
            "summary": "",
            "url": "https://modal.com/blog/gpt-oss-arch",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-d2ca5c11",
            "type": "article",
            "title": "Show HN: Linkedin2md \u2013 Convert LinkedIn Exports to Markdown for LLM Analysis",
            "summary": "",
            "url": "https://linkedin2md.daza.ar",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-e67020d8",
            "type": "article",
            "title": "Show HN: On-Device (Offline) AI SDK for iOS (LLMs, Vision and Stable Diffusion)",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46699734",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ac90d437",
            "type": "article",
            "title": "Sandbox Your AI Dev Tools: A Practical Guide for VMs and Lima",
            "summary": "",
            "url": "https://www.metachris.dev/2025/11/sandbox-your-ai-dev-tools-a-practical-guide-for-vms-and-lima/",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-1641f0f9",
            "type": "article",
            "title": "Ask HN: Why are so many rolling out their own AI/LLM agent sandboxing solution?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46699324",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-7b6d5ab2",
            "type": "article",
            "title": "Ask HN: Have you integrated LLMs into any of your bash scripts or aliases?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46698843",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-1ea5456e",
            "type": "article",
            "title": "Show HN: A curated list of academic papers and resources on Physical AI",
            "summary": "",
            "url": "https://github.com/keon/awesome-physical-ai",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-e9c2f1d2",
            "type": "article",
            "title": "Ask HN: SF founders training for a boxing match \u2013 anyone want in?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46698739",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-3221fc00",
            "type": "article",
            "title": "Looking at the numbers, I'm less productive using AI",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46698729",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-59c936d7",
            "type": "article",
            "title": "CI and LLM Review on Fedora Forge with Forgejo Actions",
            "summary": "",
            "url": "https://www.happyassassin.net/posts/2026/01/19/ci-and-llm-review-on-fedora-forge-with-forgejo-actions/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-54b8ed32",
            "type": "article",
            "title": "LLMs and Your Career",
            "summary": "",
            "url": "https://notes.eatonphil.com/2026-01-19-llms-and-your-career.html",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-50245d9a",
            "type": "article",
            "title": "Show HN: Driftcheck \u2013 Pre-push hook that catches doc/code drift with LLMs",
            "summary": "",
            "url": "https://github.com/deichrenner/driftcheck",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-e2067a7c",
            "type": "article",
            "title": "Show HN: Kuzco \u2013 On-Device AI SDK for iOS (LLMs, Vision and Stable Diffusion)",
            "summary": "",
            "url": "https://kuzco.co/waitlist",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-325ac223",
            "type": "article",
            "title": "Wolfi: Linux OS by Chainguard closed now for OSS",
            "summary": "",
            "url": "https://github.com/orgs/wolfi-dev/discussions/77550",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-9fa2d061",
            "type": "article",
            "title": "Show HN: Train Core ML models from the command line",
            "summary": "",
            "url": "https://github.com/schappim/createml-cli",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 50
        },
        {
            "id": "article-ae54ec3a",
            "type": "article",
            "title": "Libbbf: Bound Book Format, A high-performance container for comics and manga",
            "summary": "",
            "url": "https://github.com/ef1500/libbbf",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 52
        },
        {
            "id": "article-e28edd35",
            "type": "article",
            "title": "Anthropic's original take home assignment open sourced",
            "summary": "",
            "url": "https://github.com/anthropics/original_performance_takehome",
            "source": "hackernews",
            "date": "2026-01-21",
            "trendingScore": 64
        },
        {
            "id": "article-9567c23d",
            "type": "article",
            "title": "WeatherGenerator project aims to recast ML for Earth system modelling",
            "summary": "",
            "url": "https://www.ecmwf.int/en/about/media-centre/news/2024/weathergenerator-project-aims-recast-machine-learning-earth-system",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-3bb08cde",
            "type": "article",
            "title": "Show HN: Created an AI for myself to achieve goals, it might help you guys too",
            "summary": "",
            "url": "https://zropi.com",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-fef345ee",
            "type": "article",
            "title": "Show HN: A 6.9B Moe LLM in Rust, Go, and Python",
            "summary": "",
            "url": "https://github.com/fumi-engineer/machine_learning",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-611c79d6",
            "type": "article",
            "title": "Anything Will Work (In AI)",
            "summary": "",
            "url": "https://publish.obsidian.md/ueaj/Machine+Learning/Theory/Anything+WILL+work",
            "source": "hackernews",
            "date": "2026-01-17",
            "trendingScore": 50
        },
        {
            "id": "article-ec34be3d",
            "type": "article",
            "title": "Generating Shakespeare Without Neural Networks",
            "summary": "",
            "url": "https://nathan.rs/posts/shakespeare-n-gram/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-bcd73599",
            "type": "article",
            "title": "DiffusionBlocks: Block-Wise Neural Network Training",
            "summary": "",
            "url": "https://arxiv.org/abs/2506.14202",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-f0f14da7",
            "type": "article",
            "title": "The Convolutional Neural Network",
            "summary": "",
            "url": "https://cocakoala.substack.com/p/the-convolutional-neural-network",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-684ce99c",
            "type": "article",
            "title": "Exploring hard-constrained PINNs for real-time industrial control",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46672660",
            "source": "hackernews",
            "date": "2026-01-18",
            "trendingScore": 50
        },
        {
            "id": "article-d679d1bf",
            "type": "article",
            "title": "Show HN: Tiny Toy Network \u2013 a neural net to practice backpropagation",
            "summary": "",
            "url": "https://hollyemblem.github.io/tiny-toy-network/",
            "source": "hackernews",
            "date": "2026-01-18",
            "trendingScore": 50
        },
        {
            "id": "article-a0735af6",
            "type": "article",
            "title": "Batmobile: 10-20x Faster CUDA Kernels for Equivariant Graph Neural Networks",
            "summary": "",
            "url": "https://elliotarledge.com/blog/batmobile",
            "source": "hackernews",
            "date": "2026-01-18",
            "trendingScore": 50
        },
        {
            "id": "article-a6cc62f4",
            "type": "article",
            "title": "Show HN: Why Neural Networks Need He Init, Clipping, and Momentum",
            "summary": "",
            "url": "https://sbondaryev.dev/articles/he-init-clipping-momentum",
            "source": "hackernews",
            "date": "2026-01-15",
            "trendingScore": 50
        },
        {
            "id": "article-d05c02ec",
            "type": "article",
            "title": "Show HN: I figured out how to get consistent UI from Claude Code",
            "summary": "",
            "url": "https://interface-design.dev/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 51
        },
        {
            "id": "article-7323b1ea",
            "type": "article",
            "title": "Ask HN: What have you built/shipped with Claude-code",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46699204",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-bac4a2c9",
            "type": "article",
            "title": "Claude Chill: Fix Claude Code's flickering in terminal",
            "summary": "",
            "url": "https://github.com/davidbeesley/claude-chill",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 64
        },
        {
            "id": "article-60596b21",
            "type": "article",
            "title": "Show HN: WhoDB CLI \u2013 Terminal database client (Golang) with local AI support",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46697475",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-9dbb5010",
            "type": "article",
            "title": "Show HN: Run Claude Code from WhatsApp",
            "summary": "",
            "url": "https://github.com/gokapso/claude-code-whatsapp",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-967d60a5",
            "type": "article",
            "title": "Claude Code as a Sales Guy",
            "summary": "",
            "url": "https://twitter.com/chaaai/status/2013530788676149755",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-7bbce76d",
            "type": "article",
            "title": "Claude Code Browser Automation on Bazzite",
            "summary": "",
            "url": "https://www.schwab.sh/blog/claude-code-browser-bazzite/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-4284d458",
            "type": "article",
            "title": "Things I Learned at the Claude Code NYC Meetup",
            "summary": "",
            "url": "https://benr.build/blog/claude-code-nyc-meetup",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-3b19de80",
            "type": "article",
            "title": "Trying Out Claude Code with Ollama",
            "summary": "",
            "url": "https://slicervm.com/blog/trying-claude-code-with-ollama/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-e41404ec",
            "type": "article",
            "title": "Show HN: PatchPal \u2013 a small, hackable Claude Code\u2013style coding agent in Python",
            "summary": "",
            "url": "https://github.com/amaiya/patchpal",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-73eeb130",
            "type": "article",
            "title": "Show HN: Git-Fit \u2013 A workout app for people bored to death waiting for vibes",
            "summary": "",
            "url": "https://www.git-fit.app/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-691e995d",
            "type": "article",
            "title": "Show HN: Create promo videos for your projects with Claude Code",
            "summary": "",
            "url": "https://github.com/alentodorov/create-promo-video",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-786d914d",
            "type": "article",
            "title": "Humanizer: Claude Code skill that removes signs of AI-generated writing",
            "summary": "",
            "url": "https://github.com/blader/humanizer",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-159d8c7e",
            "type": "article",
            "title": "Show HN: PasteClean \u2013 A small tool to clean ChatGPT output for Outlook and email",
            "summary": "",
            "url": "https://www.pasteclean.app",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-0026a387",
            "type": "article",
            "title": "Show HN: An open-source personal finance simulator with AI features",
            "summary": "",
            "url": "https://www.ignidash.com",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-0f92043b",
            "type": "article",
            "title": "Show HN: AIChatLens \u2013 Save AI chats and snippets locally in the browser",
            "summary": "",
            "url": "https://chromewebstore.google.com/detail/aichatlens-ai-memory-and/edefkcahpidomhojmdacbdagmccggclb",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-933bc434",
            "type": "article",
            "title": "Apple Intelligence Built Atop Google Gemini Seems Like Admitting Defeat",
            "summary": "",
            "url": "https://www.bloomberg.com/news/newsletters/2026-01-19/apple-s-use-of-google-gemini-shows-iphone-s-lack-of-ai-advantage",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-0d29b1cb",
            "type": "article",
            "title": "Show HN: NetUtil \u2013 I Rebuilt Apple's Network Utility Using Claude Code",
            "summary": "",
            "url": "https://www.netutil.app/en/",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-ab2eb633",
            "type": "article",
            "title": "Show HN: BlueMouse \u2013 AI Code Generator with 17-Layer Validation",
            "summary": "",
            "url": "https://github.com/peijun1700/bluemouse",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-8560fd03",
            "type": "article",
            "title": "OSS ChatGPT WebUI \u2013 530 Models, Tools, MCP, Gemini RAG, Image/Audio Gen",
            "summary": "",
            "url": "https://llmspy.org",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-4e42823b",
            "type": "article",
            "title": "I ported the OpenAI Codex review prompts to Gemini CLI",
            "summary": "",
            "url": "https://github.com/grainier/gemini-cli-codex-reviews",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-2cc1892c",
            "type": "article",
            "title": "Show HN: Gemini-live-react \u2013 Real-time voice AI that works in the browser",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46690392",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-21d27cb0",
            "type": "article",
            "title": "AI Californication",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46688573",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-fb91a1ea",
            "type": "article",
            "title": "OpenAI GPT-5.2-Codex (High) vs. Claude Opus 4.5 vs. Gemini 3 Pro (In Production)",
            "summary": "",
            "url": "https://www.tensorlake.ai/blog/gpt5.2-codex-high-vs-opus-4.5-vs-gemini-3-pro",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-e2bff14f",
            "type": "article",
            "title": "Volvo EX60: First Gemini-Powered EV vs. BMW iX3 Alexa+",
            "summary": "",
            "url": "https://www.techradar.com/vehicle-tech/dash-cams/the-worlds-first-gemini-powered-ev-lands-this-week-but-the-volvo-ex60-needs-to-be-better-than-alexa-on-the-bmw-ix3",
            "source": "hackernews",
            "date": "2026-01-20",
            "trendingScore": 50
        },
        {
            "id": "article-54fd7678",
            "type": "article",
            "title": "Ask HN: How worried should I be about running LLM code on my machine?",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46686262",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-71025c92",
            "type": "article",
            "title": "OSS ChatGPT WebUI \u2013 530 Models, Tools, MCP, Gemini RAG, Image/Audio Gen",
            "summary": "",
            "url": "https://llmspy.org/docs/v3",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-d629a671",
            "type": "article",
            "title": "Show HN: ChatGPT Projects wasn't enough, so I built my \"dream notes app\"",
            "summary": "",
            "url": "https://apps.apple.com/us/app/wiz-note-ai-smart-notes/id6757632086",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-c0d0de7f",
            "type": "article",
            "title": "Show HN: Bundle a large codebase for use across multiple LLM apps",
            "summary": "",
            "url": "https://news.ycombinator.com/item?id=46676819",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "article-30ecf124",
            "type": "article",
            "title": "Why the Best AI Systems Are Still So Bad at Pok\u00e9mon",
            "summary": "",
            "url": "https://time.com/7345903/ai-chatgpt-claude-gemini-pokemon/",
            "source": "hackernews",
            "date": "2026-01-19",
            "trendingScore": 50
        },
        {
            "id": "topic-large-language-models",
            "type": "topic",
            "title": "Large Language Models",
            "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
            "connectionCount": 50
        },
        {
            "id": "topic-reinforcement-learning",
            "type": "topic",
            "title": "Reinforcement Learning",
            "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
            "connectionCount": 26
        },
        {
            "id": "topic-nlp",
            "type": "topic",
            "title": "NLP",
            "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
            "connectionCount": 36
        },
        {
            "id": "topic-ai-reasoning",
            "type": "topic",
            "title": "AI Reasoning",
            "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
            "connectionCount": 13
        },
        {
            "id": "topic-fine-tuning",
            "type": "topic",
            "title": "Fine-tuning",
            "summary": "Adapting pre-trained models to specific tasks or domains.",
            "connectionCount": 3
        },
        {
            "id": "topic-multimodal-ai",
            "type": "topic",
            "title": "Multimodal AI",
            "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
            "connectionCount": 2
        },
        {
            "id": "topic-ai-agents",
            "type": "topic",
            "title": "AI Agents",
            "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
            "connectionCount": 16
        },
        {
            "id": "topic-model-efficiency",
            "type": "topic",
            "title": "Model Efficiency",
            "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
            "connectionCount": 7
        },
        {
            "id": "topic-rag",
            "type": "topic",
            "title": "RAG",
            "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
            "connectionCount": 11
        },
        {
            "id": "topic-prompt-engineering",
            "type": "topic",
            "title": "Prompt Engineering",
            "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
            "connectionCount": 7
        },
        {
            "id": "topic-ai-safety",
            "type": "topic",
            "title": "AI Safety",
            "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
            "connectionCount": 5
        },
        {
            "id": "topic-computer-vision",
            "type": "topic",
            "title": "Computer Vision",
            "summary": "AI systems for understanding and processing visual information from images and video.",
            "connectionCount": 12
        },
        {
            "id": "topic-diffusion-models",
            "type": "topic",
            "title": "Diffusion Models",
            "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
            "connectionCount": 4
        },
        {
            "id": "org-aws",
            "type": "organization",
            "title": "AWS",
            "summary": "AWS - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-meta",
            "type": "organization",
            "title": "Meta",
            "summary": "Meta - AI research and development.",
            "connectionCount": 3
        },
        {
            "id": "org-mistral",
            "type": "organization",
            "title": "Mistral",
            "summary": "Mistral - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-google",
            "type": "organization",
            "title": "Google",
            "summary": "Google - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-anthropic",
            "type": "organization",
            "title": "Anthropic",
            "summary": "Anthropic - AI research and development.",
            "connectionCount": 1
        },
        {
            "id": "org-apple",
            "type": "organization",
            "title": "Apple",
            "summary": "Apple - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "org-openai",
            "type": "organization",
            "title": "OpenAI",
            "summary": "OpenAI - AI research and development.",
            "connectionCount": 2
        },
        {
            "id": "model-llama",
            "type": "model",
            "title": "Llama",
            "summary": "Llama AI model.",
            "connectionCount": 2
        },
        {
            "id": "model-mistral",
            "type": "model",
            "title": "Mistral",
            "summary": "Mistral AI model.",
            "connectionCount": 1
        },
        {
            "id": "model-gemini",
            "type": "model",
            "title": "Gemini",
            "summary": "Gemini AI model.",
            "connectionCount": 8
        },
        {
            "id": "model-stable-diffusion",
            "type": "model",
            "title": "Stable Diffusion",
            "summary": "Stable Diffusion AI model.",
            "connectionCount": 2
        },
        {
            "id": "model-claude",
            "type": "model",
            "title": "Claude",
            "summary": "Claude AI model.",
            "connectionCount": 13
        },
        {
            "id": "model-chatgpt",
            "type": "model",
            "title": "ChatGPT",
            "summary": "ChatGPT AI model.",
            "connectionCount": 4
        },
        {
            "id": "model-gpt-5",
            "type": "model",
            "title": "GPT-5",
            "summary": "GPT-5 AI model.",
            "connectionCount": 1
        }
    ],
    "edges": [
        {
            "source": "article-ee750791",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ee750791",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c8e1fb1f",
            "target": "org-aws",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c91c0549",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c91c0549",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c91c0549",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c91c0549",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ca974260",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ca974260",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ca974260",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ca974260",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1c17b47",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-e1c17b47",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-5afaf0e6",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-5e3fa748",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-5e3fa748",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-5e3fa748",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a869becd",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-a869becd",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-a869becd",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a869becd",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb967b9e",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb967b9e",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb967b9e",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb967b9e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-cb967b9e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-808c7113",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-808c7113",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-55bec34c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-55bec34c",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-55bec34c",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-55bec34c",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-4baeba5e",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-4baeba5e",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-509c3a60",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-509c3a60",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-509c3a60",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-509c3a60",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-509c3a60",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-59e9cc5b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-59e9cc5b",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7242e263",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7242e263",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-03401201",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-03401201",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-03401201",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7c10b92b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-7c10b92b",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7c10b92b",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-7c10b92b",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-cd89a890",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-cd89a890",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-cd89a890",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-9b4dec1e",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-9b4dec1e",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-9b4dec1e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c4219dd6",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c4219dd6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c4219dd6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-418db2e4",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-418db2e4",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-418db2e4",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-96fdaaea",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6de3b920",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-6de3b920",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e37c4dc9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e37c4dc9",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-e37c4dc9",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-fc52275a",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-fc52275a",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fc52275a",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d65f2810",
            "target": "topic-multimodal-ai",
            "relationship": "COVERS"
        },
        {
            "source": "article-86048130",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-86048130",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-86048130",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-72945253",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-72945253",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-0e16a322",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-0e16a322",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-7824794b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-427ebd4b",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-427ebd4b",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-162c5b29",
            "target": "org-aws",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-6a8aa192",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-29d11910",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-29d11910",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-29d11910",
            "target": "org-meta",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ea565150",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ea565150",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-0415fb26",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-0415fb26",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-905b0a64",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-905b0a64",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-905b0a64",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-9c9497ef",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-9c9497ef",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-9c9497ef",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-9c9497ef",
            "target": "model-llama",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0fee3d0b",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-0fee3d0b",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-0fee3d0b",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-ab07b3ac",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ab07b3ac",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-8e051fdc",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-8e051fdc",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-8e051fdc",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-e85800ec",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e85800ec",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-e85800ec",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-d026d8ba",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c224b7d9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-c224b7d9",
            "target": "topic-fine-tuning",
            "relationship": "COVERS"
        },
        {
            "source": "article-c224b7d9",
            "target": "org-mistral",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c224b7d9",
            "target": "model-mistral",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-33b98c96",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-33b98c96",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ea6df1b6",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ea6df1b6",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-86454263",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-86454263",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-86454263",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-86454263",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-86454263",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-992029d3",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-992029d3",
            "target": "topic-ai-reasoning",
            "relationship": "COVERS"
        },
        {
            "source": "article-992029d3",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-992029d3",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-992029d3",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4cb52a50",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-4cb52a50",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-4cb52a50",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-be476cfe",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b9b6cab",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4b9b6cab",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-adb62bd4",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-9069f128",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4da9c8f8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4da9c8f8",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-4da9c8f8",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-37d20f54",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-37d20f54",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-f569cfbc",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-f569cfbc",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-95c475fd",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-0976a6e6",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-0976a6e6",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-1c3efbc3",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-82f3872c",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0489375a",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-a81d7cf6",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-63594910",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4d1007eb",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-4d1007eb",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-4d1007eb",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-651872a0",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-651872a0",
            "target": "topic-ai-safety",
            "relationship": "COVERS"
        },
        {
            "source": "article-651872a0",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c0152437",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-c0152437",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-ad9c360f",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-a6348962",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-410fc383",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-160debc1",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-bde1b65e",
            "target": "topic-reinforcement-learning",
            "relationship": "COVERS"
        },
        {
            "source": "article-346f1d09",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-bdd0bdf2",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-ba5b9f6f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d2ca5c11",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e67020d8",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e67020d8",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e67020d8",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e67020d8",
            "target": "model-stable-diffusion",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-1641f0f9",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-1641f0f9",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-7b6d5ab2",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-59c936d7",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-54b8ed32",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-50245d9a",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e2067a7c",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e2067a7c",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-e2067a7c",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-e2067a7c",
            "target": "model-stable-diffusion",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ae54ec3a",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-e28edd35",
            "target": "org-anthropic",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9567c23d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-fef345ee",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-fef345ee",
            "target": "topic-model-efficiency",
            "relationship": "COVERS"
        },
        {
            "source": "article-ec34be3d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-bcd73599",
            "target": "topic-diffusion-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-d05c02ec",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-7323b1ea",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-bac4a2c9",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-9dbb5010",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-967d60a5",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-7bbce76d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4284d458",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-3b19de80",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-3b19de80",
            "target": "model-llama",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e41404ec",
            "target": "topic-ai-agents",
            "relationship": "COVERS"
        },
        {
            "source": "article-e41404ec",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-691e995d",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-691e995d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-786d914d",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-786d914d",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-159d8c7e",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-933bc434",
            "target": "org-google",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-933bc434",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-933bc434",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0d29b1cb",
            "target": "org-apple",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-0d29b1cb",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-ab2eb633",
            "target": "topic-nlp",
            "relationship": "COVERS"
        },
        {
            "source": "article-8560fd03",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-8560fd03",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-8560fd03",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-8560fd03",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4e42823b",
            "target": "topic-prompt-engineering",
            "relationship": "COVERS"
        },
        {
            "source": "article-4e42823b",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-4e42823b",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-2cc1892c",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fb91a1ea",
            "target": "org-openai",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fb91a1ea",
            "target": "model-gpt-5",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fb91a1ea",
            "target": "model-claude",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-fb91a1ea",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-e2bff14f",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-54fd7678",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "article-71025c92",
            "target": "topic-rag",
            "relationship": "COVERS"
        },
        {
            "source": "article-71025c92",
            "target": "topic-computer-vision",
            "relationship": "COVERS"
        },
        {
            "source": "article-71025c92",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-71025c92",
            "target": "model-gemini",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-d629a671",
            "target": "model-chatgpt",
            "relationship": "MENTIONS"
        },
        {
            "source": "article-c0d0de7f",
            "target": "topic-large-language-models",
            "relationship": "COVERS"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-reasoning",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-ai-agents",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-large-language-models",
            "target": "topic-rag",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-multimodal-ai",
            "target": "topic-computer-vision",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-agents",
            "target": "topic-prompt-engineering",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-model-efficiency",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        },
        {
            "source": "topic-ai-safety",
            "target": "topic-large-language-models",
            "relationship": "RELATED_TO"
        }
    ]
};

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = AIChronicleData;
}
