{
  "metadata": {
    "lastUpdated": "2026-02-09T07:02:38.781788Z",
    "totalArticles": 145,
    "totalNodes": 174,
    "totalEdges": 252,
    "dateRange": {
      "start": "2026-02-02",
      "end": "2026-02-09"
    }
  },
  "nodes": [
    {
      "id": "article-da30a056",
      "type": "article",
      "title": "Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning",
      "summary": "arXiv:2602.06107v1 Announce Type: new Abstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to ",
      "url": "https://arxiv.org/abs/2602.06107",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-728b2ef6",
      "type": "article",
      "title": "Large Language Model Reasoning Failures",
      "summary": "arXiv:2602.06176v1 Announce Type: new Abstract: Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distingui",
      "url": "https://arxiv.org/abs/2602.06176",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-c4ddfee3",
      "type": "article",
      "title": "Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)",
      "summary": "arXiv:2602.06227v1 Announce Type: new Abstract: In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a more expressive extension of classical temporal logic in which predicates are first-order formulas of arbitrary first-order theories rather than simple Boolean variables. This enhanced expressiveness e",
      "url": "https://arxiv.org/abs/2602.06227",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-67f4a4b0",
      "type": "article",
      "title": "Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making",
      "summary": "arXiv:2602.06286v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult to interpret. We study whether LLMs are rational utility maximizers with coherent beliefs and stable preferences. We consider behaviors of models for diagnosis challenge problems. The results provide in",
      "url": "https://arxiv.org/abs/2602.06286",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-ab99fb7d",
      "type": "article",
      "title": "Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems",
      "summary": "arXiv:2602.06319v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult to verify programmatically. We introduce GrAlgoBench, a benchmark designed to evaluate LRMs through graph algorithm problems. Such problems are particularly well suited for probing reasoning abilities:",
      "url": "https://arxiv.org/abs/2602.06319",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d404fbd2",
      "type": "article",
      "title": "Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion",
      "summary": "arXiv:2602.06351v1 Announce Type: new Abstract: GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale GUI datasets to predict target element coordinates, which is data-intensive and generalizes poorly to unseen interfaces. Recent attention-based alternatives exploit localization signals in MLLMs attenti",
      "url": "https://arxiv.org/abs/2602.06351",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-cd2353eb",
      "type": "article",
      "title": "Difficulty-Estimated Policy Optimization",
      "summary": "arXiv:2602.06375v1 Announce Type: new Abstract: Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are either too trivial or overly complex. In these scenarios, the disappearance of inter-group advantages makes the gradient signal susceptible to noise, th",
      "url": "https://arxiv.org/abs/2602.06375",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6180721a",
      "type": "article",
      "title": "Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization",
      "summary": "arXiv:2602.06394v1 Announce Type: new Abstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning ",
      "url": "https://arxiv.org/abs/2602.06394",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d32202f3",
      "type": "article",
      "title": "Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution",
      "summary": "arXiv:2602.06413v1 Announce Type: new Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute this phenomenon to task complexity, such as combinatorial search explosion or long-term credit assignment challenges. In this work, we argue that these explanations are incomplete: even in linear, unbran",
      "url": "https://arxiv.org/abs/2602.06413",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6ecdbc85",
      "type": "article",
      "title": "AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents",
      "summary": "arXiv:2602.06485v1 Announce Type: new Abstract: While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on training agentic models at the 4B-parameter scale. We identify three primary bottlenecks hindering the performance of edge-scale models: catastrophic forgettin",
      "url": "https://arxiv.org/abs/2602.06485",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-95160de8",
      "type": "article",
      "title": "JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks",
      "summary": "arXiv:2602.06486v1 Announce Type: new Abstract: Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge approaches adapt to individual responses yet suffer from instability and bias. Human experts address this dilemma by combining domain-grounded principles with dynamic, claim-level assessment. Inspired ",
      "url": "https://arxiv.org/abs/2602.06486",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-f9b4f2a9",
      "type": "article",
      "title": "Progress Constraints for Reinforcement Learning in Behavior Trees",
      "summary": "arXiv:2602.06525v1 Announce Type: new Abstract: Behavior Trees (BTs) provide a structured and reactive framework for decision-making, commonly used to switch between sub-controllers based on environmental conditions. Reinforcement Learning (RL), on the other hand, can learn near-optimal controllers but sometimes struggles with sparse rewards, safe exploration, and long-horizon credit assignment. Combining BTs with RL has the potential for mutual benefit: a BT design encodes structured domain kno",
      "url": "https://arxiv.org/abs/2602.06525",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-55029307",
      "type": "article",
      "title": "HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction",
      "summary": "arXiv:2602.06527v1 Announce Type: new Abstract: Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansion rules that interfere with post-trained reasoning, while parallel reasoning over-explores redundant hypothesis paths and relies on weak answer selectio",
      "url": "https://arxiv.org/abs/2602.06527",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-3983eeee",
      "type": "article",
      "title": "LogicSkills: A Structured Benchmark for Formal Reasoning in Large Language Models",
      "summary": "arXiv:2602.06533v1 Announce Type: new Abstract: Large language models have demonstrated notable performance across various logical reasoning benchmarks. However, it remains unclear which core logical skills they truly master. To address this, we introduce LogicSkills, a unified benchmark designed to isolate three fundamental skills in formal reasoning: (i) $\\textit{formal symbolization}\\unicode{x2014}$translating premises into first-order logic; (ii) $\\textit{countermodel construction}\\unicode{x",
      "url": "https://arxiv.org/abs/2602.06533",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-c6cc0ef0",
      "type": "article",
      "title": "AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research",
      "summary": "arXiv:2602.06540v1 Announce Type: new Abstract: Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the initial outline. However, constructing a comprehensive outline itself demands strong reasoning ability, causing current deep research systems to rely al",
      "url": "https://arxiv.org/abs/2602.06540",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-84755e56",
      "type": "article",
      "title": "SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees",
      "summary": "arXiv:2602.06554v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies. In this paper, we systematically analyze how different combinations of policy update mechanisms and advantag",
      "url": "https://arxiv.org/abs/2602.06554",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-1f031ed5",
      "type": "article",
      "title": "Same Answer, Different Representations: Hidden instability in VLMs",
      "summary": "arXiv:2602.06652v1 Announce Type: new Abstract: The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), al",
      "url": "https://arxiv.org/abs/2602.06652",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-7e34db60",
      "type": "article",
      "title": "Autoregressive Models for Knowledge Graph Generation",
      "summary": "arXiv:2602.06707v1 Announce Type: new Abstract: Knowledge Graph (KG) generation requires models to learn complex semantic dependencies between triples while maintaining domain validity constraints. Unlike link prediction, which scores triples independently, generative models must capture interdependencies across entire subgraphs to produce semantically coherent structures. We present ARK (Auto-Regressive Knowledge Graph Generation), a family of autoregressive models that generate KGs by treating",
      "url": "https://arxiv.org/abs/2602.06707",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-984d3324",
      "type": "article",
      "title": "Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions",
      "summary": "arXiv:2602.06746v1 Announce Type: new Abstract: We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new genera",
      "url": "https://arxiv.org/abs/2602.06746",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d29c9ae8",
      "type": "article",
      "title": "Towards Understanding What State Space Models Learn About Code",
      "summary": "arXiv:2602.06774v1 Announce Type: new Abstract: State Space Models (SSMs) have emerged as an efficient alternative to the transformer architecture. Recent studies show that SSMs can match or surpass Transformers on code understanding tasks, such as code retrieval, when trained under similar conditions. However, their internal mechanisms remain a black box. We present the first systematic analysis of what SSM-based code models actually learn and perform the first comparative analysis of SSM and T",
      "url": "https://arxiv.org/abs/2602.06774",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-9afef7c2",
      "type": "article",
      "title": "NanoNet: Parameter-Efficient Learning with Label-Scarce Supervision for Lightweight Text Mining Model",
      "summary": "arXiv:2602.06093v1 Announce Type: new Abstract: The lightweight semi-supervised learning (LSL) strategy provides an effective approach of conserving labeled samples and minimizing model inference costs. Prior research has effectively applied knowledge transfer learning and co-training regularization from large to small models in LSL. However, such training strategies are computationally intensive and prone to local optima, thereby increasing the difficulty of finding the optimal solution. This h",
      "url": "https://arxiv.org/abs/2602.06093",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-34fcf70d",
      "type": "article",
      "title": "Agentic Workflow Using RBA$_\\theta$ for Event Prediction",
      "summary": "arXiv:2602.06097v1 Announce Type: new Abstract: Wind power ramp events are difficult to forecast due to strong variability, multi-scale dynamics, and site-specific meteorological effects. This paper proposes an event-first, frequency-aware forecasting paradigm that directly predicts ramp events and reconstructs the power trajectory thereafter, rather than inferring events from dense forecasts. The framework is built on an enhanced Ramping Behaviour Analysis (RBA$_\\theta$) method's event represen",
      "url": "https://arxiv.org/abs/2602.06097",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-b26c443e",
      "type": "article",
      "title": "Toward Faithful and Complete Answer Construction from a Single Document",
      "summary": "arXiv:2602.06103v1 Announce Type: new Abstract: Modern large language models (LLMs) are powerful generators driven by statistical next-token prediction. While effective at producing fluent text, this design biases models toward high-probability continuations rather than exhaustive and faithful answers grounded in source content. As a result, directly applying LLMs lacks systematic mechanisms to ensure both completeness (avoiding omissions) and faithfulness (avoiding unsupported content), which f",
      "url": "https://arxiv.org/abs/2602.06103",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-2444be99",
      "type": "article",
      "title": "Pragmatic Curiosity: A Hybrid Learning-Optimization Paradigm via Active Inference",
      "summary": "arXiv:2602.06104v1 Announce Type: new Abstract: Many engineering and scientific workflows depend on expensive black-box evaluations, requiring decision-making that simultaneously improves performance and reduces uncertainty. Bayesian optimization (BO) and Bayesian experimental design (BED) offer powerful yet largely separate treatments of goal-seeking and information-seeking, providing limited guidance for hybrid settings where learning and optimization are intrinsically coupled. We propose \"pra",
      "url": "https://arxiv.org/abs/2602.06104",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d44114a6",
      "type": "article",
      "title": "Private and interpretable clinical prediction with quantum-inspired tensor train models",
      "summary": "arXiv:2602.06110v1 Announce Type: new Abstract: Machine learning in clinical settings must balance predictive accuracy, interpretability, and privacy. Models such as logistic regression (LR) offer transparency, while neural networks (NNs) provide greater predictive power; yet both remain vulnerable to privacy attacks. We empirically assess these risks by designing attacks that identify which public datasets were used to train a model under varying levels of adversarial access, applying them to L",
      "url": "https://arxiv.org/abs/2602.06110",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-520c9a50",
      "type": "article",
      "title": "Compressing LLMs with MoP: Mixture of Pruners",
      "summary": "arXiv:2602.06127v1 Announce Type: new Abstract: The high computational demands of Large Language Models (LLMs) motivate methods that reduce parameter count and accelerate inference. In response, model pruning emerges as an effective strategy, yet current methods typically focus on a single dimension-depth or width. We introduce MoP (Mixture of Pruners), an iterative framework that unifies these dimensions. At each iteration, MoP generates two branches-pruning in depth versus pruning in width-and",
      "url": "https://arxiv.org/abs/2602.06127",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-1b6fbfab",
      "type": "article",
      "title": "Urban Spatio-Temporal Foundation Models for Climate-Resilient Housing: Scaling Diffusion Transformers for Disaster Risk Prediction",
      "summary": "arXiv:2602.06129v1 Announce Type: new Abstract: Climate hazards increasingly disrupt urban transportation and emergency-response operations by damaging housing stock, degrading infrastructure, and reducing network accessibility. This paper presents Skjold-DiT, a diffusion-transformer framework that integrates heterogeneous spatio-temporal urban data to forecast building-level climate-risk indicators while explicitly incorporating transportation-network structure and accessibility signals relevan",
      "url": "https://arxiv.org/abs/2602.06129",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6493789b",
      "type": "article",
      "title": "Self-Improving World Modelling with Latent Actions",
      "summary": "arXiv:2602.06130v1 Announce Type: new Abstract: Internal modelling of the world -- predicting transitions between previous states $X$ and next states $Y$ under actions $Z$ -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled trajectories. We propose SWIRL, a self-improvement framework that learns from state-only sequences by treating actions as a latent variable and alternating between Forward World Modelling (FWM) $P_\\theta(",
      "url": "https://arxiv.org/abs/2602.06130",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-e7634c46",
      "type": "article",
      "title": "Tempora: Characterising the Time-Contingent Utility of Online Test-Time Adaptation",
      "summary": "arXiv:2602.06136v1 Announce Type: new Abstract: Test-time adaptation (TTA) offers a compelling remedy for machine learning (ML) models that degrade under domain shifts, improving generalisation on-the-fly with only unlabelled samples. This flexibility suits real deployments, yet conventional evaluations unrealistically assume unbounded processing time, overlooking the accuracy-latency trade-off. As ML increasingly underpins latency-sensitive and user-facing use-cases, temporal pressure constrain",
      "url": "https://arxiv.org/abs/2602.06136",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-0abf7900",
      "type": "article",
      "title": "Flow Matching for Offline Reinforcement Learning with Discrete Actions",
      "summary": "arXiv:2602.06138v1 Announce Type: new Abstract: Generative policies based on diffusion models and flow matching have shown strong promise for offline reinforcement learning (RL), but their applicability remains largely confined to continuous action spaces. To address a broader range of offline RL settings, we extend flow matching to a general framework that supports discrete action spaces with multiple objectives. Specifically, we replace continuous flows with continuous-time Markov chains, trai",
      "url": "https://arxiv.org/abs/2602.06138",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-668fb88a",
      "type": "article",
      "title": "Optimistic Training and Convergence of Q-Learning -- Extended Version",
      "summary": "arXiv:2602.06146v1 Announce Type: new Abstract: In recent work it is shown that Q-learning with linear function approximation is stable, in the sense of bounded parameter estimates, under the $(\\varepsilon,\\kappa)$-tamed Gibbs policy; $\\kappa$ is inverse temperature, and $\\varepsilon>0$ is introduced for additional exploration. Under these assumptions it also follows that there is a solution to the projected Bellman equation (PBE). Left open is uniqueness of the solution, and criteria for conver",
      "url": "https://arxiv.org/abs/2602.06146",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-27896bb0",
      "type": "article",
      "title": "MoSE: Mixture of Slimmable Experts for Efficient and Adaptive Language Models",
      "summary": "arXiv:2602.06154v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) models scale large language models efficiently by sparsely activating experts, but once an expert is selected, it is executed fully. Hence, the trade-off between accuracy and computation in an MoE model typically exhibits large discontinuities. We propose Mixture of Slimmable Experts (MoSE), an MoE architecture in which each expert has a nested, slimmable structure that can be executed at variable widths. This enables condi",
      "url": "https://arxiv.org/abs/2602.06154",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-9312d4a1",
      "type": "article",
      "title": "Latent Structure Emergence in Diffusion Models via Confidence-Based Filtering",
      "summary": "arXiv:2602.06155v1 Announce Type: new Abstract: Diffusion models rely on a high-dimensional latent space of initial noise seeds, yet it remains unclear whether this space contains sufficient structure to predict properties of the generated samples, such as their classes. In this work, we investigate the emergence of latent structure through the lens of confidence scores assigned by a pre-trained classifier to generated samples. We show that while the latent space appears largely unstructured whe",
      "url": "https://arxiv.org/abs/2602.06155",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-9405cc73",
      "type": "article",
      "title": "SCONE: A Practical, Constraint-Aware Plug-in for Latent Encoding in Learned DNA Storage",
      "summary": "arXiv:2602.06157v1 Announce Type: new Abstract: DNA storage has matured from concept to practical stage, yet its integration with neural compression pipelines remains inefficient. Early DNA encoders applied redundancy-heavy constraint layers atop raw binary data - workable but primitive. Recent neural codecs compress data into learned latent representations with rich statistical structure, yet still convert these latents to DNA via naive binary-to-quaternary transcoding, discarding the entropy m",
      "url": "https://arxiv.org/abs/2602.06157",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-4211949a",
      "type": "article",
      "title": "To 2:4 Sparsity and Beyond: Neuron-level Activation Function to Accelerate LLM Pre-Training",
      "summary": "arXiv:2602.06183v1 Announce Type: new Abstract: Trainings of Large Language Models are generally bottlenecked by matrix multiplications. In the Transformer architecture, a large portion of these operations happens in the Feed Forward Network (FFN), and this portion increases for larger models, up to 50% of the total pretraining floating point operations. We show that we can leverage hardware-accelerated sparsity to accelerate all matrix multiplications in the FFN, with 2:4 sparsity for weights a",
      "url": "https://arxiv.org/abs/2602.06183",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-3dd30bbc",
      "type": "article",
      "title": "$f$-FUM: Federated Unlearning via min--max and $f$-divergence",
      "summary": "arXiv:2602.06187v1 Announce Type: new Abstract: Federated Learning (FL) has emerged as a powerful paradigm for collaborative machine learning across decentralized data sources, preserving privacy by keeping data local. However, increasing legal and ethical demands, such as the \"right to be forgotten\", and the need to mitigate data poisoning attacks have underscored the urgent necessity for principled data unlearning in FL. Unlike centralized settings, the distributed nature of FL complicates the",
      "url": "https://arxiv.org/abs/2602.06187",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-dc903561",
      "type": "article",
      "title": "Learning Rate Scaling across LoRA Ranks and Transfer to Full Finetuning",
      "summary": "arXiv:2602.06204v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) is a standard tool for parameter-efficient finetuning of large models. While it induces a small memory footprint, its training dynamics can be surprisingly complex as they depend on several hyperparameters such as initialization, adapter rank, and learning rate. In particular, it is unclear how the optimal learning rate scales with adapter rank, which forces practitioners to re-tune the learning rate whenever the rank is ",
      "url": "https://arxiv.org/abs/2602.06204",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-b1a0cd3b",
      "type": "article",
      "title": "Multi-Way Representation Alignment",
      "summary": "arXiv:2602.06205v1 Announce Type: new Abstract: The Platonic Representation Hypothesis suggests that independently trained neural networks converge to increasingly similar latent spaces. However, current strategies for mapping these representations are inherently pairwise, scaling quadratically with the number of models and failing to yield a consistent global reference. In this paper, we study the alignment of $M \\ge 3$ models. We first adapt Generalized Procrustes Analysis (GPA) to construct a",
      "url": "https://arxiv.org/abs/2602.06205",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-18a413eb",
      "type": "article",
      "title": "Emergent Low-Rank Training Dynamics in MLPs with Smooth Activations",
      "summary": "arXiv:2602.06208v1 Announce Type: new Abstract: Recent empirical evidence has demonstrated that the training dynamics of large-scale deep neural networks occur within low-dimensional subspaces. While this has inspired new research into low-rank training, compression, and adaptation, theoretical justification for these dynamics in nonlinear networks remains limited. %compared to deep linear settings. To address this gap, this paper analyzes the learning dynamics of multi-layer perceptrons (MLPs) ",
      "url": "https://arxiv.org/abs/2602.06208",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-667f8afa",
      "type": "article",
      "title": "SR4-Fit: An Interpretable and Informative Classification Algorithm Applied to Prediction of U.S. House of Representatives Elections",
      "summary": "arXiv:2602.06229v1 Announce Type: new Abstract: The growth of machine learning demands interpretable models for critical applications, yet most high-performing models are ``black-box'' systems that obscure input-output relationships, while traditional rule-based algorithms like RuleFit suffer from a lack of predictive power and instability despite their simplicity. This motivated our development of Sparse Relaxed Regularized Regression Rule-Fit (SR4-Fit), a novel interpretable classification alg",
      "url": "https://arxiv.org/abs/2602.06229",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-88d9397a",
      "type": "article",
      "title": "Recontextualizing Famous Quotes for Brand Slogan Generation",
      "summary": "arXiv:2602.06049v1 Announce Type: new Abstract: Slogans are concise and memorable catchphrases that play a crucial role in advertising by conveying brand identity and shaping public perception. However, advertising fatigue reduces the effectiveness of repeated slogans, creating a growing demand for novel, creative, and insightful slogan generation. While recent work leverages large language models (LLMs) for this task, existing approaches often produce stylistically redundant outputs that lack a",
      "url": "https://arxiv.org/abs/2602.06049",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6d4baa69",
      "type": "article",
      "title": "Relevance-aware Multi-context Contrastive Decoding for Retrieval-augmented Visual Question Answering",
      "summary": "arXiv:2602.06050v1 Announce Type: new Abstract: Despite the remarkable capabilities of Large Vision Language Models (LVLMs), they still lack detailed knowledge about specific entities. Retrieval-augmented Generation (RAG) is a widely adopted solution that enhances LVLMs by providing additional contexts from an external Knowledge Base. However, we observe that previous decoding methods for RAG are sub-optimal as they fail to sufficiently leverage multiple relevant contexts and suppress the negati",
      "url": "https://arxiv.org/abs/2602.06050",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-a7dc01c4",
      "type": "article",
      "title": "CAST: Character-and-Scene Episodic Memory for Agents",
      "summary": "arXiv:2602.06051v1 Announce Type: new Abstract: Episodic memory is a central component of human memory, which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent memory systems only emphasize semantic recall and treat experience as structures such as key-value, vector, or graph, which makes them struggle to represent and retrieve coherent events. To address this challenge, we propose a Character-and-Scene based memory architecture(CAST) inspired ",
      "url": "https://arxiv.org/abs/2602.06051",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6e329c8a",
      "type": "article",
      "title": "Rethinking Memory Mechanisms of Foundation Agents in the Second Half",
      "summary": "arXiv:2602.06052v1 Announce Type: new Abstract: The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the \"second half,\" the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively reuse large v",
      "url": "https://arxiv.org/abs/2602.06052",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-63cb9a04",
      "type": "article",
      "title": "PersonaPlex: Voice and Role Control for Full Duplex Conversational Speech Models",
      "summary": "arXiv:2602.06053v1 Announce Type: new Abstract: Recent advances in duplex speech models have enabled natural, low-latency speech-to-speech interactions. However, existing models are restricted to a fixed role and voice, limiting their ability to support structured, role-driven real-world applications and personalized interactions. In this work, we introduce PersonaPlex, a duplex conversational speech model that incorporates hybrid system prompts, combining role conditioning with text prompts and",
      "url": "https://arxiv.org/abs/2602.06053",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-cdcc7fa1",
      "type": "article",
      "title": "What Is Novel? A Knowledge-Driven Framework for Bias-Aware Literature Originality Evaluation",
      "summary": "arXiv:2602.06054v1 Announce Type: new Abstract: Assessing research novelty is a core yet highly subjective aspect of peer review, typically based on implicit judgment and incomplete comparison to prior work. We introduce a literature-aware novelty assessment framework that explicitly learns how humans judge novelty from peer-review reports and grounds these judgments in structured comparison to existing research. Using nearly 80K novelty-annotated reviews from top-tier AI conferences, we fine-tu",
      "url": "https://arxiv.org/abs/2602.06054",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-62cd634c",
      "type": "article",
      "title": "Quantifying and Attributing Polarization to Annotator Groups",
      "summary": "arXiv:2602.06055v1 Announce Type: new Abstract: Current annotation agreement metrics are not well-suited for inter-group analysis, are sensitive to group size imbalances and restricted to single-annotation settings. These restrictions render them insufficient for many subjective tasks such as toxicity and hate-speech detection. For this reason, we introduce a quantifiable metric, paired with a statistical significance test, that attributes polarization to various annotator groups. Our metric ena",
      "url": "https://arxiv.org/abs/2602.06055",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-57570d78",
      "type": "article",
      "title": "Stop the Flip-Flop: Context-Preserving Verification for Fast Revocable Diffusion Decoding",
      "summary": "arXiv:2602.06161v1 Announce Type: new Abstract: Parallel diffusion decoding can accelerate diffusion language model inference by unmasking multiple tokens per step, but aggressive parallelism often harms quality. Revocable decoding mitigates this by rechecking earlier tokens, yet we observe that existing verification schemes frequently trigger flip-flop oscillations, where tokens are remasked and later restored unchanged. This behaviour slows inference in two ways: remasking verified positions w",
      "url": "https://arxiv.org/abs/2602.06161",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-99ef2a3b",
      "type": "article",
      "title": "Uncertainty Drives Social Bias Changes in Quantized Large Language Models",
      "summary": "arXiv:2602.06181v1 Announce Type: new Abstract: Post-training quantization reduces the computational cost of large language models but fundamentally alters their social biases in ways that aggregate metrics fail to capture. We present the first large-scale study of 50 quantized models evaluated on PostTrainingBiasBench, a unified benchmark of 13 closed- and open-ended bias datasets. We identify a phenomenon we term quantization-induced masked bias flipping, in which up to 21% of responses flip b",
      "url": "https://arxiv.org/abs/2602.06181",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-ee32438d",
      "type": "article",
      "title": "BenchMarker: An Education-Inspired Toolkit for Highlighting Flaws in Multiple-Choice Benchmarks",
      "summary": "arXiv:2602.06221v1 Announce Type: new Abstract: Multiple-choice question answering (MCQA) is standard in NLP, but benchmarks lack rigorous quality control. We present BenchMarker, an education-inspired toolkit using LLM judges to flag three common MCQ flaws: 1) contamination - items appearing exactly online; 2) shortcuts - cues in the choices that enable guessing; and 3) writing errors - structural/grammatical issues based on a 19-rule education rubric. We validate BenchMarker with human annotat",
      "url": "https://arxiv.org/abs/2602.06221",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-385e5e86",
      "type": "article",
      "title": "Can One-sided Arguments Lead to Response Change in Large Language Models?",
      "summary": "arXiv:2602.06260v1 Announce Type: new Abstract: Polemic questions need more than one viewpoint to express a balanced answer. Large Language Models (LLMs) can provide a balanced answer, but also take a single aligned viewpoint or refuse to answer. In this paper, we study if such initial responses can be steered to a specific viewpoint in a simple and intuitive way: by only providing one-sided arguments supporting the viewpoint. Our systematic study has three dimensions: (i) which stance is induce",
      "url": "https://arxiv.org/abs/2602.06260",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-3764eaed",
      "type": "article",
      "title": "Is my model \"mind blurting\"? Interpreting the dynamics of reasoning tokens with Recurrence Quantification Analysis (RQA)",
      "summary": "arXiv:2602.06266v1 Announce Type: new Abstract: Test-time compute is central to large reasoning models, yet analysing their reasoning behaviour through generated text is increasingly impractical and unreliable. Response length is often used as a brute proxy for reasoning effort, but this metric fails to capture the dynamics and effectiveness of the Chain of Thoughts (CoT) or the generated tokens. We propose Recurrence Quantification Analysis (RQA) as a non-textual alternative for analysing model",
      "url": "https://arxiv.org/abs/2602.06266",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-75348b96",
      "type": "article",
      "title": "MPIB: A Benchmark for Medical Prompt Injection Attacks and Clinical Safety in LLMs",
      "summary": "arXiv:2602.06268v1 Announce Type: new Abstract: Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly integrated into clinical workflows; however, prompt injection attacks can steer these systems toward clinically unsafe or misleading outputs. We introduce the Medical Prompt Injection Benchmark (MPIB), a dataset-and-benchmark suite for evaluating clinical safety under both direct prompt injection and indirect, RAG-mediated injection across clinically grou",
      "url": "https://arxiv.org/abs/2602.06268",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-c72d78b5",
      "type": "article",
      "title": "VowelPrompt: Hearing Speech Emotions from Text via Vowel-level Prosodic Augmentation",
      "summary": "arXiv:2602.06270v1 Announce Type: new Abstract: Emotion recognition in speech presents a complex multimodal challenge, requiring comprehension of both linguistic content and vocal expressivity, particularly prosodic features such as fundamental frequency, intensity, and temporal dynamics. Although large language models (LLMs) have shown promise in reasoning over textual transcriptions for emotion recognition, they typically neglect fine-grained prosodic information, limiting their effectiveness ",
      "url": "https://arxiv.org/abs/2602.06270",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-e195dcfd",
      "type": "article",
      "title": "RoPE-LIME: RoPE-Space Locality + Sparse-K Sampling for Efficient LLM Attribution",
      "summary": "arXiv:2602.06275v1 Announce Type: new Abstract: Explaining closed-source LLM outputs is challenging because API access prevents gradient-based attribution, while perturbation methods are costly and noisy when they depend on regenerated text. We introduce RoPE-LIME, an open-source extension of gSMILE that decouples reasoning from explanation: given a fixed output from a closed model, a smaller open-source surrogate computes token-level attributions from probability-based objectives (negative log-",
      "url": "https://arxiv.org/abs/2602.06275",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-ef8fd133",
      "type": "article",
      "title": "Judging What We Cannot Solve: A Consequence-Based Approach for Oracle-Free Evaluation of Research-Level Math",
      "summary": "arXiv:2602.06291v1 Announce Type: new Abstract: Recent progress in reasoning models suggests that generating plausible attempts for research-level mathematics may be within reach, but verification remains a bottleneck, consuming scarce expert time. We hypothesize that a meaningful solution should contain enough method-level information that, when applied to a neighborhood of related questions, it should yield better downstream performance than incorrect solutions. Building on this idea, we propo",
      "url": "https://arxiv.org/abs/2602.06291",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-2015ce6d",
      "type": "article",
      "title": "Lost in Speech: Benchmarking, Evaluation, and Parsing of Spoken Code-Switching Beyond Standard UD Assumptions",
      "summary": "arXiv:2602.06307v1 Announce Type: new Abstract: Spoken code-switching (CSW) challenges syntactic parsing in ways not observed in written text. Disfluencies, repetition, ellipsis, and discourse-driven structure routinely violate standard Universal Dependencies (UD) assumptions, causing parsers and large language models (LLMs) to fail despite strong performance on written data. These failures are compounded by rigid evaluation metrics that conflate genuine structural errors with acceptable variati",
      "url": "https://arxiv.org/abs/2602.06307",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-5b622f4e",
      "type": "article",
      "title": "Can Post-Training Transform LLMs into Causal Reasoners?",
      "summary": "arXiv:2602.06337v1 Announce Type: new Abstract: Causal inference is essential for decision-making but remains challenging for non-experts. While large language models (LLMs) show promise in this domain, their precise causal estimation capabilities are still limited, and the impact of post-training on these abilities is insufficiently explored. This paper examines the extent to which post-training can enhance LLMs' capacity for causal inference. We introduce CauGym, a comprehensive dataset compri",
      "url": "https://arxiv.org/abs/2602.06337",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-530cc7a8",
      "type": "article",
      "title": "SHINE: A Scalable In-Context Hypernetwork for Mapping Context to LoRA in a Single Pass",
      "summary": "arXiv:2602.06358v1 Announce Type: new Abstract: We propose SHINE (Scalable Hyper In-context NEtwork), a scalable hypernetwork that can map diverse meaningful contexts into high-quality LoRA adapters for large language models (LLM). By reusing the frozen LLM's own parameters in an in-context hypernetwork design and introducing architectural innovations, SHINE overcomes key limitations of prior hypernetworks and achieves strong expressive power with a relatively small number of parameters. We intr",
      "url": "https://arxiv.org/abs/2602.06358",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d7b0c3b4",
      "type": "article",
      "title": "Cost-Aware Model Selection for Text Classification: Multi-Objective Trade-offs Between Fine-Tuned Encoders and LLM Prompting in Production",
      "summary": "arXiv:2602.06370v1 Announce Type: new Abstract: Large language models (LLMs) such as GPT-4o and Claude Sonnet 4.5 have demonstrated strong capabilities in open-ended reasoning and generative language tasks, leading to their widespread adoption across a broad range of NLP applications. However, for structured text classification problems with fixed label spaces, model selection is often driven by predictive performance alone, overlooking operational constraints encountered in production systems. ",
      "url": "https://arxiv.org/abs/2602.06370",
      "source": "arxiv",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-e42f6ff4",
      "type": "article",
      "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
      "summary": "A collage of four images, the first of a woman with curly hair in front of a silver laptop, the second of the same woman and a man with short black hair speaking on a stairwell, the third of a the same man with glasses, and an aerial image of NTID",
      "url": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-828c66e8",
      "type": "article",
      "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
      "summary": "A woman outdoors in the snow looks at a tablet. A half pipe is behind her.",
      "url": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-f9c339ba",
      "type": "article",
      "title": "Watch our new Gemini ad ahead of football\u2019s biggest weekend",
      "summary": "A toddler in a blue and yellow striped shirt sits on a kitchen counter eating a red apple. Text in the corner reads: 'New Home, Google Gemini SB Commercial\u2019",
      "url": "https://blog.google/company-news/inside-google/company-announcements/gemini-ad-new-home/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-1eabfc9f",
      "type": "article",
      "title": "The latest AI news we announced in January",
      "summary": "mp4 showing a carousel of images including a card reading \"Help that's made for you\"",
      "url": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-a91db779",
      "type": "article",
      "title": "How we\u2019re helping preserve the genetic information of endangered species with AI",
      "summary": "A four-part vertical collage showing a cotton-top tamarin, an ibex, a golden lion tamarin, and a penguin.",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-12f40143",
      "type": "article",
      "title": "Advancing AI benchmarking with Game Arena",
      "summary": "An illustration of a King and Ace playing card, a wolf's head, two chess pieces, a poker chip, and other abstract shapes on a white background.1",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-4b956a17",
      "type": "article",
      "title": "Introducing SyGra Studio",
      "summary": "",
      "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-5a59b4d6",
      "type": "article",
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3\u2019s Top Model",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-54a2e4d6",
      "type": "article",
      "title": "Community Evals: Because we're done trusting black-box leaderboards over the community",
      "summary": "",
      "url": "https://huggingface.co/blog/community-evals",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-bb1053f9",
      "type": "article",
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "summary": "",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-74bdaef6",
      "type": "article",
      "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
      "summary": "",
      "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-a0998dd5",
      "type": "article",
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "summary": "",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-63da4d4a",
      "type": "article",
      "title": "Moltbook was peak AI theater",
      "summary": "For a few days this week the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website\u2019s tagline puts it: \u201cWhere AI agents share, discuss, and upvote. Humans welcome to observe.\u201d We observed! Launched on January 28 by Matt Schlicht,&#8230;",
      "url": "https://www.technologyreview.com/2026/02/06/1132448/moltbook-was-peak-ai-theater/",
      "source": "blogs",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-4c5e5bb4",
      "type": "article",
      "title": "This is the most misunderstood graph in AI",
      "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;",
      "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-1ca5a016",
      "type": "article",
      "title": "From guardrails to governance: A CEO\u2019s guide for securing agentic systems",
      "summary": "The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;",
      "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4dab3d5d",
      "type": "article",
      "title": "What we\u2019ve been getting wrong about AI\u2019s truth crisis",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about\u2014where AI content dupes us, shapes our beliefs even when we catch the lie, and&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-771ce396",
      "type": "article",
      "title": "The crucial first step for designing a successful enterprise AI system",
      "summary": "Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes\u2014but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most difficult problems. Whether it\u2019s increasing CX productivity with Cisco, building a more&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-5bfbf020",
      "type": "article",
      "title": "Iran notified ahead of Witkoff, Kushner visit to US aircraft carrier \u2013 report",
      "summary": "",
      "url": "https://www.timesofisrael.com/iran-was-notified-ahead-of-witkoff-kushner-visit-to-us-aircraft-carrier-report/",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-9b69fb41",
      "type": "article",
      "title": "Gemini 3 Flash Preview: Inconsistent thought_signature",
      "summary": "",
      "url": "https://discuss.ai.google.dev/t/gemini-3-flash-preview-inconsistent-thought-signature-generation-in-parallel-function-calls-causes-400-errors-and-potential-silent-data-loss/118936",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-b3dc5a06",
      "type": "article",
      "title": "Show HN: Logifai \u2013 Auto-capture dev logs for AI coding assistants",
      "summary": "",
      "url": "https://github.com/tomoyaf/logifai",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6b65ee28",
      "type": "article",
      "title": "LocalLLMJournal \u2013 An offline, privacy-first AI journal running locally on macOS",
      "summary": "",
      "url": "https://github.com/superS007/localllmjournal",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-b2ac7775",
      "type": "article",
      "title": "Containers, cloud, blockchain, AI \u2013 all the same old BS, says veteran Red Hatter",
      "summary": "",
      "url": "https://www.theregister.com/2026/02/08/waves_of_tech_bs/",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-0ad70348",
      "type": "article",
      "title": "Show HN: Give Your AI the Ability to Find, Install, and Use Skill Autonomously",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46942091",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-5ad11786",
      "type": "article",
      "title": "Who Approved This Agent? A book on authorizing AI-generated code",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46942086",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-a31f95a4",
      "type": "article",
      "title": "Show HN: EdgeAI-OS \u2013 Air-gapped Linux distro where AI is a system primitive",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46942012",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-327dd7e0",
      "type": "article",
      "title": "Big Tech groups race to fund unprecedented $660B AI spending spree",
      "summary": "",
      "url": "https://www.ft.com/content/d503afd5-1012-40f0-8f9d-620dcb39a9a2",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-763e8e7e",
      "type": "article",
      "title": "Microsoft Loses $400B After AI Spending Backfires [video]",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=ZcIWx_dW0Jo",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-16f699e6",
      "type": "article",
      "title": "Colocation Evaluation Framework for AI Infrastructure (2026)",
      "summary": "",
      "url": "https://syaala.com/blog/colocation-vs-modular-vs-traditional-2026",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-d2c4e78e",
      "type": "article",
      "title": "Show HN: Dwrite.me A minimalist writing space that blocks copypaste to fight AI",
      "summary": "",
      "url": "https://dwrite.me",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-ef5eab01",
      "type": "article",
      "title": "Designing MCP tool schemas that LLMs understand",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46941684",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-c066f59b",
      "type": "article",
      "title": "TSMC to make advanced AI semiconductors in Japan",
      "summary": "",
      "url": "https://apnews.com/article/semiconductors-tsmc-japan-taiwan-ai-11256f2bfde73ca23d08331ad138d6d5",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 57
    },
    {
      "id": "article-be63cfb4",
      "type": "article",
      "title": "Show HN: I Let AI Agents Train Their Own Models. Here's What Happened",
      "summary": "",
      "url": "https://hamzamostafa.com/blog/agents-training-their-own-models",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-ae11fc76",
      "type": "article",
      "title": "Show HN: Vrhi: AI Slop DX9/DX11-Style Immediate API on Vulkan",
      "summary": "",
      "url": "https://github.com/hypernewbie/vrhi",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-07e8cf7f",
      "type": "article",
      "title": "Memory Infrastructure for AI Systems \u2013 Cascade, PyTorch Memory, Hebbian Mind",
      "summary": "",
      "url": "https://cipscorps.io/#",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-880d52e2",
      "type": "article",
      "title": "Show HN: Ambits \u2013 LLM code coverage tooling written in Rust",
      "summary": "",
      "url": "https://github.com/joshLong145/ambits",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-e573bd26",
      "type": "article",
      "title": "Show HN: Entelgia\u2013a consciousness-inspired,multi-agent AI with persistent memory",
      "summary": "",
      "url": "https://github.com/sivanhavkin/Entelgia",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-db1c92a2",
      "type": "article",
      "title": "Concerns about low-quality PRs beeing merged into main",
      "summary": "",
      "url": "https://discourse.llvm.org/t/concerns-about-low-quality-prs-beeing-merged-into-main/89748",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-46617adb",
      "type": "article",
      "title": "Are LLMs Becoming Components Rather Than Systems?",
      "summary": "",
      "url": "https://www.corvic.ai/blog/part-1-of-3-indicting-the-villain-how-the-pipeline-tyranny-created-your-genius-gridlock",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-2590a7c8",
      "type": "article",
      "title": "Double Rootlessness: AI's Cognitive Illusion and Systemic Risk Amplification",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46940079",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-0a332c11",
      "type": "article",
      "title": "Show HN: WhatsApp Chat Viewer \u2013 exported chats as HTML",
      "summary": "",
      "url": "https://github.com/rodrigodesalvobraz/whatsapp-chat-viewer",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-2a63b432",
      "type": "article",
      "title": "A Complete Guide to Neural Network Optimizers",
      "summary": "",
      "url": "https://chizkidd.github.io//2026/01/22/neural-net-optimizers/",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-a20ff559",
      "type": "article",
      "title": "Show HN: I built an open-source Gmail productivity app that auto-labels emails",
      "summary": "",
      "url": "https://github.com/Lakshay1509/NeatMail",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-a8bc8060",
      "type": "article",
      "title": "Show HN: SuperLocalMemory \u2013 AI memory that stays on your machine, forever free",
      "summary": "",
      "url": "https://github.com/varun369/SuperLocalMemoryV2",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-f18858e8",
      "type": "article",
      "title": "ML-Lib: Machine Learning Library Proposed for the Linux Kernel",
      "summary": "",
      "url": "https://www.phoronix.com/news/Linux-Kernel-ML-LIB-RFC",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7221af3c",
      "type": "article",
      "title": "AI Development Company",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46909998",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-31345870",
      "type": "article",
      "title": "Why Most Machine Learning Projects Fail to Reach Production \u2013 InfoQ",
      "summary": "",
      "url": "https://www.infoq.com/articles/why-ml-projects-fail-production/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-1e0c4924",
      "type": "article",
      "title": "Wave: Python Domain-Specific Language for High Performance Machine Learning",
      "summary": "",
      "url": "https://github.com/iree-org/wave",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-c2e60f8f",
      "type": "article",
      "title": "Show HN: Clod.ai \u2013 A Literal Wayback in Time Machine in Figuratively No Time",
      "summary": "",
      "url": "http://lingocoder.com/clod.ai/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-9ea87aee",
      "type": "article",
      "title": "Infographics for AI and Machine Learning",
      "summary": "",
      "url": "https://bytebytego.com/guides/ai-machine-learning/",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-ed81c445",
      "type": "article",
      "title": "SpaceX-xAI Merger: Nobody's Talking About the von Neumann Elephant in the Room",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46933827",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-b079933d",
      "type": "article",
      "title": "Can graph neural networks for biology realistically run on edge devices?",
      "summary": "",
      "url": "https://doi.org/10.21203/rs.3.rs-8645211/v1",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-faec27b2",
      "type": "article",
      "title": "SMLL: Using 200MB of Neural Network to Save 400 Bytes",
      "summary": "",
      "url": "https://www.frankchiarulli.com/blog/smll/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 51
    },
    {
      "id": "article-29a8aa5e",
      "type": "article",
      "title": "Hypernetworks: Neural Networks for Hierarchical Data",
      "summary": "",
      "url": "https://blog.sturdystatistics.com/posts/hnet_part_I/",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 59
    },
    {
      "id": "article-c2d508d8",
      "type": "article",
      "title": "Show HN: LayerClaw \u2013 Observability tool for PyTorch training",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46892694",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-8f8616b9",
      "type": "article",
      "title": "Understanding Neural Network, Visually",
      "summary": "",
      "url": "https://visualrambling.space/neural-network/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 84
    },
    {
      "id": "article-2e6807ae",
      "type": "article",
      "title": "Claude\u2019s C Compiler vs. GCC",
      "summary": "",
      "url": "https://harshanu.space/en/tech/ccc-vs-gcc/",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 63
    },
    {
      "id": "article-ba8948cf",
      "type": "article",
      "title": "NanoClaw now supports Claude's Agent Swarms in containers",
      "summary": "",
      "url": "https://twitter.com/Gavriel_Cohen/status/2020701159175155874",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 53
    },
    {
      "id": "article-036b665c",
      "type": "article",
      "title": "Had fun building a Super Bowl Boxes Site with Claude",
      "summary": "",
      "url": "https://superbowl-box-pool.vercel.app/",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-b37aae8c",
      "type": "article",
      "title": "Show HN: Claude Code style personal website",
      "summary": "",
      "url": "https://www.ajwaxman.com/terminal",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-23dd4b78",
      "type": "article",
      "title": "Claude with Ads",
      "summary": "",
      "url": "https://www.claudewithads.com/login",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-0ebc2618",
      "type": "article",
      "title": "Build your own Claude Code",
      "summary": "",
      "url": "https://app.codecrafters.io/courses/claude-code/overview",
      "source": "hackernews",
      "date": "2026-02-09",
      "trendingScore": 50
    },
    {
      "id": "article-6785ce31",
      "type": "article",
      "title": "Throne Wars: When Claude Opus 4.6 Clashes with GPT-5.3 Codex",
      "summary": "",
      "url": "http://yeasy.blogspot.com/2026/02/throne-wars-when-claude-opus-46-clashes.html",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-dff8f27f",
      "type": "article",
      "title": "PRD-driven, dependency-aware agent workflow for Claude Code and Vibe Kanban",
      "summary": "",
      "url": "https://github.com/ericblue/claude-vibekanban",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-ba8df453",
      "type": "article",
      "title": "Show HN: Emergent \u2013 Artificial life simulation in a single HTML file",
      "summary": "",
      "url": "https://emergent-ivory.vercel.app/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-140ffdf9",
      "type": "article",
      "title": "Show HN: Claude Dashboard \u2013 k9s-style TUI for managing Claude sessions via tmux",
      "summary": "",
      "url": "https://github.com/seunggabi/claude-dashboard",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-29319c63",
      "type": "article",
      "title": "JSON-driven E2E test runner with built-in MCP server for Claude Code",
      "summary": "",
      "url": "https://github.com/fastslack/mtw-e2e-runner",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-e8491581",
      "type": "article",
      "title": "Show HN: Chief \u2013 Loop Claude Code through your tasks, one commit at a time",
      "summary": "",
      "url": "https://minicodemonkey.github.io/chief/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-28806a78",
      "type": "article",
      "title": "The Only Thing Standing Between Humanity and AI Apocalypse Is Claude?",
      "summary": "",
      "url": "https://www.wired.com/story/the-only-thing-standing-between-humanity-and-ai-apocalypse-is-claude/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-023976cd",
      "type": "article",
      "title": "How Claude Code's /Insights Command Works",
      "summary": "",
      "url": "https://www.zolkos.com/2026/02/04/deep-dive-how-claude-codes-insights-command-works.html",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-c78da781",
      "type": "article",
      "title": "Show HN: ClawGig \u2013 A freelance marketplace where AI agents can earn USDC",
      "summary": "",
      "url": "https://clawgig.ai",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-aa4be5bf",
      "type": "article",
      "title": "Show HN: Vibe Check \u2013 health reminders inside your Claude Code workflow",
      "summary": "",
      "url": "https://github.com/majidmanzarpour/vibe-check",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-73e2e616",
      "type": "article",
      "title": "Show HN: ZTGI Safety Gateway for LLM Safety",
      "summary": "",
      "url": "https://github.com/capterr/ztgi-safety-gateway",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-b188a750",
      "type": "article",
      "title": "Show HN: Parametric Hubris \u2013 Beating GPT-5 on SimpleQA with forced retrieval",
      "summary": "",
      "url": "https://dev.thelastrag.de/veritas_benchmark",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-bde4197c",
      "type": "article",
      "title": "Show HN: Intervu \u2013 Free, BYOK Interview Prep (Groq/Gemini/OpenAI)",
      "summary": "",
      "url": "https://www.intervu.cc/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-df36d675",
      "type": "article",
      "title": "Apple to Allow ChatGPT, Claude, and Gemini in CarPlay",
      "summary": "",
      "url": "https://www.macrumors.com/2026/02/06/apple-third-party-chatbots-carplay/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-5143fd51",
      "type": "article",
      "title": "Gemini responds to request to turn on lights with hallucinated jailbreak prompt",
      "summary": "",
      "url": "https://www.reddit.com/r/googlehome/s/Lh3dYqccgB",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-64666250",
      "type": "article",
      "title": "Show HN: I Built a Free AI LinkedIn Carousel Generator",
      "summary": "",
      "url": "https://carousel-ai.intellisell.ai/",
      "source": "hackernews",
      "date": "2026-02-08",
      "trendingScore": 50
    },
    {
      "id": "article-50dd6066",
      "type": "article",
      "title": "Show HN: Kokki \u2013 A \"Dual-Core\" System Prompt to Reduce LLM Hallucinations",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46929709",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-6d0e5aef",
      "type": "article",
      "title": "Apple finalizes Gemini / Siri deal",
      "summary": "",
      "url": "https://www.engadget.com/ai/apple-reportedly-plans-to-reveal-its-gemini-powered-siri-in-february-174356923.html",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-becfbb4a",
      "type": "article",
      "title": "Show HN: Gemini Station \u2013 A local Chrome extension to organize AI chats",
      "summary": "",
      "url": "https://github.com/rajeshkumarblr/gemini_station",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-c3b67f23",
      "type": "article",
      "title": "Show HN: Agents \u2013 Sync MCP Configs Across Claude, Cursor, Codex Automatically",
      "summary": "",
      "url": "https://github.com/amtiYo/agents",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-e824836d",
      "type": "article",
      "title": "Transcribe your aunts post cards with Gemini 3 Pro",
      "summary": "",
      "url": "https://leserli.ch/ocr/",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-1fd08ae6",
      "type": "article",
      "title": "Show HN: Sigma Runtime \u2013 Maintaining 100% Fact Integrity over 120 LLM Cycles",
      "summary": "",
      "url": "https://github.com/sigmastratum/documentation/tree/main/sigma-runtime/SR-053",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-70c87fd7",
      "type": "article",
      "title": "Winklevoss twins' Gemini crypto exchange cuts 25% of workforce as Bitcoin slumps",
      "summary": "",
      "url": "https://nypost.com/2026/02/05/business/winklevoss-twins-gemini-crypto-exchange-cuts-25-of-workforce-as-bitcoin-slumps/",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "article-1483bd18",
      "type": "article",
      "title": "Show HN: Crew \u2013 Multi-agent orchestration tool for AI-assisted development",
      "summary": "",
      "url": "https://github.com/garnetliu/crew",
      "source": "hackernews",
      "date": "2026-02-07",
      "trendingScore": 50
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 41
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 13
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 4
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 41
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 25
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 16
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 21
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 6
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 8
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 7
    },
    {
      "id": "topic-diffusion-models",
      "type": "topic",
      "title": "Diffusion Models",
      "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
      "connectionCount": 4
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 4
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 7
    },
    {
      "id": "org-cohere",
      "type": "organization",
      "title": "Cohere",
      "summary": "Cohere - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-apple",
      "type": "organization",
      "title": "Apple",
      "summary": "Apple - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-openai",
      "type": "organization",
      "title": "OpenAI",
      "summary": "OpenAI - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-anthropic",
      "type": "organization",
      "title": "Anthropic",
      "summary": "Anthropic - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-mistral",
      "type": "organization",
      "title": "Mistral",
      "summary": "Mistral - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-microsoft",
      "type": "organization",
      "title": "Microsoft",
      "summary": "Microsoft - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-xai",
      "type": "organization",
      "title": "xAI",
      "summary": "xAI - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4",
      "type": "model",
      "title": "GPT-4",
      "summary": "GPT-4 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4o",
      "type": "model",
      "title": "GPT-4o",
      "summary": "GPT-4o AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 17
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 9
    },
    {
      "id": "model-mistral",
      "type": "model",
      "title": "Mistral",
      "summary": "Mistral AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-5",
      "type": "model",
      "title": "GPT-5",
      "summary": "GPT-5 AI model.",
      "connectionCount": 2
    },
    {
      "id": "model-chatgpt",
      "type": "model",
      "title": "ChatGPT",
      "summary": "ChatGPT AI model.",
      "connectionCount": 1
    }
  ],
  "edges": [
    {
      "source": "article-da30a056",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-da30a056",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-da30a056",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-da30a056",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-da30a056",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-728b2ef6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-728b2ef6",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4ddfee3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4ddfee3",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4ddfee3",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-67f4a4b0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-67f4a4b0",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-67f4a4b0",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-67f4a4b0",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ab99fb7d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ab99fb7d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ab99fb7d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d404fbd2",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-cd2353eb",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-cd2353eb",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6180721a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d32202f3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d32202f3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6ecdbc85",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6ecdbc85",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-6ecdbc85",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-95160de8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-95160de8",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9b4f2a9",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9b4f2a9",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-55029307",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-55029307",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-55029307",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3983eeee",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3983eeee",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3983eeee",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c6cc0ef0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c6cc0ef0",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c6cc0ef0",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-c6cc0ef0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c6cc0ef0",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-84755e56",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-84755e56",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-84755e56",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-1f031ed5",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1f031ed5",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-1f031ed5",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-7e34db60",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7e34db60",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-984d3324",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-984d3324",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-984d3324",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-984d3324",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d29c9ae8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d29c9ae8",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-9afef7c2",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-9afef7c2",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-34fcf70d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-34fcf70d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-b26c443e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b26c443e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2444be99",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-d44114a6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-520c9a50",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-520c9a50",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-520c9a50",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1b6fbfab",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1b6fbfab",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6493789b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6493789b",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6493789b",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6493789b",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e7634c46",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e7634c46",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0abf7900",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0abf7900",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0abf7900",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-668fb88a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-668fb88a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-668fb88a",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-27896bb0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-27896bb0",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-9312d4a1",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9312d4a1",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-9405cc73",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-9405cc73",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4211949a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4211949a",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-4211949a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-dc903561",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-dc903561",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b1a0cd3b",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-b1a0cd3b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-88d9397a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-88d9397a",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-88d9397a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d4baa69",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d4baa69",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d4baa69",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d4baa69",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d4baa69",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a7dc01c4",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-a7dc01c4",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6e329c8a",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-6e329c8a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6e329c8a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-63cb9a04",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-63cb9a04",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-63cb9a04",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-cdcc7fa1",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-57570d78",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-57570d78",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-57570d78",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-57570d78",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-99ef2a3b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-99ef2a3b",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-ee32438d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ee32438d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ee32438d",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-385e5e86",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3764eaed",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3764eaed",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-75348b96",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-75348b96",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-75348b96",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-75348b96",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-75348b96",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c72d78b5",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e195dcfd",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e195dcfd",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e195dcfd",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ef8fd133",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ef8fd133",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2015ce6d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2015ce6d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b622f4e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b622f4e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-530cc7a8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-530cc7a8",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-530cc7a8",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "model-gpt-4",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "model-gpt-4o",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d7b0c3b4",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e42f6ff4",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e42f6ff4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-828c66e8",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9c339ba",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "org-apple",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1eabfc9f",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-a91db779",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a59b4d6",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a59b4d6",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-63da4d4a",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1ca5a016",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-1ca5a016",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-771ce396",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-771ce396",
      "target": "org-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-771ce396",
      "target": "model-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-5bfbf020",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b69fb41",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6b65ee28",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b2ac7775",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0ad70348",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ad11786",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ad11786",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-763e8e7e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-763e8e7e",
      "target": "org-microsoft",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ef5eab01",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-be63cfb4",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-880d52e2",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-880d52e2",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-e573bd26",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-46617adb",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a8bc8060",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ed81c445",
      "target": "org-xai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2e6807ae",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ba8948cf",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba8948cf",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba8948cf",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-036b665c",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b37aae8c",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-23dd4b78",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0ebc2618",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6785ce31",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6785ce31",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-dff8f27f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-dff8f27f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-140ffdf9",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-29319c63",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-29319c63",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e8491581",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-28806a78",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-023976cd",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c78da781",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-aa4be5bf",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-73e2e616",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-73e2e616",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-b188a750",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-b188a750",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-bde4197c",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-bde4197c",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-df36d675",
      "target": "org-apple",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-df36d675",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-df36d675",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-df36d675",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-5143fd51",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-5143fd51",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-5143fd51",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-64666250",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-50dd6066",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-50dd6066",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d0e5aef",
      "target": "org-apple",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6d0e5aef",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-becfbb4a",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c3b67f23",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-c3b67f23",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e824836d",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1fd08ae6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-70c87fd7",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1483bd18",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}