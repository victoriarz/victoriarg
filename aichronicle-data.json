{
  "metadata": {
    "lastUpdated": "2026-01-06T06:33:02.050179Z",
    "totalArticles": 135,
    "totalNodes": 161,
    "totalEdges": 202,
    "dateRange": {
      "start": "2025-12-30",
      "end": "2026-01-06"
    }
  },
  "nodes": [
    {
      "id": "article-1268d449",
      "type": "article",
      "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections",
      "summary": "arXiv:2601.00814v1 Announce Type: new Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar enti",
      "url": "https://arxiv.org/abs/2601.00814",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-9bf07684",
      "type": "article",
      "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback",
      "summary": "arXiv:2601.00816v1 Announce Type: new Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates ar",
      "url": "https://arxiv.org/abs/2601.00816",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f9af5012",
      "type": "article",
      "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making",
      "summary": "arXiv:2601.00818v1 Announce Type: new Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system w",
      "url": "https://arxiv.org/abs/2601.00818",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8b7a7eec",
      "type": "article",
      "title": "CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations",
      "summary": "arXiv:2601.00821v1 Announce Type: new Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compressi",
      "url": "https://arxiv.org/abs/2601.00821",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-d39a0414",
      "type": "article",
      "title": "Energy-Aware Routing to Large Reasoning Models",
      "summary": "arXiv:2601.00823v1 Announce Type: new Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which nei",
      "url": "https://arxiv.org/abs/2601.00823",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-abf20bec",
      "type": "article",
      "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis",
      "summary": "arXiv:2601.00828v1 Announce Type: new Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=5",
      "url": "https://arxiv.org/abs/2601.00828",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-35c9f81d",
      "type": "article",
      "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning",
      "summary": "arXiv:2601.00830v1 Announce Type: new Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. Thi",
      "url": "https://arxiv.org/abs/2601.00830",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-1a2b6aa5",
      "type": "article",
      "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification",
      "summary": "arXiv:2601.00843v1 Announce Type: new Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexi",
      "url": "https://arxiv.org/abs/2601.00843",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-3aa1d71c",
      "type": "article",
      "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes",
      "summary": "arXiv:2601.00845v1 Announce Type: new Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that ",
      "url": "https://arxiv.org/abs/2601.00845",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5971ec6e",
      "type": "article",
      "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models",
      "summary": "arXiv:2601.00848v1 Announce Type: new Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. ",
      "url": "https://arxiv.org/abs/2601.00848",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-0075f93f",
      "type": "article",
      "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks",
      "summary": "arXiv:2601.00856v1 Announce Type: new Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) ana",
      "url": "https://arxiv.org/abs/2601.00856",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e90ae87d",
      "type": "article",
      "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery",
      "summary": "arXiv:2601.00869v1 Announce Type: new Abstract: As artificial intelligence systems increasingly mediate consumer information discovery, brands face algorithmic invisibility. This study investigates Cultural Encoding in Large Language Models (LLMs) -- systematic differences in brand recommendations arising from training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o, Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6 percentage ",
      "url": "https://arxiv.org/abs/2601.00869",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b2b3be14",
      "type": "article",
      "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering",
      "summary": "arXiv:2601.00880v1 Announce Type: new Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance",
      "url": "https://arxiv.org/abs/2601.00880",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a712315c",
      "type": "article",
      "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models",
      "summary": "arXiv:2601.00885v1 Announce Type: new Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual c",
      "url": "https://arxiv.org/abs/2601.00885",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-ac1448ea",
      "type": "article",
      "title": "Context Collapse: In-Context Learning and Model Collapse",
      "summary": "arXiv:2601.00923v1 Announce Type: new Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear",
      "url": "https://arxiv.org/abs/2601.00923",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-fdc0022c",
      "type": "article",
      "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems",
      "summary": "arXiv:2601.00994v1 Announce Type: new Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs,",
      "url": "https://arxiv.org/abs/2601.00994",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-95ced44d",
      "type": "article",
      "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering",
      "summary": "arXiv:2601.01195v1 Announce Type: new Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning e",
      "url": "https://arxiv.org/abs/2601.01195",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-c0a33d9b",
      "type": "article",
      "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies",
      "summary": "arXiv:2601.01301v1 Announce Type: new Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster whe",
      "url": "https://arxiv.org/abs/2601.01301",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-317e41d6",
      "type": "article",
      "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models",
      "summary": "arXiv:2601.01321v1 Announce Type: new Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing t",
      "url": "https://arxiv.org/abs/2601.01321",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-46852fbb",
      "type": "article",
      "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale",
      "summary": "arXiv:2601.01330v1 Announce Type: new Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely o",
      "url": "https://arxiv.org/abs/2601.01330",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-06fae34f",
      "type": "article",
      "title": "Horizon Reduction as Information Loss in Offline Reinforcement Learning",
      "summary": "arXiv:2601.00831v1 Announce Type: new Abstract: Horizon reduction is a common design strategy in offline reinforcement learning (RL), used to mitigate long-horizon credit assignment, improve stability, and enable scalable learning through truncated rollouts, windowed training, or hierarchical decomposition (Levine et al., 2020; Prudencio et al., 2023; Park et al., 2025). Despite recent empirical evidence that horizon reduction can improve scaling on challenging offline RL benchmarks, its theoret",
      "url": "https://arxiv.org/abs/2601.00831",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-9242d402",
      "type": "article",
      "title": "ShrimpXNet: A Transfer Learning Framework for Shrimp Disease Classification with Augmented Regularization, Adversarial Training, and Explainable AI",
      "summary": "arXiv:2601.00832v1 Announce Type: new Abstract: Shrimp is one of the most widely consumed aquatic species globally, valued for both its nutritional content and economic importance. Shrimp farming represents a significant source of income in many regions; however, like other forms of aquaculture, it is severely impacted by disease outbreaks. These diseases pose a major challenge to sustainable shrimp production. To address this issue, automated disease classification methods can offer timely and ",
      "url": "https://arxiv.org/abs/2601.00832",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-ae4848f7",
      "type": "article",
      "title": "Intrinsic-Metric Physics-Informed Neural Networks (IM-PINN) for Reaction-Diffusion Dynamics on Complex Riemannian Manifolds",
      "summary": "arXiv:2601.00834v1 Announce Type: new Abstract: Simulating nonlinear reaction-diffusion dynamics on complex, non-Euclidean manifolds remains a fundamental challenge in computational morphogenesis, constrained by high-fidelity mesh generation costs and symplectic drift in discrete time-stepping schemes. This study introduces the Intrinsic-Metric Physics-Informed Neural Network (IM-PINN), a mesh-free geometric deep learning framework that solves partial differential equations directly in the conti",
      "url": "https://arxiv.org/abs/2601.00834",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-cf213fb9",
      "type": "article",
      "title": "SLO-Conditioned Action Routing for Retrieval-Augmented Generation: Objective Ablation and Failure Modes",
      "summary": "arXiv:2601.00841v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) introduces a practical control problem: retrieval depth and generation behavior must be chosen per query to satisfy service-level objectives (SLOs) such as cost, refusal rate, and hallucination risk. This work models per-query control as a small discrete action: choose a retrieval depth and a generation mode (guarded vs. auto), or refuse. An offline logged dataset is constructed from SQuAD 2.0 by executing each ",
      "url": "https://arxiv.org/abs/2601.00841",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-d5b8c783",
      "type": "article",
      "title": "Value-guided action planning with JEPA world models",
      "summary": "arXiv:2601.00844v1 Announce Type: new Abstract: Building deep learning models that can reason about their environment requires capturing its underlying dynamics. Joint-Embedded Predictive Architectures (JEPA) provide a promising framework to model such dynamics by learning representations and predictors through a self-supervised prediction objective. However, their ability to support effective action planning remains limited. We propose an approach to enhance planning with JEPA world models by s",
      "url": "https://arxiv.org/abs/2601.00844",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b119d0a0",
      "type": "article",
      "title": "You Only Need Your Transformer 25% of the Time: Meaning-First Execution for Eliminating Unnecessary Inference",
      "summary": "arXiv:2601.00847v1 Announce Type: new Abstract: Modern AI inference systems treat transformer execution as mandatory, conflating model capability with execution necessity. We reframe inference as a control-plane decision problem: determining when execution is necessary versus when correctness can be preserved through alternative pathways. We introduce Meaning-First Execution (MFEE), a control-plane architecture implementing this framework, selectively invoking transformer inference only when req",
      "url": "https://arxiv.org/abs/2601.00847",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a13d414d",
      "type": "article",
      "title": "EdgeJury: Cross-Reviewed Small-Model Ensembles for Truthful Question Answering on Serverless Edge Inference",
      "summary": "arXiv:2601.00850v1 Announce Type: new Abstract: Hallucinations hinder reliable question answering, especially in resource-constrained deployments where frontier-scale models or retrieval pipelines may be impractical. We present EdgeJury, a lightweight ensemble framework that improves truthfulness and robustness using only small instruction-tuned language models (3B-8B) suitable for serverless edge inference. EdgeJury orchestrates four stages: (1) parallel role-specialized generation, (2) anonymi",
      "url": "https://arxiv.org/abs/2601.00850",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-011b2c8f",
      "type": "article",
      "title": "FedSCAM (Federated Sharpness-Aware Minimization with Clustered Aggregation and Modulation): Scam-resistant SAM for Robust Federated Optimization in Heterogeneous Environments",
      "summary": "arXiv:2601.00853v1 Announce Type: new Abstract: Federated Learning (FL) enables collaborative model training across decentralized edge devices while preserving data privacy. However, statistical heterogeneity among clients, often manifested as non-IID label distributions, poses significant challenges to convergence and generalization. While Sharpness-Aware Minimization (SAM) has been introduced to FL to seek flatter, more robust minima, existing approaches typically apply a uniform perturbation ",
      "url": "https://arxiv.org/abs/2601.00853",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-c4c45fb6",
      "type": "article",
      "title": "Harvesting AlphaEarth: Benchmarking the Geospatial Foundation Model for Agricultural Downstream Tasks",
      "summary": "arXiv:2601.00857v1 Announce Type: new Abstract: Geospatial foundation models (GFMs) have emerged as a promising approach to overcoming the limitations in existing featurization methods. More recently, Google DeepMind has introduced AlphaEarth Foundation (AEF), a GFM pre-trained using multi-source EOs across continuous time. An annual and global embedding dataset is produced using AEF that is ready for analysis and modeling. The internal experiments show that AEF embeddings have outperformed oper",
      "url": "https://arxiv.org/abs/2601.00857",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-905d17e5",
      "type": "article",
      "title": "Path Integral Solution for Dissipative Generative Dynamics",
      "summary": "arXiv:2601.00860v1 Announce Type: new Abstract: Can purely mechanical systems generate intelligent language? We prove that dissipative quantum dynamics with analytically tractable non-local context aggregation produce coherent text generation, while conservation laws cause fundamental failure. Employing Koopman operators with closed-form path integral propagators, we show irreversible computation fundamentally requires both controlled information dissipation and causal context aggregation. Spect",
      "url": "https://arxiv.org/abs/2601.00860",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-d8da28ac",
      "type": "article",
      "title": "Universal Battery Degradation Forecasting Driven by Foundation Model Across Diverse Chemistries and Conditions",
      "summary": "arXiv:2601.00862v1 Announce Type: new Abstract: Accurate forecasting of battery capacity fade is essential for the safety, reliability, and long-term efficiency of energy storage systems. However, the strong heterogeneity across cell chemistries, form factors, and operating conditions makes it difficult to build a single model that generalizes beyond its training domain. This work proposes a unified capacity forecasting framework that maintains robust performance across diverse chemistries and u",
      "url": "https://arxiv.org/abs/2601.00862",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a27aaaac",
      "type": "article",
      "title": "Selective Imperfection as a Generative Framework for Analysis, Creativity and Discovery",
      "summary": "arXiv:2601.00863v1 Announce Type: new Abstract: We introduce materiomusic as a generative framework linking the hierarchical structures of matter with the compositional logic of music. Across proteins, spider webs and flame dynamics, vibrational and architectural principles recur as tonal hierarchies, harmonic progressions, and long-range musical form. Using reversible mappings, from molecular spectra to musical tones and from three-dimensional networks to playable instruments, we show how sound",
      "url": "https://arxiv.org/abs/2601.00863",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e63c9bca",
      "type": "article",
      "title": "Distribution Matching for Graph Quantification Under Structural Covariate Shift",
      "summary": "arXiv:2601.00864v1 Announce Type: new Abstract: Graphs are commonly used in machine learning to model relationships between instances. Consider the task of predicting the political preferences of users in a social network; to solve this task one should consider, both, the features of each individual user and the relationships between them. However, oftentimes one is not interested in the label of a single instance but rather in the distribution of labels over a set of instances; e.g., when predi",
      "url": "https://arxiv.org/abs/2601.00864",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-841deb19",
      "type": "article",
      "title": "A-PINN: Auxiliary Physics-informed Neural Networks for Structural Vibration Analysis in Continuous Euler-Bernoulli Beam",
      "summary": "arXiv:2601.00866v1 Announce Type: new Abstract: Recent advancements in physics-informed neural networks (PINNs) and their variants have garnered substantial focus from researchers due to their effectiveness in solving both forward and inverse problems governed by differential equations. In this research, a modified Auxiliary physics-informed neural network (A-PINN) framework with balanced adaptive optimizers is proposed for the analysis of structural vibration problems. In order to accurately re",
      "url": "https://arxiv.org/abs/2601.00866",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-3488afb9",
      "type": "article",
      "title": "SmartFlow Reinforcement Learning and Agentic AI for Bike-Sharing Optimisation",
      "summary": "arXiv:2601.00868v1 Announce Type: new Abstract: SmartFlow is a multi-layered framework that integrates Reinforcement Learning and Agentic AI to address the dynamic rebalancing problem in urban bike-sharing services. Its architecture separates strategic, tactical, and communication functions for clarity and scalability. At the strategic level, a Deep Q-Network (DQN) agent, trained in a high-fidelity simulation of New Yorks Citi Bike network, learns robust rebalancing policies by modelling the cha",
      "url": "https://arxiv.org/abs/2601.00868",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-7eee472f",
      "type": "article",
      "title": "Quantum Machine Learning Approaches for Coordinated Stealth Attack Detection in Distributed Generation Systems",
      "summary": "arXiv:2601.00873v1 Announce Type: new Abstract: Coordinated stealth attacks are a serious cybersecurity threat to distributed generation systems because they modify control and measurement signals while remaining close to normal behavior, making them difficult to detect using standard intrusion detection methods. This study investigates quantum machine learning approaches for detecting coordinated stealth attacks on a distributed generation unit in a microgrid. High-quality simulated measurement",
      "url": "https://arxiv.org/abs/2601.00873",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-6755eb9f",
      "type": "article",
      "title": "LLMize: A Framework for Large Language Model-Based Numerical Optimization",
      "summary": "arXiv:2601.00874v1 Announce Type: new Abstract: Large language models (LLMs) have recently shown strong reasoning capabilities beyond traditional language tasks, motivating their use for numerical optimization. This paper presents LLMize, an open-source Python framework that enables LLM-driven optimization through iterative prompting and in-context learning. LLMize formulates optimization as a black-box process in which candidate solutions are generated in natural language, evaluated by an exter",
      "url": "https://arxiv.org/abs/2601.00874",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-1f35dc0d",
      "type": "article",
      "title": "LearnAD: Learning Interpretable Rules for Brain Networks in Alzheimer's Disease Classification",
      "summary": "arXiv:2601.00877v1 Announce Type: new Abstract: We introduce LearnAD, a neuro-symbolic method for predicting Alzheimer's disease from brain magnetic resonance imaging data, learning fully interpretable rules. LearnAD applies statistical models, Decision Trees, Random Forests, or GNNs to identify relevant brain connections, and then employs FastLAS to learn global rules. Our best instance outperforms Decision Trees, matches Support Vector Machine accuracy, and performs only slightly below Random ",
      "url": "https://arxiv.org/abs/2601.00877",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-677a7847",
      "type": "article",
      "title": "Outlier Detection Using Vector Cosine Similarity by Adding a Dimension",
      "summary": "arXiv:2601.00883v1 Announce Type: new Abstract: We propose a new outlier detection method for multi-dimensional data. The method detects outliers based on vector cosine similarity, using a new dataset constructed by adding a dimension with zero values to the original data. When a point in the new dataset is selected as the measured point, an observation point is created as the origin, differing only in the new dimension by having a non-zero value compared to the measured point. Vectors are then ",
      "url": "https://arxiv.org/abs/2601.00883",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-2157297b",
      "type": "article",
      "title": "FANoS: Friction-Adaptive Nos\\'e--Hoover Symplectic Momentum for Stiff Objectives",
      "summary": "arXiv:2601.00889v1 Announce Type: new Abstract: We study a physics-inspired optimizer, \\emph{FANoS} (Friction-Adaptive Nos\\'e--Hoover Symplectic momentum), which combines (i) a momentum update written as a discretized second-order dynamical system, (ii) a Nos\\'e--Hoover-like thermostat variable that adapts a scalar friction coefficient using kinetic-energy feedback, and (iii) a semi-implicit (symplectic-Euler) integrator, optionally with a diagonal RMS preconditioner. The method is motivated by ",
      "url": "https://arxiv.org/abs/2601.00889",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-815670fc",
      "type": "article",
      "title": "The Qualitative Laboratory: Theory Prototyping and Hypothesis Generation with Large Language Models",
      "summary": "arXiv:2601.00797v1 Announce Type: new Abstract: A central challenge in social science is to generate rich qualitative hypotheses about how diverse social groups might interpret new information. This article introduces and illustrates a novel methodological approach for this purpose: sociological persona simulation using Large Language Models (LLMs), which we frame as a \"qualitative laboratory\". We argue that for this specific task, persona simulation offers a distinct advantage over established ",
      "url": "https://arxiv.org/abs/2601.00797",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-1d8d5e98",
      "type": "article",
      "title": "Rate-Distortion Analysis of Compressed Query Delegation with Low-Rank Riemannian Updates",
      "summary": "arXiv:2601.00938v1 Announce Type: new Abstract: Bounded-context agents fail when intermediate reasoning exceeds an effective working-memory budget. We study compressed query delegation (CQD): (i) compress a high-dimensional latent reasoning state into a low-rank tensor query, (ii) delegate the minimal query to an external oracle, and (iii) update the latent state via Riemannian optimization on fixed-rank manifolds. We give a math-first formulation: CQD is a constrained stochastic program with a ",
      "url": "https://arxiv.org/abs/2601.00938",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-928f2fda",
      "type": "article",
      "title": "Intention Collapse: Intention-Level Metrics for Reasoning in Language Models",
      "summary": "arXiv:2601.01011v1 Announce Type: new Abstract: Every act of language generation compresses a rich internal state into a single token sequence. We call this process intention collapse: a many-to-one projection from a high dimensional intention space I into an external language space L. We formalize intention collapse for contemporary language models, define three simple, model agnostic intention metrics (intention entropy Hint, effective dimensionality dimeff, and latent knowledge recoverability",
      "url": "https://arxiv.org/abs/2601.01011",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-53ff4ed8",
      "type": "article",
      "title": "HyperJoin: LLM-augmented Hypergraph Link Prediction for Joinable Table Discovery",
      "summary": "arXiv:2601.01015v1 Announce Type: new Abstract: As a pivotal task in data lake management, joinable table discovery has attracted widespread interest. While existing language model-based methods achieve remarkable performance by combining offline column representation learning with online ranking, their design insufficiently accounts for the underlying structural interactions: (1) offline, they directly model tables into isolated or pairwise columns, thereby struggling to capture the rich inter-",
      "url": "https://arxiv.org/abs/2601.01015",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-6f97ff6e",
      "type": "article",
      "title": "Multi-Dimensional Prompt Chaining to Improve Open-Domain Dialogue Generation",
      "summary": "arXiv:2601.01037v1 Announce Type: new Abstract: Small language models (SLMs) offer significant deployment advantages but often struggle to match the dialogue quality of larger models in open-domain settings. In this paper, we propose a multi-dimensional prompt-chaining framework that integrates Naturalness, Coherence, and Engagingness dimensions to enhance human-likeness in open-domain dialogue generation. We apply the framework to two SLMs, TinyLlama and Llama-2-7B, and benchmark their performa",
      "url": "https://arxiv.org/abs/2601.01037",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f24de1dd",
      "type": "article",
      "title": "KV-Embedding: Training-free Text Embedding via Internal KV Re-routing in Decoder-only LLMs",
      "summary": "arXiv:2601.01046v1 Announce Type: new Abstract: While LLMs are powerful embedding backbones, their application in training-free settings faces two structural challenges: causal attention restricts early tokens from accessing subsequent context, and the next-token prediction objective biases representations toward generation rather than semantic compression. To address these limitations, we propose KV-Embedding, a framework that activates the latent representation power of frozen LLMs. Our method",
      "url": "https://arxiv.org/abs/2601.01046",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-202cdeb9",
      "type": "article",
      "title": "Unsupervised Text Style Transfer for Controllable Intensity",
      "summary": "arXiv:2601.01060v1 Announce Type: new Abstract: Unsupervised Text Style Transfer (UTST) aims to build a system to transfer the stylistic properties of a given text without parallel text pairs. Compared with text transfer between style polarities, UTST for controllable intensity is more challenging due to the subtle differences in stylistic features across different intensity levels. Faced with the challenges posed by the lack of parallel data and the indistinguishability between adjacent intensi",
      "url": "https://arxiv.org/abs/2601.01060",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f408c4b6",
      "type": "article",
      "title": "ks-lit-3m: A 3.1 million word kashmiri text dataset for large language model pretraining",
      "summary": "arXiv:2601.01091v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate remarkable fluency across high-resource languages yet consistently fail to generate coherent text in Kashmiri, a language spoken by approximately seven million people. This performance disparity stems not from inherent model limitations but from a critical scarcity of high-quality training data. Decades of Kashmiri literature remain inaccessible to modern NLP pipelines due to their encoding in the proprietar",
      "url": "https://arxiv.org/abs/2601.01091",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-6ebaaa2a",
      "type": "article",
      "title": "EmoLoom-2B: Fast Base-Model Screening for Emotion Classification and VAD with Lexicon-Weak Supervision and KV-Off Evaluation",
      "summary": "arXiv:2601.01112v1 Announce Type: new Abstract: We introduce EmoLoom-2B, a lightweight and reproducible pipeline that turns small language models under 2B parameters into fast screening candidates for joint emotion classification and Valence-Arousal-Dominance prediction. To ensure protocol-faithful and fair evaluation, we unify data loading, training, and inference under a single JSON input-output contract and remove avoidable variance by adopting KV-off decoding as the default setting. We incor",
      "url": "https://arxiv.org/abs/2601.01112",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-58d6e52c",
      "type": "article",
      "title": "Listen, Attend, Understand: a Regularization Technique for Stable E2E Speech Translation Training on High Variance labels",
      "summary": "arXiv:2601.01121v1 Announce Type: new Abstract: End-to-End Speech Translation often shows slower convergence and worse performance when target transcriptions exhibit high variance and semantic ambiguity. We propose Listen, Attend, Understand (LAU), a semantic regularization technique that constrains the acoustic encoder's latent space during training. By leveraging frozen text embeddings to provide a directional auxiliary loss, LAU injects linguistic groundedness into the acoustic representation",
      "url": "https://arxiv.org/abs/2601.01121",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-3988308c",
      "type": "article",
      "title": "RoboPhD: Self-Improving Text-to-SQL Through Autonomous Agent Evolution",
      "summary": "arXiv:2601.01126v1 Announce Type: new Abstract: We present RoboPhD, a system where AI agents autonomously conduct research to improve Text-to-SQL performance. RoboPhD implements a closed-loop evolution cycle with two coordinated components: a SQL Generation agent composed of a database analysis script and SQL generation instructions, and an Evolution agent that designs new versions based on performance feedback. Central to the framework is an ELO-based selection mechanism enabling survival-of-th",
      "url": "https://arxiv.org/abs/2601.01126",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5d585b6c",
      "type": "article",
      "title": "KOS-TL (Knowledge Operation System Type Logic)",
      "summary": "arXiv:2601.01143v1 Announce Type: new Abstract: This paper introduces KOS-TL (Knowledge Operation System Type Logic), a novel constructive framework designed to provide a rigorous logical foundation for autonomous and executable knowledge systems. Traditional knowledge representation models often suffer from a gap between static symbolic logic and dynamic system execution. To bridge this divide, KOS-TL leverages Dependent Type Theory to unify data, logic, and proof into a singular computational ",
      "url": "https://arxiv.org/abs/2601.01143",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-2d40cb18",
      "type": "article",
      "title": "SongSage: A Large Musical Language Model with Lyric Generative Pre-training",
      "summary": "arXiv:2601.01153v1 Announce Type: new Abstract: Large language models have achieved significant success in various domains, yet their understanding of lyric-centric knowledge has not been fully explored. In this work, we first introduce PlaylistSense, a dataset to evaluate the playlist understanding capability of language models. PlaylistSense encompasses ten types of user queries derived from common real-world perspectives, challenging LLMs to accurately grasp playlist features and address dive",
      "url": "https://arxiv.org/abs/2601.01153",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-fdb54da3",
      "type": "article",
      "title": "DHI: Leveraging Diverse Hallucination Induction for Enhanced Contrastive Factuality Control in Large Language Models",
      "summary": "arXiv:2601.01156v1 Announce Type: new Abstract: Large language models (LLMs) frequently produce inaccurate or fabricated information, known as \"hallucinations,\" which compromises their reliability. Existing approaches often train an \"Evil LLM\" to deliberately generate hallucinations on curated datasets, using these induced hallucinations to guide contrastive decoding against a reliable \"positive model\" for hallucination mitigation. However, this strategy is limited by the narrow diversity of hal",
      "url": "https://arxiv.org/abs/2601.01156",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e7b5566f",
      "type": "article",
      "title": "Almost Clinical: Linguistic properties of synthetic electronic health records",
      "summary": "arXiv:2601.01171v1 Announce Type: new Abstract: This study evaluates the linguistic and clinical suitability of synthetic electronic health records (EHRs) in the field of mental health. First, we describe the rationale and the methodology for creating the synthetic corpus. Second, we assess agency, modality, and information flow across four clinical genres (Assessments, Correspondence, Referrals and Care plans) to understand how LLMs grammatically construct medical authority and patient agency t",
      "url": "https://arxiv.org/abs/2601.01171",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-08c690d9",
      "type": "article",
      "title": "Stylometry Analysis of Human and Machine Text for Academic Integrity",
      "summary": "arXiv:2601.01225v1 Announce Type: new Abstract: This work addresses critical challenges to academic integrity, including plagiarism, fabrication, and verification of authorship of educational content, by proposing a Natural Language Processing (NLP)-based framework for authenticating students' content through author attribution and style change detection. Despite some initial efforts, several aspects of the topic are yet to be explored. In contrast to existing solutions, the paper provides a com",
      "url": "https://arxiv.org/abs/2601.01225",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5583d90b",
      "type": "article",
      "title": "Racka: Efficient Hungarian LLM Adaptation on Academic Infrastructure",
      "summary": "arXiv:2601.01244v1 Announce Type: new Abstract: We present Racka, a lightweight, continually pretrained large language model designed to bridge the resource gap between Hungarian and high-resource languages such as English and German. Racka employs parameter-efficient continual pretraining via Low-Rank Adaptation (LoRA) on a Qwen-3 4B backbone, making the recipe practical on A100 (40GB)-based HPC clusters with low inter-node bandwidth. To better match the training distribution, we replace and ad",
      "url": "https://arxiv.org/abs/2601.01244",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8dc8fa4b",
      "type": "article",
      "title": "From Policy to Logic for Efficient and Interpretable Coverage Assessment",
      "summary": "arXiv:2601.01266v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in interpreting lengthy, complex legal and policy language. However, their reliability can be undermined by hallucinations and inconsistencies, particularly when analyzing subjective and nuanced documents. These challenges are especially critical in medical coverage policy review, where human experts must be able to rely on accurate information. In this paper, we present an approach",
      "url": "https://arxiv.org/abs/2601.01266",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-1163607d",
      "type": "article",
      "title": "Does Memory Need Graphs? A Unified Framework and Empirical Analysis for Long-Term Dialog Memory",
      "summary": "arXiv:2601.01280v1 Announce Type: new Abstract: Graph structures are increasingly used in dialog memory systems, but empirical findings on their effectiveness remain inconsistent, making it unclear which design choices truly matter. We present an experimental, system-oriented analysis of long-term dialog memory architectures. We introduce a unified framework that decomposes dialog memory systems into core components and supports both graph-based and non-graph approaches. Under this framework, we",
      "url": "https://arxiv.org/abs/2601.01280",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-16b7717d",
      "type": "article",
      "title": "T3C: Test-Time Tensor Compression with Consistency Guarantees",
      "summary": "arXiv:2601.01299v1 Announce Type: new Abstract: We present T3C, a train-once, test-time budget-conditioned compression framework that exposes rank and precision as a controllable deployment knob. T3C combines elastic tensor factorization (maintained up to a maximal rank) with rank-tied mixed-precision quantization and a lightweight controller that maps a latency/energy/size budget token to per-layer rank/bit assignments; the policy snaps to hardware-aligned profiles and is monotone in the budget",
      "url": "https://arxiv.org/abs/2601.01299",
      "source": "arxiv",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-423ae0f6",
      "type": "article",
      "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-650e8a5e",
      "type": "article",
      "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
      "summary": "",
      "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-66f18b5e",
      "type": "article",
      "title": "NVIDIA brings agents to life with DGX Spark and Reachy Mini",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia-reachy-mini",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-8bdc2f5a",
      "type": "article",
      "title": "What\u2019s next for AI in 2026",
      "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In an industry in constant flux, sticking your neck out to predict what\u2019s coming next may seem reckless. (AI bubble? What AI bubble?) But for the&#8230;",
      "url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-e4a7bbc2",
      "type": "article",
      "title": "The ascent of the AI therapist",
      "summary": "We\u2019re in the midst of a global mental-\u00adhealth crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year. Given the clear&#8230;",
      "url": "https://www.technologyreview.com/2025/12/30/1129392/book-reviews-ai-therapy-mental-health/",
      "source": "blogs",
      "date": "2025-12-30",
      "trendingScore": 50
    },
    {
      "id": "article-4aefc378",
      "type": "article",
      "title": "Nvidia Unveils Faster AI Chips Sooner Than Expected",
      "summary": "",
      "url": "https://www.wsj.com/tech/ai/nvidia-unveils-faster-ai-chips-sooner-than-expected-626154a5",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-c63eca5b",
      "type": "article",
      "title": "AI Construction Costs Can Be an Accounting 'Black Box'",
      "summary": "",
      "url": "https://www.wsj.com/articles/ai-construction-costs-can-be-an-accounting-black-box-3c197b09",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-82badc60",
      "type": "article",
      "title": "How People Actually Use AI (100 Trillion Token Study)",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=RaPmhA2uQQM",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f251f6d1",
      "type": "article",
      "title": "AI Kindle Highlights Connections",
      "summary": "",
      "url": "https://www.morning-notes.com/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-bb877b26",
      "type": "article",
      "title": "AI from the perspective of a software developer, year-end 2025",
      "summary": "",
      "url": "https://www.themotte.org/post/3424/ai-from-the-perspective-of-a",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-1e7adc9e",
      "type": "article",
      "title": "Built an AI-powered profit calculator and inventory tracker app for resellers",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46508942",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b2c5b39f",
      "type": "article",
      "title": "Few Shall Return is now gen-AI free",
      "summary": "",
      "url": "https://www.ballardgames.com/tales/gen-ai-go-away/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a70f40f8",
      "type": "article",
      "title": "Factcheckr.io \u2013 AI Powered Community-driven fact checking for social media",
      "summary": "",
      "url": "https://factcheckr.io/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-24058352",
      "type": "article",
      "title": "Amazon Prime AI overviews can't even get the basics right",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46508324",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 52
    },
    {
      "id": "article-34cf6bd8",
      "type": "article",
      "title": "AI-driven inflation is 2026's most overlooked risk, investors say",
      "summary": "",
      "url": "https://www.reuters.com/world/asia-pacific/ai-driven-inflation-is-2026s-most-overlooked-risk-investors-say-2026-01-05/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b3a0b383",
      "type": "article",
      "title": "Show HN: llmgame.ai \u2013 The Wikipedia Game but with LLMs",
      "summary": "",
      "url": "https://www.llmgame.ai",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e2e66209",
      "type": "article",
      "title": "Code Review in the Age of AI",
      "summary": "",
      "url": "https://addyo.substack.com/p/code-review-in-the-age-of-ai",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-47483037",
      "type": "article",
      "title": "Show HN: Arbor \u2013 An AST based Rust engine for deterministic AI codebase context",
      "summary": "",
      "url": "https://github.com/Anandb71/arbor",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b80e3229",
      "type": "article",
      "title": "Show HN: LLM CAS tools (math verification)",
      "summary": "",
      "url": "https://auteng.ai/#cas-demo",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-9d0636ca",
      "type": "article",
      "title": "Tracks vs. Trains: Why the Real AI Boom Hasn't Started Yet \u2013 Insights for 2026",
      "summary": "",
      "url": "https://shawnharris.com/tracks-vs-trains-why-the-real-artificial-intelligence-boom-hasnt-started-yet-insights-for-2026/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-0a97a100",
      "type": "article",
      "title": "Generation AI: fears of social divide unless all children learn computing skills",
      "summary": "",
      "url": "https://www.theguardian.com/education/2026/jan/05/generation-ai-fears-of-social-divide-unless-all-children-learn-computing-skills",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 51
    },
    {
      "id": "article-977d2850",
      "type": "article",
      "title": "Debunking the AI food delivery hoax that fooled Reddit",
      "summary": "",
      "url": "https://www.platformer.news/fake-uber-eats-whisleblower-hoax-debunked/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-4eef30fe",
      "type": "article",
      "title": "Why AI Memory Hasn't Been Solved (Yet)",
      "summary": "",
      "url": "https://twitter.com/ashpreetbedi/status/2008315658417647895",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-7a8d8c97",
      "type": "article",
      "title": "Ask HN: Do you feel an obvious \"uncanny valley\" when reading AI-generated text?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46507634",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-05f28cdc",
      "type": "article",
      "title": "Ask HN: Why are LLM's made intentionally non-deterministic?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46509291",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-d98abdd9",
      "type": "article",
      "title": "LLM Optimized Engineering Principles",
      "summary": "",
      "url": "https://github.com/skhameneh/principles",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b06c1494",
      "type": "article",
      "title": "Can a Large Language Model Understand the Waste Land?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46508621",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-7226401f",
      "type": "article",
      "title": "The Patient Is Not a Document: Moving from LLMs to a World Model for Oncology",
      "summary": "",
      "url": "https://blog.standardmodel.bio/p/the-patient-is-not-a-document-moving-f88",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-99f0ca55",
      "type": "article",
      "title": "Show HN: I built a *fully free* AI resume maker",
      "summary": "",
      "url": "https://www.resume-razor.com/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5abf57e3",
      "type": "article",
      "title": "AI Assistant with Intelligent Memory",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46506268",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-e1f96433",
      "type": "article",
      "title": "Show HN: Tuff Toucan Steal a Brainrot Wiki \u2013 A \"Neo-Brutalist\" Game Database",
      "summary": "",
      "url": "https://tufftoucan.com",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-76e018f4",
      "type": "article",
      "title": "Semantic Layer for LLM Apps",
      "summary": "",
      "url": "https://github.com/hikarilabs/semantido",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-fd38c95f",
      "type": "article",
      "title": "Eval Testing LLMs in PHPUnit",
      "summary": "",
      "url": "https://joshhornby.com/eval-testing-llms-in-phpunit",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-1c8cbe6a",
      "type": "article",
      "title": "Show HN: ISO 8583 simulator in Python with LLM-powered message explanation",
      "summary": "",
      "url": "https://github.com/bassrehab/ISO8583-Simulator",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-93842b3e",
      "type": "article",
      "title": "Evolution Without an Oracle: Driving Effective Evolution with LLM Judges",
      "summary": "",
      "url": "https://arxiv.org/abs/2511.19489",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-85305ae2",
      "type": "article",
      "title": "Show HN: Doloris \u2013 A distributed system in Go that feels pain",
      "summary": "",
      "url": "https://github.com/FreeFlowLabsCL/doloris",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-184e34c6",
      "type": "article",
      "title": "Show HN: A Ralph Wiggum\u2013Style Gemini CLI Extension",
      "summary": "",
      "url": "https://github.com/AsyncFuncAI/ralph-wiggum-extension",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f38bf4fb",
      "type": "article",
      "title": "Training a Hamiltonian Neural Network",
      "summary": "",
      "url": "https://ritog.github.io/posts/hamiltonian_nn/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5b17ee09",
      "type": "article",
      "title": "Practically Utilizing Neural Networks in CPU-Based Production Rendering (JCGT)",
      "summary": "",
      "url": "https://jcgt.org/published/0015/01/01/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-949fbb3d",
      "type": "article",
      "title": "Visualizing neural network inference in 3D with WebGL and ONNX",
      "summary": "",
      "url": "https://www.erikjs.com/blog/building-neural-network-visualizer",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-e345449d",
      "type": "article",
      "title": "Neural Networks: Zero to Hero",
      "summary": "",
      "url": "https://karpathy.ai/zero-to-hero.html",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 100
    },
    {
      "id": "article-fadf0f36",
      "type": "article",
      "title": "Show HN: Stability First AI \u2013 Recovering memory without training data",
      "summary": "",
      "url": "https://github.com/vitali-sialedchyk/stability-first-ai",
      "source": "hackernews",
      "date": "2026-01-03",
      "trendingScore": 50
    },
    {
      "id": "article-b9019ba6",
      "type": "article",
      "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018)",
      "summary": "",
      "url": "https://arxiv.org/abs/1803.03635",
      "source": "hackernews",
      "date": "2026-01-02",
      "trendingScore": 58
    },
    {
      "id": "article-e5b5c482",
      "type": "article",
      "title": "Boris Cherny: how I use Claude Code",
      "summary": "",
      "url": "https://twitter.com/bcherny/status/2007179832300581177",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a4ea8133",
      "type": "article",
      "title": "How I Use Claude Code with Neovim",
      "summary": "",
      "url": "https://laktek.com/using-claude-code-with-neovim",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f9fa6a40",
      "type": "article",
      "title": "Show HN: Dr. Ralph \u2013 Medical Diagnostics Plugin Using Claude Code's Ralph Wiggum",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46508290",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-576a24e1",
      "type": "article",
      "title": "Claude's Minecraft Adventures",
      "summary": "",
      "url": "https://minecraft.gptkids.app/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-ea74e6ad",
      "type": "article",
      "title": "Show HN: MCP-tidy \u2013 How many MCPs in your Claude Code are you actually using?",
      "summary": "",
      "url": "https://github.com/nnnkkk7/mcp-tidy",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-7d0404a8",
      "type": "article",
      "title": "Sandboxed Claude Code GIF Creator",
      "summary": "",
      "url": "https://modal.com/docs/examples/claude-slack-gif-creator",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-d4ea8713",
      "type": "article",
      "title": "Show HN: Single-file memory for Claude Code",
      "summary": "",
      "url": "https://github.com/memvid/claude-brain",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-7cf6d84c",
      "type": "article",
      "title": "Remote Claude Code: programing like it was the early 2000s",
      "summary": "",
      "url": "https://harper.blog/2026/01/05/claude-code-is-better-on-your-phone/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-9f47aad2",
      "type": "article",
      "title": "Claude Code can now call your phone",
      "summary": "",
      "url": "https://github.com/abracadabra50/claude-code-voice-skill",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-0bdfc555",
      "type": "article",
      "title": "Claude Code is a general-purpose AI agent transforming knowledge work",
      "summary": "",
      "url": "https://www.transformernews.ai/p/claude-code-is-about-so-much-more",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-a5983ddf",
      "type": "article",
      "title": "You Can Just Make Stuff with OpenCode and Claude Opus 4.5",
      "summary": "",
      "url": "https://ericmjl.github.io/blog/2025/12/28/you-can-just-make-stuff-with-opencode-and-claude-opus-4-5/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-83ef8e2f",
      "type": "article",
      "title": "Connect Google Maps with Claude API",
      "summary": "",
      "url": "https://onebite.dev/access-real-time-data-from-claude-api/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-72504f2c",
      "type": "article",
      "title": "How I Use Claude Code with Neovim",
      "summary": "",
      "url": "https://www.laktek.com/using-claude-code-with-neovim",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-2f4dfc67",
      "type": "article",
      "title": "Claude Coach: Free Personalized Training Plans with AI",
      "summary": "",
      "url": "https://felixrieseberg.github.io/claude-coach/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-ac29e4c5",
      "type": "article",
      "title": "I Built Claude Code into Gmail with GitHub Actions and MCP Bundles",
      "summary": "",
      "url": "https://medium.com/@tony.lewis.london/how-i-built-an-ai-active-gmail-inbox-with-real-context-personalization-without-googles-ai-64937a191ffa",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-c2c00de9",
      "type": "article",
      "title": "Show HN: I accidentally built \"SQLite for AI memory\" (Memvid)",
      "summary": "",
      "url": "https://github.com/memvid/memvid",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-4ae00661",
      "type": "article",
      "title": "Claude Agent SDK [Full Workshop] [video]",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=TqC1qOfiVcQ",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-175d4bb3",
      "type": "article",
      "title": "Show HN: We're pitting 9 AI models in a stock portfolio competition",
      "summary": "",
      "url": "https://portfoliogenius.ai/leaderboards",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-2d246e51",
      "type": "article",
      "title": "Show HN: Context Protocol, a sovereign-first workflow for thinking with LLMs",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46502088",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-1850275a",
      "type": "article",
      "title": "Show HN: Generate photography prompts from a product image (for Gemini)",
      "summary": "",
      "url": "https://imagetransformprompt.com/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-437a5264",
      "type": "article",
      "title": "Show HN: AgTrace \u2013 Observability for AI Coding Agents via MCP (Claude Code etc.)",
      "summary": "",
      "url": "https://github.com/lanegrid/agtrace",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-5ddb05a7",
      "type": "article",
      "title": "Samsung to double AI mobile devices to 800M units this year",
      "summary": "",
      "url": "https://www.reuters.com/world/china/samsung-double-mobile-devices-powered-by-googles-gemini-800-mln-units-this-year-2026-01-05/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-44ad89be",
      "type": "article",
      "title": "Translating Cave Story into Classical Latin with Gemini",
      "summary": "",
      "url": "https://www.semilin.dev/blog/doukutsu-translator",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-b7d7a098",
      "type": "article",
      "title": "Show HN: DayLeet \u2013 A daily habit for sharpening whiteboard logic",
      "summary": "",
      "url": "https://dayleet.com/",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-a70dbbed",
      "type": "article",
      "title": "Orchestrating GCP Packet Mirroring with Gemini CLI and Google MCP",
      "summary": "",
      "url": "https://www.thefactorysystem.ai/blog/orchestrating-gcp-packet-mirroring-gemini-cli-google-mcp",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-abda2974",
      "type": "article",
      "title": "From Snoop to Solutions: Orchestrating Packet Analysis with Gemini and Tshark",
      "summary": "",
      "url": "https://www.thefactorysystem.ai/blog/orchestrating-packet-analysis-gemini-tshark",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-1c2dba33",
      "type": "article",
      "title": "Show HN: I built a UI for Gemini 3 (Nano Banana) Batch API \u2013 50% cheaper",
      "summary": "",
      "url": "https://github.com/aaronkwhite/nanobanana-studio",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-da4415ac",
      "type": "article",
      "title": "Show HN: Gemini ReAct Java \u2013 A lightweight, typed LLM library for Java",
      "summary": "",
      "url": "https://github.com/srijithunni7182/llm4j/tree/main/gemini-react-java",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-08e21d1c",
      "type": "article",
      "title": "Agent Skills are coming to Gemini CLI",
      "summary": "",
      "url": "https://github.com/google-gemini/gemini-cli/commit/de1233b8c",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-14dd4219",
      "type": "article",
      "title": "Show HN: Create PDFs in ChatGPT natively. Convert Latex to pdf and download",
      "summary": "",
      "url": "https://www.strivemath.com/pdf",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-30bc9d7f",
      "type": "article",
      "title": "Skeptic impressed by colleague's AI workflow",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46481814",
      "source": "hackernews",
      "date": "2026-01-03",
      "trendingScore": 50
    },
    {
      "id": "article-71e65bfe",
      "type": "article",
      "title": "Gemini 3.0 Pro helps solve longstanding mystery in the Nuremberg Chronicle",
      "summary": "",
      "url": "https://siliconangle.com/2026/01/01/googles-gemini-3-0-pro-helps-solve-long-standing-mystery-nuremberg-chronicle/",
      "source": "hackernews",
      "date": "2026-01-03",
      "trendingScore": 50
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 39
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 3
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 40
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 3
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 11
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 13
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 19
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 4
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 1
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 4
    },
    {
      "id": "topic-diffusion-models",
      "type": "topic",
      "title": "Diffusion Models",
      "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
      "connectionCount": 1
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 7
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 2
    },
    {
      "id": "org-nvidia",
      "type": "organization",
      "title": "NVIDIA",
      "summary": "NVIDIA - AI research and development.",
      "connectionCount": 4
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-google-deepmind",
      "type": "organization",
      "title": "Google DeepMind",
      "summary": "Google DeepMind - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-deepmind",
      "type": "organization",
      "title": "DeepMind",
      "summary": "DeepMind - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-cohere",
      "type": "organization",
      "title": "Cohere",
      "summary": "Cohere - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-amazon",
      "type": "organization",
      "title": "Amazon",
      "summary": "Amazon - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-chatgpt",
      "type": "model",
      "title": "ChatGPT",
      "summary": "ChatGPT AI model.",
      "connectionCount": 2
    },
    {
      "id": "model-gpt-4",
      "type": "model",
      "title": "GPT-4",
      "summary": "GPT-4 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4o",
      "type": "model",
      "title": "GPT-4o",
      "summary": "GPT-4o AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 18
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 11
    },
    {
      "id": "model-llama",
      "type": "model",
      "title": "Llama",
      "summary": "Llama AI model.",
      "connectionCount": 1
    }
  ],
  "edges": [
    {
      "source": "article-1268d449",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9bf07684",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9af5012",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9af5012",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b7a7eec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b7a7eec",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b7a7eec",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-abf20bec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-35c9f81d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-35c9f81d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a2b6aa5",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a2b6aa5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3aa1d71c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3aa1d71c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0075f93f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0075f93f",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gpt-4",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gpt-4o",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b2b3be14",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ac1448ea",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ac1448ea",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdc0022c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdc0022c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c0a33d9b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c0a33d9b",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-46852fbb",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-46852fbb",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-06fae34f",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ae4848f7",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ae4848f7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-cf213fb9",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-cf213fb9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d5b8c783",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b119d0a0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a13d414d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a13d414d",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-a13d414d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a13d414d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-011b2c8f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4c45fb6",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c4c45fb6",
      "target": "org-google-deepmind",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c4c45fb6",
      "target": "org-deepmind",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-905d17e5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-905d17e5",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-905d17e5",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d8da28ac",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-d8da28ac",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-d8da28ac",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-d8da28ac",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a27aaaac",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-841deb19",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3488afb9",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-3488afb9",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7eee472f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6755eb9f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6755eb9f",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6755eb9f",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-6755eb9f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2157297b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-815670fc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-815670fc",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-815670fc",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d8d5e98",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d8d5e98",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d8d5e98",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-928f2fda",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-928f2fda",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-928f2fda",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-53ff4ed8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-53ff4ed8",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6f97ff6e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6f97ff6e",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-6f97ff6e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6f97ff6e",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6f97ff6e",
      "target": "model-llama",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f24de1dd",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f24de1dd",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f24de1dd",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-202cdeb9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f408c4b6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f408c4b6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f408c4b6",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6ebaaa2a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6ebaaa2a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-58d6e52c",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-58d6e52c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3988308c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-3988308c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5d585b6c",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5d585b6c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5d585b6c",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-2d40cb18",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2d40cb18",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2d40cb18",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdb54da3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdb54da3",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdb54da3",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e7b5566f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-08c690d9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5583d90b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5583d90b",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-8dc8fa4b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8dc8fa4b",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-8dc8fa4b",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-16b7717d",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-16b7717d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-16b7717d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-423ae0f6",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-423ae0f6",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-66f18b5e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-66f18b5e",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e4a7bbc2",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4aefc378",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-4aefc378",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-24058352",
      "target": "org-amazon",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-34cf6bd8",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b3a0b383",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-47483037",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-b80e3229",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a97a100",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7a8d8c97",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-05f28cdc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d98abdd9",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b06c1494",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7226401f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7226401f",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-76e018f4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fd38c95f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1c8cbe6a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-93842b3e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-184e34c6",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e5b5c482",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a4ea8133",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9fa6a40",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-576a24e1",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ea74e6ad",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7d0404a8",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d4ea8713",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7cf6d84c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7cf6d84c",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-9f47aad2",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0bdfc555",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-0bdfc555",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0bdfc555",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a5983ddf",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-83ef8e2f",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-83ef8e2f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-72504f2c",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2f4dfc67",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ac29e4c5",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4ae00661",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4ae00661",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-4ae00661",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2d246e51",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2d246e51",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-437a5264",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-437a5264",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-44ad89be",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a70dbbed",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a70dbbed",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-abda2974",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1c2dba33",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-da4415ac",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-da4415ac",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-08e21d1c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-08e21d1c",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-14dd4219",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-71e65bfe",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}