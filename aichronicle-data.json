{
  "metadata": {
    "lastUpdated": "2026-01-08T06:32:28.108352Z",
    "totalArticles": 139,
    "totalNodes": 167,
    "totalEdges": 248,
    "dateRange": {
      "start": "2026-01-02",
      "end": "2026-01-08"
    }
  },
  "nodes": [
    {
      "id": "article-9f769fef",
      "type": "article",
      "title": "Mastering the Game of Go with Self-play Experience Replay",
      "summary": "arXiv:2601.03306v1 Announce Type: new Abstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and o",
      "url": "https://arxiv.org/abs/2601.03306",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-24448a5d",
      "type": "article",
      "title": "Digital Red Queen: Adversarial Program Evolution in Core War with LLMs",
      "summary": "arXiv:2601.03335v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embraces",
      "url": "https://arxiv.org/abs/2601.03335",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-5f9dba51",
      "type": "article",
      "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization",
      "summary": "arXiv:2601.03359v1 Announce Type: new Abstract: Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that dec",
      "url": "https://arxiv.org/abs/2601.03359",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-5a4f1b00",
      "type": "article",
      "title": "Exploration Through Introspection: A Self-Aware Reward Model",
      "summary": "arXiv:2601.03389v1 Announce Type: new Abstract: Understanding how artificial agents model internal mental states is central to advancing Theory of Mind in AI. Evidence points to a unified system for self- and other-awareness. We explore this self-awareness by having reinforcement learning agents infer their own internal states in gridworld environments. Specifically, we introduce an introspective exploration component that is inspired by biological pain as a learning signal by utilizing a hidden",
      "url": "https://arxiv.org/abs/2601.03389",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-e27dd56c",
      "type": "article",
      "title": "Toward Maturity-Based Certification of Embodied AI: Quantifying Trustworthiness Through Measurement Mechanisms",
      "summary": "arXiv:2601.03470v1 Announce Type: new Abstract: We propose a maturity-based framework for certifying embodied AI systems through explicit measurement mechanisms. We argue that certifiable embodied AI requires structured assessment frameworks, quantitative scoring mechanisms, and methods for navigating multi-objective trade-offs inherent in trustworthiness evaluation. We demonstrate this approach using uncertainty quantification as an exemplar measurement mechanism and illustrate feasibility thro",
      "url": "https://arxiv.org/abs/2601.03470",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-1a53e9b2",
      "type": "article",
      "title": "CPGPrompt: Translating Clinical Guidelines into LLM-Executable Decision Support",
      "summary": "arXiv:2601.03475v1 Announce Type: new Abstract: Clinical practice guidelines (CPGs) provide evidence-based recommendations for patient care; however, integrating them into Artificial Intelligence (AI) remains challenging. Previous approaches, such as rule-based systems, face significant limitations, including poor interpretability, inconsistent adherence to guidelines, and narrow domain applicability. To address this, we develop and validate CPGPrompt, an auto-prompting system that converts narr",
      "url": "https://arxiv.org/abs/2601.03475",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-4c6adb79",
      "type": "article",
      "title": "Personalization of Large Foundation Models for Health Interventions",
      "summary": "arXiv:2601.03482v1 Announce Type: new Abstract: Large foundation models (LFMs) transform healthcare AI in prevention, diagnostics, and treatment. However, whether LFMs can provide truly personalized treatment recommendations remains an open question. Recent research has revealed multiple challenges for personalization, including the fundamental generalizability paradox: models achieving high accuracy in one clinical study perform at chance level in others, demonstrating that personalization and ",
      "url": "https://arxiv.org/abs/2601.03482",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-d11b5ee2",
      "type": "article",
      "title": "Evolving Programmatic Skill Networks",
      "summary": "arXiv:2601.03509v1 Announce Type: new Abstract: We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault loca",
      "url": "https://arxiv.org/abs/2601.03509",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-8e0cd4fc",
      "type": "article",
      "title": "Variance Computation for Weighted Model Counting with Knowledge Compilation Approach",
      "summary": "arXiv:2601.03523v1 Announce Type: new Abstract: One of the most important queries in knowledge compilation is weighted model counting (WMC), which has been applied to probabilistic inference on various models, such as Bayesian networks. In practical situations on inference tasks, the model's parameters have uncertainty because they are often learned from data, and thus we want to compute the degree of uncertainty in the inference outcome. One possible approach is to regard the inference outcome ",
      "url": "https://arxiv.org/abs/2601.03523",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-062cefdc",
      "type": "article",
      "title": "STAR-S: Improving Safety Alignment through Self-Taught Reasoning on Safety Rules",
      "summary": "arXiv:2601.03537v1 Announce Type: new Abstract: Defending against jailbreak attacks is crucial for the safe deployment of Large Language Models (LLMs). Recent research has attempted to improve safety by training models to reason over safety rules before responding. However, a key issue lies in determining what form of safety reasoning effectively defends against jailbreak attacks, which is difficult to explicitly design or directly obtain. To address this, we propose \\textbf{STAR-S} (\\textbf{S}e",
      "url": "https://arxiv.org/abs/2601.03537",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-47fbbfe8",
      "type": "article",
      "title": "ReEfBench: Quantifying the Reasoning Efficiency of LLMs",
      "summary": "arXiv:2601.03550v1 Announce Type: new Abstract: Test-time scaling has enabled Large Language Models (LLMs) to tackle complex reasoning, yet the limitations of current Chain-of-Thought (CoT) evaluation obscures whether performance gains stem from genuine reasoning or mere verbosity. To address this, (1) we propose a novel neuro-symbolic framework for the non-intrusive, comprehensive process-centric evaluation of reasoning. (2) Through this lens, we identify four distinct behavioral prototypes and",
      "url": "https://arxiv.org/abs/2601.03550",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-76c77af3",
      "type": "article",
      "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
      "summary": "arXiv:2601.03555v1 Announce Type: new Abstract: Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned R",
      "url": "https://arxiv.org/abs/2601.03555",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-afd38697",
      "type": "article",
      "title": "Controllable LLM Reasoning via Sparse Autoencoder-Based Steering",
      "summary": "arXiv:2601.03595v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) exhibit human-like cognitive reasoning strategies (e.g. backtracking, cross-verification) during reasoning process, which improves their performance on complex tasks. Currently, reasoning strategies are autonomously selected by LRMs themselves. However, such autonomous selection often produces inefficient or even erroneous reasoning paths. To make reasoning more reliable and flexible, it is important to develop methods",
      "url": "https://arxiv.org/abs/2601.03595",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-690b408b",
      "type": "article",
      "title": "Interleaved Tool-Call Reasoning for Protein Function Understanding",
      "summary": "arXiv:2601.03604v1 Announce Type: new Abstract: Recent advances in large language models (LLMs) have highlighted the effectiveness of chain-of-thought reasoning in symbolic domains such as mathematics and programming. However, our study shows that directly transferring such text-based reasoning paradigms to protein function understanding is ineffective: reinforcement learning mainly amplifies superficial keyword patterns while failing to introduce new biological knowledge, resulting in limited g",
      "url": "https://arxiv.org/abs/2601.03604",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-7c2eb00c",
      "type": "article",
      "title": "Architecting Agentic Communities using Design Patterns",
      "summary": "arXiv:2601.03624v1 Announce Type: new Abstract: The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Age",
      "url": "https://arxiv.org/abs/2601.03624",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-de14dc10",
      "type": "article",
      "title": "How Does the Thinking Step Influence Model Safety? An Entropy-based Safety Reminder for LRMs",
      "summary": "arXiv:2601.03662v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) achieve remarkable success through explicit thinking steps, yet the thinking steps introduce a novel risk by potentially amplifying unsafe behaviors. Despite this vulnerability, conventional defense mechanisms remain ineffective as they overlook the unique reasoning dynamics of LRMs. In this work, we find that the emergence of safe-reminding phrases within thinking steps plays a pivotal role in ensuring LRM safety. Mot",
      "url": "https://arxiv.org/abs/2601.03662",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-813adfc0",
      "type": "article",
      "title": "Sandwich Reasoning: An Answer-Reasoning-Answer Approach for Low-Latency Query Correction",
      "summary": "arXiv:2601.03672v1 Announce Type: new Abstract: Query correction is a critical entry point in modern search pipelines, demanding high accuracy strictly within real-time latency constraints. Chain-of-Thought (CoT) reasoning improves accuracy but incurs prohibitive latency for real-time query correction. A potential solution is to output an answer before reasoning to reduce latency; however, under autoregressive decoding, the early answer is independent of subsequent reasoning, preventing the mode",
      "url": "https://arxiv.org/abs/2601.03672",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-ff404de7",
      "type": "article",
      "title": "Personalized Medication Planning via Direct Domain Modeling and LLM-Generated Heuristics",
      "summary": "arXiv:2601.03687v1 Announce Type: new Abstract: Personalized medication planning involves selecting medications and determining a dosing schedule to achieve medical goals specific to each individual patient. Previous work successfully demonstrated that automated planners, using general domain-independent heuristics, are able to generate personalized treatments, when the domain and problems are modeled using a general domain description language (\\pddlp). Unfortunately, this process was limited i",
      "url": "https://arxiv.org/abs/2601.03687",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-9b76eba3",
      "type": "article",
      "title": "EntroCoT: Enhancing Chain-of-Thought via Adaptive Entropy-Guided Segmentation",
      "summary": "arXiv:2601.03769v1 Announce Type: new Abstract: Chain-of-Thought (CoT) prompting has significantly enhanced the mathematical reasoning capabilities of Large Language Models. We find existing fine-tuning datasets frequently suffer from the \"answer right but reasoning wrong\" probelm, where correct final answers are derived from hallucinated, redundant, or logically invalid intermediate steps. This paper proposes EntroCoT, a unified framework for automatically identifying and refining low-quality C",
      "url": "https://arxiv.org/abs/2601.03769",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-34862d3b",
      "type": "article",
      "title": "ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition",
      "summary": "arXiv:2601.03822v1 Announce Type: new Abstract: Large language models (LLMs) can achieve strong reasoning performance with sufficient computation, but they do not inherently know how much computation a task requires. We study budgeted inference-time reasoning for multiple tasks under a strict global token constraint and formalize it as a Ordered Stochastic Multiple-Choice Knapsack Problem(OS-MCKP). This perspective highlights a meta-cognitive requirement -- anticipating task difficulty, estimati",
      "url": "https://arxiv.org/abs/2601.03822",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3ceec403",
      "type": "article",
      "title": "Lightweight Transformer Architectures for Edge Devices in Real-Time Applications",
      "summary": "arXiv:2601.03290v1 Announce Type: new Abstract: The deployment of transformer-based models on resource-constrained edge devices represents a critical challenge in enabling real-time artificial intelligence applications. This comprehensive survey examines lightweight transformer architectures specifically designed for edge deployment, analyzing recent advances in model compression, quantization, pruning, and knowledge distillation techniques. We systematically review prominent lightweight variant",
      "url": "https://arxiv.org/abs/2601.03290",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-85baee3d",
      "type": "article",
      "title": "Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts",
      "summary": "arXiv:2601.03315v1 Announce Type: new Abstract: We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. One completed the pipeline and was accepted to Agents4Science 2025, an experimental inaugural venue that required AI systems as first authors, passing both human and multi-AI review. From these attempts,",
      "url": "https://arxiv.org/abs/2601.03315",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-89359806",
      "type": "article",
      "title": "Ratio-Variance Regularized Policy Optimization for Efficient LLM Fine-tuning",
      "summary": "arXiv:2601.03320v1 Announce Type: new Abstract: On-policy reinforcement learning (RL), particularly Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO), has become the dominant paradigm for fine-tuning large language models (LLMs). While policy ratio clipping stabilizes training, this heuristic hard constraint incurs a fundamental cost: it indiscriminately truncates gradients from high-return yet high-divergence actions, suppressing rare but highly informative \"eurek",
      "url": "https://arxiv.org/abs/2601.03320",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-e8c2903d",
      "type": "article",
      "title": "Aligning Findings with Diagnosis: A Self-Consistent Reinforcement Learning Framework for Trustworthy Radiology Reporting",
      "summary": "arXiv:2601.03321v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) have shown strong potential for radiology report generation, yet their clinical translation is hindered by architectural heterogeneity and the prevalence of factual hallucinations. Standard supervised fine-tuning often fails to strictly align linguistic outputs with visual evidence, while existing reinforcement learning approaches struggle with either prohibitive computational costs or limited exploration. T",
      "url": "https://arxiv.org/abs/2601.03321",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-97d52eea",
      "type": "article",
      "title": "HEEGNet: Hyperbolic Embeddings for EEG",
      "summary": "arXiv:2601.03322v1 Announce Type: new Abstract: Electroencephalography (EEG)-based brain-computer interfaces facilitate direct communication with a computer, enabling promising applications in human-computer interactions. However, their utility is currently limited because EEG decoding often suffers from poor generalization due to distribution shifts across domains (e.g., subjects). Learning robust representations that capture underlying task-relevant information would mitigate these shifts and ",
      "url": "https://arxiv.org/abs/2601.03322",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-21c4d57f",
      "type": "article",
      "title": "Extreme-value forest fire prediction A study of the Loss Function in an Ordinality Scheme",
      "summary": "arXiv:2601.03327v1 Announce Type: new Abstract: Wildfires are highly imbalanced natural hazards in both space and severity, making the prediction of extreme events particularly challenging. In this work, we introduce the first ordinal classification framework for forecasting wildfire severity levels directly aligned with operational decision-making in France. Our study investigates the influence of loss-function design on the ability of neural models to predict rare yet critical high-severity fi",
      "url": "https://arxiv.org/abs/2601.03327",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-cb8a6916",
      "type": "article",
      "title": "Attention mechanisms in neural networks",
      "summary": "arXiv:2601.03329v1 Announce Type: new Abstract: Attention mechanisms represent a fundamental paradigm shift in neural network architectures, enabling models to selectively focus on relevant portions of input sequences through learned weighting functions. This monograph provides a comprehensive and rigorous mathematical treatment of attention mechanisms, encompassing their theoretical foundations, computational properties, and practical implementations in contemporary deep learning systems. Appli",
      "url": "https://arxiv.org/abs/2601.03329",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-278f9563",
      "type": "article",
      "title": "LUT-KAN: Segment-wise LUT Quantization for Fast KAN Inference",
      "summary": "arXiv:2601.03332v1 Announce Type: new Abstract: Kolmogorov--Arnold Networks (KAN) replace scalar weights by learnable univariate functions, often implemented with B-splines. This design can be accurate and interpretable, but it makes inference expensive on CPU because each layer requires many spline evaluations. Standard quantization toolchains are also hard to apply because the main computation is not a matrix multiply but repeated spline basis evaluation. This paper introduces LUT-KAN, a segme",
      "url": "https://arxiv.org/abs/2601.03332",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-b0cc2fbc",
      "type": "article",
      "title": "Physics-Informed Gaussian Process Regression for the Constitutive Modeling of Concrete: A Data-Driven Improvement to Phenomenological Models",
      "summary": "arXiv:2601.03367v1 Announce Type: new Abstract: Understanding and modeling the constitutive behavior of concrete is crucial for civil and defense applications, yet widely used phenomenological models such as Karagozian \\& Case concrete (KCC) model depend on empirically calibrated failure surfaces that lack flexibility in model form and associated uncertainty quantification. This work develops a physics-informed framework that retains the modular elastoplastic structure of KCC model while replaci",
      "url": "https://arxiv.org/abs/2601.03367",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3e988fb4",
      "type": "article",
      "title": "Enhancing Small Dataset Classification Using Projected Quantum Kernels with Convolutional Neural Networks",
      "summary": "arXiv:2601.03375v1 Announce Type: new Abstract: Convolutional Neural Networks (CNNs) have shown promising results in efficiency and accuracy in image classification. However, their efficacy often relies on large, labeled datasets, posing challenges for applications with limited data availability. Our research addresses these challenges by introducing an innovative approach that leverages projected quantum kernels (PQK) to enhance feature extraction for CNNs, specifically tailored for small datas",
      "url": "https://arxiv.org/abs/2601.03375",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-2aebefc5",
      "type": "article",
      "title": "Weather-Aware Transformer for Real-Time Route Optimization in Drone-as-a-Service Operations",
      "summary": "arXiv:2601.03376v1 Announce Type: new Abstract: This paper presents a novel framework to accelerate route prediction in Drone-as-a-Service operations through weather-aware deep learning models. While classical path-planning algorithms, such as A* and Dijkstra, provide optimal solutions, their computational complexity limits real-time applicability in dynamic environments. We address this limitation by training machine learning and deep learning models on synthetic datasets generated from classic",
      "url": "https://arxiv.org/abs/2601.03376",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-7b000609",
      "type": "article",
      "title": "SIGMA: Scalable Spectral Insights for LLM Collapse",
      "summary": "arXiv:2601.03385v1 Announce Type: new Abstract: The rapid adoption of synthetic data for training Large Language Models (LLMs) has introduced the technical challenge of \"model collapse\"-a degenerative process where recursive training on model-generated content leads to a contraction of distributional variance and representational quality. While the phenomenology of collapse is increasingly evident, rigorous methods to quantify and predict its onset in high-dimensional spaces remain elusive. In t",
      "url": "https://arxiv.org/abs/2601.03385",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-4507a0dc",
      "type": "article",
      "title": "Inferring Clinically Relevant Molecular Subtypes of Pancreatic Cancer from Routine Histopathology Using Deep Learning",
      "summary": "arXiv:2601.03410v1 Announce Type: new Abstract: Molecular subtyping of PDAC into basal-like and classical has established prognostic and predictive value. However, its use in clinical practice is limited by cost, turnaround time, and tissue requirements, thereby restricting its application in the management of PDAC. We introduce PanSubNet, an interpretable deep learning framework that predicts therapy-relevant molecular subtypes directly from standard H&amp;E-stained WSIs. PanSubNet was develope",
      "url": "https://arxiv.org/abs/2601.03410",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-e02e2f33",
      "type": "article",
      "title": "Sensor to Pixels: Decentralized Swarm Gathering via Image-Based Reinforcement Learning",
      "summary": "arXiv:2601.03413v1 Announce Type: new Abstract: This study highlights the potential of image-based reinforcement learning methods for addressing swarm-related tasks. In multi-agent reinforcement learning, effective policy learning depends on how agents sense, interpret, and process inputs. Traditional approaches often rely on handcrafted feature extraction or raw vector-based representations, which limit the scalability and efficiency of learned policies concerning input order and size. In this ",
      "url": "https://arxiv.org/abs/2601.03413",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-639ae756",
      "type": "article",
      "title": "Jailbreaking LLMs Without Gradients or Priors: Effective and Transferable Attacks",
      "summary": "arXiv:2601.03420v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed in safety-critical domains, rigorously evaluating their robustness against adversarial jailbreaks is essential. However, current safety evaluations often overestimate robustness because existing automated attacks are limited by restrictive assumptions. They typically rely on handcrafted priors or require white-box access for gradient propagation. We challenge these constraints by demonstrati",
      "url": "https://arxiv.org/abs/2601.03420",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-e5a7d8e6",
      "type": "article",
      "title": "Spectral Archaeology: The Causal Topology of Model Evolution",
      "summary": "arXiv:2601.03424v1 Announce Type: new Abstract: Behavioral benchmarks tell us \\textit{what} a model does, but not \\textit{how}. We introduce a training-free mechanistic probe using attention-graph spectra. Treating each layer as a token graph, we compute algebraic connectivity ($\\lambda_2$), smoothness, and spectral entropy. Across 12 models and 10 languages, these measures yield stable ``spectral fingerprints'' that expose discontinuities missed by standard evaluation. We report four results. (",
      "url": "https://arxiv.org/abs/2601.03424",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3e17a02b",
      "type": "article",
      "title": "The Illusion of Specialization: Unveiling the Domain-Invariant \"Standing Committee\" in Mixture-of-Experts Models",
      "summary": "arXiv:2601.03425v1 Announce Type: new Abstract: Mixture of Experts models are widely assumed to achieve domain specialization through sparse routing. In this work, we question this assumption by introducing COMMITTEEAUDIT, a post hoc framework that analyzes routing behavior at the level of expert groups rather than individual experts. Across three representative models and the MMLU benchmark, we uncover a domain-invariant Standing Committee. This is a compact coalition of routed experts that con",
      "url": "https://arxiv.org/abs/2601.03425",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-6df313ec",
      "type": "article",
      "title": "VNU-Bench: A Benchmarking Dataset for Multi-Source Multimodal News Video Understanding",
      "summary": "arXiv:2601.03434v1 Announce Type: new Abstract: News videos are carefully edited multimodal narratives that combine narration, visuals, and external quotations into coherent storylines. In recent years, there have been significant advances in evaluating multimodal large language models (MLLMs) for news video understanding. However, existing benchmarks largely focus on single-source, intra-video reasoning, where each report is processed in isolation. In contrast, real-world news consumption is in",
      "url": "https://arxiv.org/abs/2601.03434",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-7e5f71e2",
      "type": "article",
      "title": "Soft Contextualized Encoder For User Defined Text Classification",
      "summary": "arXiv:2601.03450v1 Announce Type: new Abstract: User-Defined Text Classification (UDTC) considers the challenge of classifying input text to user-specified, previously unseen classes, a setting that arises frequently in real-world applications such as enterprise analytics, content moderation, and domain-specific information retrieval. We propose a soft-contextualized encoder architecture for UDTC which contextualizes each candidate label with the label set and a static soft prompt representation",
      "url": "https://arxiv.org/abs/2601.03450",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-fb8abef8",
      "type": "article",
      "title": "An Expectation-Maximization Algorithm for Domain Adaptation in Gaussian Causal Models",
      "summary": "arXiv:2601.03459v1 Announce Type: new Abstract: We study the problem of imputing a designated target variable that is systematically missing in a shifted deployment domain, when a Gaussian causal DAG is available from a fully observed source domain. We propose a unified EM-based framework that combines source and target data through the DAG structure to transfer information from observed variables to the missing target. On the methodological side, we formulate a population EM operator in the DAG",
      "url": "https://arxiv.org/abs/2601.03459",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-6bcc4c1e",
      "type": "article",
      "title": "DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing",
      "summary": "arXiv:2601.03261v1 Announce Type: new Abstract: Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context blindness in noisy environments. To bridge this gap, we propose DeepResearch-Slice, a simple yet effective neuro-symbolic framework. Unlike implicit attention, our approach predicts precise span indic",
      "url": "https://arxiv.org/abs/2601.03261",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-594afdb3",
      "type": "article",
      "title": "Internal Reasoning vs. External Control: A Thermodynamic Analysis of Sycophancy in Large Language Models",
      "summary": "arXiv:2601.03263v1 Announce Type: new Abstract: Large Language Models frequently exhibit sycophancy, prioritizing user agreeableness over correctness. We investigate whether this requires external regulation or can be mitigated by internal reasoning alone. Using CAP-GSM8K (N=500), an adversarial dataset, we evaluate internal (CoT) versus external (RCA) mechanisms across GPT-3.5, GPT-4o, and GPT-5.1. Our results reveal the structural limits of internal reasoning: it causes performance collapse in",
      "url": "https://arxiv.org/abs/2601.03263",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3bf212d8",
      "type": "article",
      "title": "Jailbreak-Zero: A Path to Pareto Optimal Red Teaming for Large Language Models",
      "summary": "arXiv:2601.03265v1 Announce Type: new Abstract: This paper introduces Jailbreak-Zero, a novel red teaming methodology that shifts the paradigm of Large Language Model (LLM) safety evaluation from a constrained example-based approach to a more expansive and effective policy-based framework. By leveraging an attack LLM to generate a high volume of diverse adversarial prompts and then fine-tuning this attack model with a preference dataset, Jailbreak-Zero achieves Pareto optimality across the cruci",
      "url": "https://arxiv.org/abs/2601.03265",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-dd212150",
      "type": "article",
      "title": "Benchmarking and Adapting On-Device Large Language Models for Clinical Decision Support",
      "summary": "arXiv:2601.03266v1 Announce Type: new Abstract: Large language models (LLMs) have rapidly advanced in clinical decision-making, yet the deployment of proprietary systems is hindered by privacy concerns and reliance on cloud-based infrastructure. Open-source alternatives allow local inference but often require large model sizes that limit their use in resource-constrained clinical settings. Here, we benchmark two on-device LLMs, gpt-oss-20b and gpt-oss-120b, across three representative clinical t",
      "url": "https://arxiv.org/abs/2601.03266",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-6cacfbe3",
      "type": "article",
      "title": "OpenAI GPT-5 System Card",
      "summary": "arXiv:2601.03267v1 Announce Type: new Abstract: This is the system card published alongside the OpenAI GPT-5 launch, August 2025. GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to use based on conversation type, complexity, tool needs, and explicit intent (for example, if you say 'think hard about this' in the prompt). The router is continuously trained on rea",
      "url": "https://arxiv.org/abs/2601.03267",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-31896352",
      "type": "article",
      "title": "WRAVAL -- WRiting Assist eVALuation",
      "summary": "arXiv:2601.03268v1 Announce Type: new Abstract: The emergence of Large Language Models (LLMs) has shifted language model evaluation toward reasoning and problem-solving tasks as measures of general intelligence. Small Language Models (SLMs) -- defined here as models under 10B parameters -- typically score 3-4 times lower than LLMs on these metrics. However, we demonstrate that these evaluations fail to capture SLMs' effectiveness in common industrial applications, such as tone modification tasks",
      "url": "https://arxiv.org/abs/2601.03268",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-151d060d",
      "type": "article",
      "title": "The Instruction Gap: LLMs get lost in Following Instruction",
      "summary": "arXiv:2601.03269v1 Announce Type: new Abstract: Large Language Models (LLMs) have shown remarkable capabilities in natural language understanding and generation, yet their deployment in enterprise environments reveals a critical limitation: inconsistent adherence to custom instructions. This study presents a comprehensive evaluation of 13 leading LLMs across instruction compliance, response accuracy, and performance metrics in realworld RAG (Retrieval-Augmented Generation) scenarios. Through sys",
      "url": "https://arxiv.org/abs/2601.03269",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3057c910",
      "type": "article",
      "title": "Advances and Challenges in Semantic Textual Similarity: A Comprehensive Survey",
      "summary": "arXiv:2601.03270v1 Announce Type: new Abstract: Semantic Textual Similarity (STS) research has expanded rapidly since 2021, driven by advances in transformer architectures, contrastive learning, and domain-specific techniques. This survey reviews progress across six key areas: transformer-based models, contrastive learning, domain-focused solutions, multi-modal methods, graph-based approaches, and knowledge-enhanced techniques. Recent transformer models such as FarSSiBERT and DeBERTa-v3 have ach",
      "url": "https://arxiv.org/abs/2601.03270",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3d281f86",
      "type": "article",
      "title": "Less is more: Not all samples are effective for evaluation",
      "summary": "arXiv:2601.03272v1 Announce Type: new Abstract: The versatility of Large Language Models (LLMs) in vertical domains has spurred the development of numerous specialized evaluation benchmarks. However, these benchmarks often suffer from significant semantic redundancy and impose high computational costs during evaluation. Existing compression methods, such as tinyBenchmarks depend critically on correctness labels from multiple historical models evaluated on the full test set, making them inapplica",
      "url": "https://arxiv.org/abs/2601.03272",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-4db91b8c",
      "type": "article",
      "title": "GuardEval: A Multi-Perspective Benchmark for Evaluating Safety, Fairness, and Robustness in LLM Moderators",
      "summary": "arXiv:2601.03273v1 Announce Type: new Abstract: As large language models (LLMs) become deeply embedded in daily life, the urgent need for safer moderation systems, distinguishing between naive from harmful requests while upholding appropriate censorship boundaries, has never been greater. While existing LLMs can detect harmful or unsafe content, they often struggle with nuanced cases such as implicit offensiveness, subtle gender and racial biases, and jailbreak prompts, due to the subjective and",
      "url": "https://arxiv.org/abs/2601.03273",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-54bcf10c",
      "type": "article",
      "title": "LLM_annotate: A Python package for annotating and analyzing fiction characters",
      "summary": "arXiv:2601.03274v1 Announce Type: new Abstract: LLM_annotate is a Python package for analyzing the personality of fiction characters with large language models. It standardizes workflows for annotating character behaviors in full texts (e.g., books and movie scripts), inferring character traits, and validating annotation/inference quality via a human-in-the-loop GUI. The package includes functions for text chunking, LLM-based annotation, character name disambiguation, quality scoring, and comput",
      "url": "https://arxiv.org/abs/2601.03274",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-5b069a66",
      "type": "article",
      "title": "Topic Segmentation Using Generative Language Models",
      "summary": "arXiv:2601.03276v1 Announce Type: new Abstract: Topic segmentation using generative Large Language Models (LLMs) remains relatively unexplored. Previous methods use semantic similarity between sentences, but such models lack the long range dependencies and vast knowledge found in LLMs. In this work, we propose an overlapping and recursive prompting strategy using sentence enumeration. We also support the adoption of the boundary similarity evaluation metric. Results show that LLMs can be more ef",
      "url": "https://arxiv.org/abs/2601.03276",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-f9422a42",
      "type": "article",
      "title": "Bare-Metal Tensor Virtualization: Overcoming the Memory Wall in Edge-AI Inference on ARM64",
      "summary": "arXiv:2601.03324v1 Announce Type: new Abstract: The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" the bottleneck where data movement latency outstrips arithmetic throughput. Standard inference runtimes often incur significant overhead through high-level abstractions, dynamic dispatch, and unaligned memory access patterns. In this work, we present a novel \"Virtual Tensor Core\" architecture implemented in software, optimized specifical",
      "url": "https://arxiv.org/abs/2601.03324",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-bbd1027a",
      "type": "article",
      "title": "A path to natural language through tokenisation and transformers",
      "summary": "arXiv:2601.03368v1 Announce Type: new Abstract: Natural languages exhibit striking regularities in their statistical structure, including notably the emergence of Zipf's and Heaps' laws. Despite this, it remains broadly unclear how these properties relate to the modern tokenisation schemes used in contemporary transformer models. In this note, we analyse the information content (as measured by the Shannon entropy) of various corpora under the assumption of a Zipfian frequency distribution, and d",
      "url": "https://arxiv.org/abs/2601.03368",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-f2f90e16",
      "type": "article",
      "title": "Metaphors are a Source of Cross-Domain Misalignment of Large Reasoning Models",
      "summary": "arXiv:2601.03388v1 Announce Type: new Abstract: Earlier research has shown that metaphors influence human's decision making, which raises the question of whether metaphors also influence large language models (LLMs)' reasoning pathways, considering their training data contain a large number of metaphors. In this work, we investigate the problem in the scope of the emergent misalignment problem where LLMs can generalize patterns learned from misaligned content in one domain to another domain. We ",
      "url": "https://arxiv.org/abs/2601.03388",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-8237f778",
      "type": "article",
      "title": "Breaking the Assistant Mold: Modeling Behavioral Variation in LLM Based Procedural Character Generation",
      "summary": "arXiv:2601.03396v1 Announce Type: new Abstract: Procedural content generation has enabled vast virtual worlds through levels, maps, and quests, but large-scale character generation remains underexplored. We identify two alignment-induced biases in existing methods: a positive moral bias, where characters uniformly adopt agreeable stances (e.g. always saying lying is bad), and a helpful assistant bias, where characters invariably answer questions directly (e.g. never refusing or deflecting). Whil",
      "url": "https://arxiv.org/abs/2601.03396",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3df78084",
      "type": "article",
      "title": "Rendering Data Unlearnable by Exploiting LLM Alignment Mechanisms",
      "summary": "arXiv:2601.03401v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly trained on massive, heterogeneous text corpora, raising serious concerns about the unauthorised use of proprietary or personal data during model training. In this work, we address the problem of data protection against unwanted model learning in a realistic black-box setting. We propose Disclaimer Injection, a novel data-level defence that renders text unlearnable to LLMs. Rather than relying on model-s",
      "url": "https://arxiv.org/abs/2601.03401",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-0d3b99b7",
      "type": "article",
      "title": "Tigrinya Number Verbalization: Rules, Algorithm, and Implementation",
      "summary": "arXiv:2601.03403v1 Announce Type: new Abstract: We present a systematic formalization of Tigrinya cardinal and ordinal number verbalization, addressing a gap in computational resources for the language. This work documents the canonical rules governing the expression of numerical values in spoken Tigrinya, including the conjunction system, scale words, and special cases for dates, times, and currency. We provide a formal algorithm for number-to-word conversion and release an open-source implemen",
      "url": "https://arxiv.org/abs/2601.03403",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-78fc06de",
      "type": "article",
      "title": "Implicit Graph, Explicit Retrieval: Towards Efficient and Interpretable Long-horizon Memory for Large Language Models",
      "summary": "arXiv:2601.03417v1 Announce Type: new Abstract: Long-horizon applications increasingly require large language models (LLMs) to answer queries when relevant evidence is sparse and dispersed across very long contexts. Existing memory systems largely follow two paradigms: explicit structured memories offer interpretability but often become brittle under long-context overload, while latent memory mechanisms are efficient and stable yet difficult to inspect. We propose LatentGraphMem, a memory framew",
      "url": "https://arxiv.org/abs/2601.03417",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-5dc2aa48",
      "type": "article",
      "title": "PCoA: A New Benchmark for Medical Aspect-Based Summarization With Phrase-Level Context Attribution",
      "summary": "arXiv:2601.03418v1 Announce Type: new Abstract: Verifying system-generated summaries remains challenging, as effective verification requires precise attribution to the source context, which is especially crucial in high-stakes medical domains. To address this challenge, we introduce PCoA, an expert-annotated benchmark for medical aspect-based summarization with phrase-level context attribution. PCoA aligns each aspect-based summary with its supporting contextual sentences and contributory phrase",
      "url": "https://arxiv.org/abs/2601.03418",
      "source": "arxiv",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-423ae0f6",
      "type": "article",
      "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-650e8a5e",
      "type": "article",
      "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
      "summary": "",
      "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-66f18b5e",
      "type": "article",
      "title": "NVIDIA brings agents to life with DGX Spark and Reachy Mini",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia-reachy-mini",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-0ba59559",
      "type": "article",
      "title": "LLMs contain a LOT of parameters. But what\u2019s a parameter?",
      "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. I am writing this because one of my editors woke up in the middle of the night and scribbled on a bedside notepad: \u201cWhat is a&#8230;",
      "url": "https://www.technologyreview.com/2026/01/07/1130795/what-even-is-a-parameter/",
      "source": "blogs",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f2318d54",
      "type": "article",
      "title": "Why AI predictions are so hard",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. Sometimes AI feels like a niche topic to write about, but then the holidays happen, and I hear relatives of all ages talking about cases of chatbot-induced psychosis, blaming rising electricity prices&#8230;",
      "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
      "source": "blogs",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8bdc2f5a",
      "type": "article",
      "title": "What\u2019s next for AI in 2026",
      "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In an industry in constant flux, sticking your neck out to predict what\u2019s coming next may seem reckless. (AI bubble? What AI bubble?) But for the&#8230;",
      "url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-1232a4c3",
      "type": "article",
      "title": "AI product distribution platform to tell where and how to get first 100 users?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46537797",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-9c8fda2f",
      "type": "article",
      "title": "Arm-based AI PC review",
      "summary": "",
      "url": "https://github.com/Mr-Yanwei/Blog-Review/blob/main/Arm/MetaComputing%20AI%20PC%20with%20Framework%20Laptop%2013%3A%20A%20New%20Force%20in%20Productivity%20and%20Entertainment%20on%20Arm%20Architecture.md",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-982dd1d0",
      "type": "article",
      "title": "IBM's AI agent Bob easily duped to run malware, researchers show",
      "summary": "",
      "url": "https://www.theregister.com/2026/01/07/ibm_bob_vulnerability/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-818b7ff7",
      "type": "article",
      "title": "AI layoffs are looking like corporate fiction that's masking a darker reality",
      "summary": "",
      "url": "https://fortune.com/2026/01/07/ai-layoffs-convenient-corporate-fiction-true-false-oxford-economics-productivity/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-6b7c7a30",
      "type": "article",
      "title": "Dell admits consumers don't care about AI PCs",
      "summary": "",
      "url": "https://www.theverge.com/news/857723/dell-consumers-ai-pcs-comments",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-6cd00e52",
      "type": "article",
      "title": "Ask HN: Identity crisis as a software engineer because of AI",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46537469",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-2d8c09ab",
      "type": "article",
      "title": "AI pilots a free-flying robot aboard the ISS for the 1st time",
      "summary": "",
      "url": "https://scienceclock.com/first-autonomous-ai-robot-flight-iss/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-c9fd12b9",
      "type": "article",
      "title": "AI Chatbot Startup, Google to Settle Lawsuits over Teen Suicides",
      "summary": "",
      "url": "https://www.wsj.com/tech/ai/ai-chatbot-startup-google-to-settle-lawsuits-over-teen-suicides-fb41a063",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-f1f1ca3a",
      "type": "article",
      "title": "Why we're taking legal action against SerpApi's unlawful scraping",
      "summary": "",
      "url": "https://blog.google/innovation-and-ai/technology/safety-security/serpapi-lawsuit/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-9bb77c78",
      "type": "article",
      "title": "Show HN: How I generate animated pixel art with AI and Python",
      "summary": "",
      "url": "https://sarthakmishra.com/blog/building-animated-sprite-hero",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-56c5a7a1",
      "type": "article",
      "title": "Ask HN: We built an air-gapped document vault with encrypted print and export",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46537186",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-aadc8cae",
      "type": "article",
      "title": "A field guide to sandboxing AI workloads",
      "summary": "",
      "url": "https://www.luiscardoso.dev/blog/sandboxes-for-ai",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-35416e60",
      "type": "article",
      "title": "Show HN: A skill that finds expert methodologies before generating AI skills",
      "summary": "",
      "url": "https://jefferyk.notion.site/The-Best-Skills-Aren-t-Written-They-re-Curated-2e2114c258a1805f9282f00437a4595e",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-211d8b69",
      "type": "article",
      "title": "Show HN: I built Mike \u2013 AI motion graphics",
      "summary": "",
      "url": "https://www.mike.new/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3245098a",
      "type": "article",
      "title": "Z.ai Goes Public",
      "summary": "",
      "url": "https://twitter.com/ZixuanLi/status/2009083001716560209",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-c5a0ce73",
      "type": "article",
      "title": "\"I put AI in a security camera\"",
      "summary": "",
      "url": "https://twitter.com/shiloh_wwe/status/2009058171332251862",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-69b72ccb",
      "type": "article",
      "title": "A history of AI in two line paper summaries (part two)",
      "summary": "",
      "url": "https://xquant.substack.com/p/what-if-we-simply-a-history-of-ai-20c",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-385429fd",
      "type": "article",
      "title": "LLM Guided GPU Kernel Optimization",
      "summary": "",
      "url": "https://mlai.blog/2025-12-20-llm-kernel-optimization",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3e1c21d4",
      "type": "article",
      "title": "LLM Poetry and the \"Greatness\" Question",
      "summary": "",
      "url": "https://hollisrobbinsanecdotal.substack.com/p/llm-poetry-and-the-greatness-question",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-a06710f1",
      "type": "article",
      "title": "Persistent Compromise of LLM Agents via Poisoned Experience Retrieval",
      "summary": "",
      "url": "https://arxiv.org/abs/2512.16962",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-64a02225",
      "type": "article",
      "title": "Show HN: Enriched HN, LLM-powered topic filtering for Hacker News",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46536799",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-ec29f4a0",
      "type": "article",
      "title": "Show HN: Graph:Easy ported to TypeScript with GPT-5.2",
      "summary": "",
      "url": "https://tomisin.space/graph-easy-ts/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-de1501a7",
      "type": "article",
      "title": "Inside An LLM",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46536090",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-19084899",
      "type": "article",
      "title": "Show HN: V.ai: a open source character platform",
      "summary": "",
      "url": "https://github.com/eotter-beep/vai",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-feab5aa8",
      "type": "article",
      "title": "Show HN: Telio \u2013 AI agents for call/text support, built on sandboxed lakehouses",
      "summary": "",
      "url": "https://gettelio.com/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-0489e5b7",
      "type": "article",
      "title": "Show HN: LLM-powered What If text gen for fun",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46534320",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8ad55c84",
      "type": "article",
      "title": "CheckMyLLM \u2013 A real-time \"status board\" for LLM reliability",
      "summary": "",
      "url": "https://checkmyllm.com/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-4709ccde",
      "type": "article",
      "title": "Show HN: Flatagents: State machine orchestration with stateless LLM agents",
      "summary": "",
      "url": "https://github.com/memgrafter/flatagents",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-114c3717",
      "type": "article",
      "title": "Show HN: Anyware \u2013 Remote Control for Claude Code",
      "summary": "",
      "url": "https://anyware.run/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-566b4e7d",
      "type": "article",
      "title": "Show HN: An LLM response cache that's aware of dynamic data",
      "summary": "",
      "url": "https://blog.butter.dev/on-automatic-template-induction-for-response-caching",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 51
    },
    {
      "id": "article-b48bab8b",
      "type": "article",
      "title": "Per-query energy consumption of LLMs",
      "summary": "",
      "url": "https://muxup.com/2026q1/per-query-energy-consumption-of-llms",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-28f29313",
      "type": "article",
      "title": "LLM from scratch, part 29 \u2013 using DDP to train a base model in the cloud",
      "summary": "",
      "url": "https://www.gilesthomas.com/2026/01/llm-from-scratch-29-ddp-training-a-base-model-in-the-cloud",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d44a24ec",
      "type": "article",
      "title": "The Silence of the LLaMbs: Getting LLMs to Shut Up",
      "summary": "",
      "url": "https://ossa-ma.github.io/blog/silence-of-the-llambs",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-09837dfb",
      "type": "article",
      "title": "I got paid minimum wage to solve an impossible problem",
      "summary": "",
      "url": "https://tiespetersen.substack.com/p/i-got-paid-minimum-wage-to-solve",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-3eb7961e",
      "type": "article",
      "title": "Claude Code 2.1.0 Released",
      "summary": "",
      "url": "https://github.com/anthropics/claude-code/blob/f34e2535b4fcf5fcc6cb0b566111c588b04873ee/CHANGELOG.md",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-33084c11",
      "type": "article",
      "title": "Ask HN: Which career is most future-secure in the AI era?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46524710",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a84ab669",
      "type": "article",
      "title": "Why machine learning fails at prioritization problems",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46521799",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d7fb0d6f",
      "type": "article",
      "title": "Show HN: Symbolic Circuit Distillation: prove program to LLM circuit equivalence",
      "summary": "",
      "url": "https://github.com/neelsomani/symbolic-circuit-distillation",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 51
    },
    {
      "id": "article-9165c26c",
      "type": "article",
      "title": "\"I love you\" \"too\": LLM Attention Explained",
      "summary": "",
      "url": "https://kaamvaam.com/machine-learning-ai/llm-attention-explanation/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8bfd8eaf",
      "type": "article",
      "title": "Show HN: ScrollMind \u2013 A visual engineering guide to AI that fits in your feed",
      "summary": "",
      "url": "https://scrollmind.ai",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5b17ee09",
      "type": "article",
      "title": "Practically Utilizing Neural Networks in CPU-Based Production Rendering (JCGT)",
      "summary": "",
      "url": "https://jcgt.org/published/0015/01/01/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f38bf4fb",
      "type": "article",
      "title": "Training a Hamiltonian Neural Network",
      "summary": "",
      "url": "https://ritog.github.io/posts/hamiltonian_nn/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-949fbb3d",
      "type": "article",
      "title": "Visualizing neural network inference in 3D with WebGL and ONNX",
      "summary": "",
      "url": "https://www.erikjs.com/blog/building-neural-network-visualizer",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-e345449d",
      "type": "article",
      "title": "Neural Networks: Zero to Hero",
      "summary": "",
      "url": "https://karpathy.ai/zero-to-hero.html",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 100
    },
    {
      "id": "article-fadf0f36",
      "type": "article",
      "title": "Show HN: Stability First AI \u2013 Recovering memory without training data",
      "summary": "",
      "url": "https://github.com/vitali-sialedchyk/stability-first-ai",
      "source": "hackernews",
      "date": "2026-01-03",
      "trendingScore": 50
    },
    {
      "id": "article-b9019ba6",
      "type": "article",
      "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018)",
      "summary": "",
      "url": "https://arxiv.org/abs/1803.03635",
      "source": "hackernews",
      "date": "2026-01-02",
      "trendingScore": 62
    },
    {
      "id": "article-c116d140",
      "type": "article",
      "title": "Hand Off Linear Issues to Claude Code (OS)",
      "summary": "",
      "url": "https://claudear.com/",
      "source": "hackernews",
      "date": "2026-01-08",
      "trendingScore": 50
    },
    {
      "id": "article-46127c2e",
      "type": "article",
      "title": "Claude-Code v2.1.0",
      "summary": "",
      "url": "https://github.com/anthropics/claude-code/commit/870624fc1581a70590e382f263e2972b3f1e56f5",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-cb72482a",
      "type": "article",
      "title": "Show HN: AI Swarm v3 \u2013 Self-host your own headless AI agents",
      "summary": "",
      "url": "https://ai-swarm.dev",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-4a1d3eea",
      "type": "article",
      "title": "Show HN: AgentOS \u2013 Self-hosted web UI for managing multiple Claude Code sessions",
      "summary": "",
      "url": "https://github.com/saadnvd1/agent-os",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d09160c4",
      "type": "article",
      "title": "Search your past ChatGPT, Claude and perplexity chats with context",
      "summary": "",
      "url": "https://github.com/siv-io/Index-AI-Chat-Search",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-ba481b1b",
      "type": "article",
      "title": "Claude Code CLI was broken",
      "summary": "",
      "url": "https://github.com/anthropics/claude-code/issues/16673",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 60
    },
    {
      "id": "article-62f64514",
      "type": "article",
      "title": "Claude Code Emergent Behavior: When Skills Combine",
      "summary": "",
      "url": "https://vibeandscribe.xyz/posts/2025-01-07-emergent-behavior.html",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 58
    },
    {
      "id": "article-22635490",
      "type": "article",
      "title": "Show HN: Basic AI agent that auto-generates B2B sales follow-ups",
      "summary": "",
      "url": "https://github.com/sneurgaonkar/sales-followup-agent",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-4634b9d2",
      "type": "article",
      "title": "Claude Opus 4.5 disappears suddenly from GitHub Copilot",
      "summary": "",
      "url": "https://github.com/orgs/community/discussions/181266",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-06384f36",
      "type": "article",
      "title": "Getting started with Claude for software development",
      "summary": "",
      "url": "https://steveklabnik.com/writing/getting-started-with-claude-for-software-development/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e2922853",
      "type": "article",
      "title": "I can't stop yelling at Claude Code",
      "summary": "",
      "url": "https://www.theargumentmag.com/p/i-cant-stop-yelling-at-claude-code",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-cb459ae1",
      "type": "article",
      "title": "Show HN: Bind.ly \u2013 Persistent memory for AI across tools",
      "summary": "",
      "url": "https://bind.ly",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-577cc433",
      "type": "article",
      "title": "Anthropic details how it measures Claude's wokeness",
      "summary": "",
      "url": "https://www.theverge.com/news/819216/anthropic-claude-political-even-handedness-woke-ai",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d8b3dd24",
      "type": "article",
      "title": "Show HN: I built a simple \"Gemini\" watermark remover extension, \"Peel Banana\"",
      "summary": "",
      "url": "https://chromewebstore.google.com/detail/peel-banana/cngdhnfjakplnhplnmlgjalmfcochdgj",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3d92b1f2",
      "type": "article",
      "title": "Gemini now recommending products unprompted",
      "summary": "",
      "url": "https://old.reddit.com/r/Bard/comments/1q6p5o8/gemini_now_recommending_products_unprompted/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 52
    },
    {
      "id": "article-e73aa188",
      "type": "article",
      "title": "ChatGPT is losing market share as Google Gemini gains ground",
      "summary": "",
      "url": "https://www.bleepingcomputer.com/news/artificial-intelligence/chatgpt-is-losing-market-share-as-google-gemini-gains-ground/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e3a16c59",
      "type": "article",
      "title": "Reducing RLHF hallucinations and sycophancy in Gemini 3 (Interactive Demo)",
      "summary": "",
      "url": "https://tomaszmachnik.pl/gemini-fix-en.html",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-7f65dd76",
      "type": "article",
      "title": "How Google got its groove back and edged ahead of OpenAI",
      "summary": "",
      "url": "https://www.wsj.com/tech/ai/google-ai-openai-gemini-chatgpt-b766e160",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 60
    },
    {
      "id": "article-552cbea2",
      "type": "article",
      "title": "Show HN: YoloForge \u2013 Create object detection datasets using Gemini 3 Pro",
      "summary": "",
      "url": "https://yoloforge.com",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-7b52bae2",
      "type": "article",
      "title": "New Gemini API",
      "summary": "",
      "url": "https://blog.google/technology/developers/interactions-api/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-86e7dc05",
      "type": "article",
      "title": "Markcut \u2013 Free Gemini Watermark Remover",
      "summary": "",
      "url": "https://markcut.com/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-dfe6ba79",
      "type": "article",
      "title": "I created an online Guru Gemini Gem based on Osho's teachings",
      "summary": "",
      "url": "https://gemini.google.com/gem/1gX9L9ICaf2VhOROlI1k7KKzMhRrT2INU?usp=sharing",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f382ae95",
      "type": "article",
      "title": "Google Gemini Is Taking Control of Humanoid Robots on Auto Factory Floors",
      "summary": "",
      "url": "https://www.wired.com/story/google-boston-dynamics-gemini-powered-robot-atlas/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a92417fc",
      "type": "article",
      "title": "Gemini's 3 line execution mode",
      "summary": "",
      "url": "https://olshansky.info/thoughts/2026-01-06-gemini-s-3-line-execution-mode",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-ad4af2ed",
      "type": "article",
      "title": "Show HN: Agents Council \u2013 Connect Claude, Codex, and Local Agents via MCP",
      "summary": "",
      "url": "https://github.com/MrLesk/agents-council",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e12a5dc0",
      "type": "article",
      "title": "Ask HN: Advise what to pick up to transition into AI/ML space",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46516268",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-744f3221",
      "type": "article",
      "title": "Gemini Protocol Deployment Statistics",
      "summary": "",
      "url": "https://www.obsessivefacts.com/gemini-proxy?uri=gemini%3A%2F%2Fgemini.bortzmeyer.org%2Fsoftware%2Flupa%2Fstats.gmi",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 57
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 20
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 22
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 53
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 18
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 9
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 33
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 5
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 9
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 6
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 7
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 2
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 8
    },
    {
      "id": "org-meta",
      "type": "organization",
      "title": "Meta",
      "summary": "Meta - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-cohere",
      "type": "organization",
      "title": "Cohere",
      "summary": "Cohere - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-openai",
      "type": "organization",
      "title": "OpenAI",
      "summary": "OpenAI - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-nvidia",
      "type": "organization",
      "title": "NVIDIA",
      "summary": "NVIDIA - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-ibm",
      "type": "organization",
      "title": "IBM",
      "summary": "IBM - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 4
    },
    {
      "id": "org-anthropic",
      "type": "organization",
      "title": "Anthropic",
      "summary": "Anthropic - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4",
      "type": "model",
      "title": "GPT-4",
      "summary": "GPT-4 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4o",
      "type": "model",
      "title": "GPT-4o",
      "summary": "GPT-4o AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-5",
      "type": "model",
      "title": "GPT-5",
      "summary": "GPT-5 AI model.",
      "connectionCount": 3
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 13
    },
    {
      "id": "model-chatgpt",
      "type": "model",
      "title": "ChatGPT",
      "summary": "ChatGPT AI model.",
      "connectionCount": 2
    },
    {
      "id": "model-copilot",
      "type": "model",
      "title": "Copilot",
      "summary": "Copilot AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 11
    },
    {
      "id": "model-gemini-pro",
      "type": "model",
      "title": "Gemini Pro",
      "summary": "Gemini Pro AI model.",
      "connectionCount": 1
    }
  ],
  "edges": [
    {
      "source": "article-9f769fef",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9f769fef",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-24448a5d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-24448a5d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-24448a5d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f9dba51",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f9dba51",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f9dba51",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f9dba51",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a4f1b00",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a4f1b00",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a4f1b00",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a4f1b00",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a53e9b2",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a53e9b2",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c6adb79",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d11b5ee2",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d11b5ee2",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-062cefdc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-062cefdc",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-062cefdc",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-062cefdc",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-47fbbfe8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-47fbbfe8",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-47fbbfe8",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-76c77af3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-76c77af3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-76c77af3",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-76c77af3",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-76c77af3",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-afd38697",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-afd38697",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-afd38697",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-690b408b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-690b408b",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-690b408b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-690b408b",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7c2eb00c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7c2eb00c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-de14dc10",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-de14dc10",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-de14dc10",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-de14dc10",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-813adfc0",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-813adfc0",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ff404de7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ff404de7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b76eba3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b76eba3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b76eba3",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b76eba3",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-9b76eba3",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-34862d3b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-34862d3b",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-34862d3b",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3ceec403",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3ceec403",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-85baee3d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-85baee3d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-85baee3d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-89359806",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-89359806",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-89359806",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8c2903d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8c2903d",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8c2903d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8c2903d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8c2903d",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-97d52eea",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-97d52eea",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-21c4d57f",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-278f9563",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-b0cc2fbc",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b0cc2fbc",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-3e988fb4",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-3e988fb4",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-3e988fb4",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-2aebefc5",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2aebefc5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7b000609",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7b000609",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e02e2f33",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-e02e2f33",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-e02e2f33",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e02e2f33",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-639ae756",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-639ae756",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-e5a7d8e6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df313ec",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7e5f71e2",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-7e5f71e2",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-7e5f71e2",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7e5f71e2",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-fb8abef8",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6bcc4c1e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-6bcc4c1e",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-6bcc4c1e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-594afdb3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-594afdb3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-594afdb3",
      "target": "model-gpt-4",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-594afdb3",
      "target": "model-gpt-4o",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-594afdb3",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3bf212d8",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-dd212150",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6cacfbe3",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6cacfbe3",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-6cacfbe3",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6cacfbe3",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-31896352",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-31896352",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-31896352",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-151d060d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-151d060d",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-151d060d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-151d060d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3057c910",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3057c910",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3d281f86",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4db91b8c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4db91b8c",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-4db91b8c",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-54bcf10c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-54bcf10c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b069a66",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b069a66",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b069a66",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b069a66",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5b069a66",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9422a42",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9422a42",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-bbd1027a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-bbd1027a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-bbd1027a",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f2f90e16",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f2f90e16",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f2f90e16",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-f2f90e16",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f2f90e16",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f2f90e16",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-8237f778",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8237f778",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-8237f778",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8237f778",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3df78084",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3df78084",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-3df78084",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-78fc06de",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-78fc06de",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-78fc06de",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-78fc06de",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5dc2aa48",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-423ae0f6",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-423ae0f6",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-66f18b5e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-66f18b5e",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0ba59559",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0ba59559",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-982dd1d0",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-982dd1d0",
      "target": "org-ibm",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c9fd12b9",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c9fd12b9",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-9bb77c78",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-35416e60",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-385429fd",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3e1c21d4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a06710f1",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a06710f1",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-a06710f1",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-64a02225",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ec29f4a0",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-de1501a7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-feab5aa8",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-feab5aa8",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0489e5b7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0489e5b7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8ad55c84",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4709ccde",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4709ccde",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-114c3717",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-566b4e7d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b48bab8b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b48bab8b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-28f29313",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d44a24ec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3eb7961e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d7fb0d6f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7fb0d6f",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-9165c26c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8bfd8eaf",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c116d140",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-46127c2e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-cb72482a",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4a1d3eea",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4a1d3eea",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d09160c4",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d09160c4",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d09160c4",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ba481b1b",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-62f64514",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-22635490",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-22635490",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-4634b9d2",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4634b9d2",
      "target": "model-copilot",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-06384f36",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e2922853",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-577cc433",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-577cc433",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d8b3dd24",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3d92b1f2",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-3d92b1f2",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e73aa188",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e73aa188",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e73aa188",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e3a16c59",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-e3a16c59",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e3a16c59",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7f65dd76",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7f65dd76",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-552cbea2",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-552cbea2",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7b52bae2",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-86e7dc05",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-dfe6ba79",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f382ae95",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f382ae95",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a92417fc",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ad4af2ed",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ad4af2ed",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-744f3221",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-744f3221",
      "target": "model-gemini-pro",
      "relationship": "MENTIONS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}