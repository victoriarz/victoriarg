{
  "metadata": {
    "lastUpdated": "2026-02-04T06:51:00.668744Z",
    "totalArticles": 143,
    "totalNodes": 170,
    "totalEdges": 264,
    "dateRange": {
      "start": "2026-01-28",
      "end": "2026-02-04"
    }
  },
  "nodes": [
    {
      "id": "article-2dfb98bc",
      "type": "article",
      "title": "Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes",
      "summary": "arXiv:2602.00053v1 Announce Type: new Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy s",
      "url": "https://arxiv.org/abs/2602.00053",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-12537dbb",
      "type": "article",
      "title": "Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets",
      "summary": "arXiv:2602.00188v1 Announce Type: new Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attributes influence price. We address this by introducing an interpretable \\emph{Additive Feature Decomposition-based Low-Dimensional Demand (\\textbf{AFDLD}) model}, where product prices are expressed as the",
      "url": "https://arxiv.org/abs/2602.00188",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4695212e",
      "type": "article",
      "title": "From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models",
      "summary": "arXiv:2602.00190v1 Announce Type: new Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, by tasking Large Language Models (LLMs) with reverse-engineering Video Game Description Language (VGDL) rules from gameplay traces. To reduce redundancy, we select nine representative games from the Ge",
      "url": "https://arxiv.org/abs/2602.00190",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-38d03c61",
      "type": "article",
      "title": "Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic",
      "summary": "arXiv:2602.00266v1 Announce Type: new Abstract: Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through a",
      "url": "https://arxiv.org/abs/2602.00266",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-2033e4cc",
      "type": "article",
      "title": "Localizing and Correcting Errors for LLM-based Planners",
      "summary": "arXiv:2602.00276v1 Announce Type: new Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targ",
      "url": "https://arxiv.org/abs/2602.00276",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-0a600732",
      "type": "article",
      "title": "Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning",
      "summary": "arXiv:2602.00298v1 Announce Type: new Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \\texttt{Qwen2.5-Coder-7B-Instruct} and \\texttt{GPT-4o-mini} reveal two key findings: (",
      "url": "https://arxiv.org/abs/2602.00298",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-d6c2b940",
      "type": "article",
      "title": "Autonomous Data Processing using Meta-Agents",
      "summary": "arXiv:2602.00307v1 Announce Type: new Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \\textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that ",
      "url": "https://arxiv.org/abs/2602.00307",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-f9335372",
      "type": "article",
      "title": "SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?",
      "summary": "arXiv:2602.00327v1 Announce Type: new Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the cont",
      "url": "https://arxiv.org/abs/2602.00327",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-6df81395",
      "type": "article",
      "title": "MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants",
      "summary": "arXiv:2602.00353v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform ",
      "url": "https://arxiv.org/abs/2602.00353",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-18c02613",
      "type": "article",
      "title": "Position: Agentic Evolution is the Path to Evolving LLMs",
      "summary": "arXiv:2602.00359v1 Announce Type: new Abstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation ",
      "url": "https://arxiv.org/abs/2602.00359",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-b24e00ea",
      "type": "article",
      "title": "POET: Protocol Optimization via Eligibility Tuning",
      "summary": "arXiv:2602.00370v1 Announce Type: new Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their pra",
      "url": "https://arxiv.org/abs/2602.00370",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-e9c01684",
      "type": "article",
      "title": "KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning",
      "summary": "arXiv:2602.00400v1 Announce Type: new Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teache",
      "url": "https://arxiv.org/abs/2602.00400",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-3eb7335d",
      "type": "article",
      "title": "RobustDebias: Debiasing Language Models using Distributionally Robust Optimization",
      "summary": "arXiv:2602.00405v1 Announce Type: new Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraini",
      "url": "https://arxiv.org/abs/2602.00405",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-85e36f2a",
      "type": "article",
      "title": "PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents",
      "summary": "arXiv:2602.00415v1 Announce Type: new Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the epistemic asymmetry inherent in probabilistic vision-language models and dense associative memories: they conflate semantic affinity with factual existence and structurally fail to encode negative constraints.",
      "url": "https://arxiv.org/abs/2602.00415",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-add53d46",
      "type": "article",
      "title": "Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks",
      "summary": "arXiv:2602.00449v1 Announce Type: new Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On ",
      "url": "https://arxiv.org/abs/2602.00449",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-931b50d9",
      "type": "article",
      "title": "Cross-Modal Memory Compression for Efficient Multi-Agent Debate",
      "summary": "arXiv:2602.00454v1 Announce Type: new Abstract: Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact ima",
      "url": "https://arxiv.org/abs/2602.00454",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-988de287",
      "type": "article",
      "title": "Benchmarking Agents in Insurance Underwriting Environments",
      "summary": "arXiv:2602.00456v1 Announce Type: new Abstract: As AI agents integrate into enterprise applications, their evaluation demands benchmarks that reflect the complexity of real-world operations. Instead, existing benchmarks overemphasize open-domains such as code, use narrow accuracy metrics, and lack authentic complexity. We present UNDERWRITE, an expert-first, multi-turn insurance underwriting benchmark designed in close collaboration with domain experts to capture real-world enterprise challenges",
      "url": "https://arxiv.org/abs/2602.00456",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-7fa4a51d",
      "type": "article",
      "title": "Dual Latent Memory for Visual Multi-agent System",
      "summary": "arXiv:2602.00471v1 Announce Type: new Abstract: While Visual Multi-Agent Systems (VMAS) promise to enhance comprehensive abilities through inter-agent collaboration, empirical evidence reveals a counter-intuitive \"scaling wall\": increasing agent turns often degrades performance while exponentially inflating token costs. We attribute this failure to the information bottleneck inherent in text-centric communication, where converting perceptual and thinking trajectories into discrete natural langua",
      "url": "https://arxiv.org/abs/2602.00471",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-6fdf5199",
      "type": "article",
      "title": "Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models",
      "summary": "arXiv:2602.00485v1 Announce Type: new Abstract: VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the prese",
      "url": "https://arxiv.org/abs/2602.00485",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-451edd14",
      "type": "article",
      "title": "PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)",
      "summary": "arXiv:2602.00510v1 Announce Type: new Abstract: Printed Circuit Board (PCB) schematic design plays an essential role in all areas of electronic industries. Unlike prior works that focus on digital or analog circuits alone, PCB design must handle heterogeneous digital, analog, and power signals while adhering to real-world IC packages and pin constraints. Automated PCB schematic design remains unexplored due to the scarcity of open-source data and the absence of simulation-based verification. We ",
      "url": "https://arxiv.org/abs/2602.00510",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-290225dd",
      "type": "article",
      "title": "UNSO: Unified Newton Schulz Orthogonalization",
      "summary": "arXiv:2602.02500v1 Announce Type: new Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been introduced to NS iteration, they fail to deviate from the conventional iterative paradigm, which could increase computation burden largely due to the matrix products along the long dimension repeatedly. To",
      "url": "https://arxiv.org/abs/2602.02500",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4600e778",
      "type": "article",
      "title": "Augmenting Parameter-Efficient Pre-trained Language Models with Large Language Models",
      "summary": "arXiv:2602.02501v1 Announce Type: new Abstract: Training AI models in cybersecurity with help of vast datasets offers significant opportunities to mimic real-world behaviors effectively. However, challenges like data drift and scarcity of labelled data lead to frequent updates of models and the risk of overfitting. To address these challenges, we used parameter-efficient fine-tuning techniques for pre-trained language models wherein we combine compacters with various layer freezing strategies. T",
      "url": "https://arxiv.org/abs/2602.02501",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-faca6ff1",
      "type": "article",
      "title": "Sparse Adapter Fusion for Continual Learning in NLP",
      "summary": "arXiv:2602.02502v1 Announce Type: new Abstract: Continual learning in natural language processing plays a crucial role in adapting to evolving data and preventing catastrophic forgetting. Despite significant progress, existing methods still face challenges, such as inefficient parameter reuse across tasks, risking catastrophic forgetting when tasks are dissimilar, and the unnecessary introduction of new parameters for each task, which hampers knowledge sharing among similar tasks. To tackle thes",
      "url": "https://arxiv.org/abs/2602.02502",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-c4e3f384",
      "type": "article",
      "title": "Learning ORDER-Aware Multimodal Representations for Composite Materials Design",
      "summary": "arXiv:2602.02513v1 Announce Type: new Abstract: Artificial intelligence (AI) has shown remarkable success in materials discovery and property prediction, particularly for crystalline and polymer systems where material properties and structures are dominated by discrete graph representations. Such graph-central paradigm breaks down on composite materials, which possess continuous and nonlinear design spaces that lack well-defined graph structures. General composite descriptors, e.g., fiber volume",
      "url": "https://arxiv.org/abs/2602.02513",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-3e4e3333",
      "type": "article",
      "title": "What Drives Length of Stay After Elective Spine Surgery? Insights from a Decade of Predictive Modeling",
      "summary": "arXiv:2602.02517v1 Announce Type: new Abstract: Objective: Predicting length of stay after elective spine surgery is essential for optimizing patient outcomes and hospital resource use. This systematic review synthesizes computational methods used to predict length of stay in this patient population, highlighting model performance and key predictors. Methods: Following PRISMA guidelines, we systematically searched PubMed, Google Scholar, and ACM Digital Library for studies published between Dece",
      "url": "https://arxiv.org/abs/2602.02517",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-8e3afdb0",
      "type": "article",
      "title": "GraphDancer: Training LLMs to Explore and Reason over Graphs via Curriculum Reinforcement Learning",
      "summary": "arXiv:2602.02518v1 Announce Type: new Abstract: Large language models (LLMs) increasingly rely on external knowledge to improve factuality, yet many real-world knowledge sources are organized as heterogeneous graphs rather than plain text. Reasoning over such graph-structured knowledge poses two key challenges: (1) navigating structured, schema-defined relations requires precise function calls rather than similarity-based retrieval, and (2) answering complex questions often demands multi-hop evi",
      "url": "https://arxiv.org/abs/2602.02518",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-d0551860",
      "type": "article",
      "title": "Scaled Dot-Product Attention implements projection of inputs onto a common surface",
      "summary": "arXiv:2602.02521v1 Announce Type: new Abstract: Scaled dot-product attention (SDPA) is a fundamental component responsible for the success of large-language models and other nonlinear signal processing applications. The rationale for SDPA has been based upon \"query, key, value\" concepts borrowed from database theory, but these concepts are difficult to reconcile with standard methods in mathematical signal processing. We show that SDPA can be rewritten in a different but mathematically equivalen",
      "url": "https://arxiv.org/abs/2602.02521",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-0ac9dbae",
      "type": "article",
      "title": "IMU-1: Sample-Efficient Pre-training of Small Language Models",
      "summary": "arXiv:2602.02522v1 Announce Type: new Abstract: We present IMU-1, a 430M-parameter language model trained on 72B tokens that approaches the benchmark performance of models trained on 56x more data. We describe a validated training recipe combining recent architectural interventions (QK-norm attention, per-head gating, value residuals, LayerNorm scaling) with optimization advances (NorMuon with cautious weight decay, muP parametrization) and a three-stage training schedule with post-hoc checkpoin",
      "url": "https://arxiv.org/abs/2602.02522",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-03241ea9",
      "type": "article",
      "title": "TabularMath: Evaluating Computational Extrapolation in Tabular Learning via Program-Verified Synthesis",
      "summary": "arXiv:2602.02523v1 Announce Type: new Abstract: Standard tabular benchmarks mainly focus on the evaluation of a model's capability to interpolate values inside a data manifold, where models good at performing local statistical smoothing are rewarded. However, there exists a very large category of high-value tabular data, including financial modeling and physical simulations, which are generated based upon deterministic computational processes, as opposed to stochastic and noisy relationships. Th",
      "url": "https://arxiv.org/abs/2602.02523",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-0b49df2c",
      "type": "article",
      "title": "The \"Robert Boulton\" Singularity: Semantic Tunneling and Manifold Unfolding in Recursive AI",
      "summary": "arXiv:2602.02526v1 Announce Type: new Abstract: The stability of generative artificial intelligence trained on recursive synthetic data is conventionally monitored via Perplexity (PPL). We demonstrate that PPL is a deceptive metric in context-stabilized regimes (L=128). Using a rigorous sliding-window protocol (N=1500), we identify a novel failure mode termed \"Semantic Tunneling.\" While the Baseline model maintains high grammatical fluency (PPL approx. 83.9), it suffers a catastrophic loss of se",
      "url": "https://arxiv.org/abs/2602.02526",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-e338f5a2",
      "type": "article",
      "title": "Incident-Guided Spatiotemporal Traffic Forecasting",
      "summary": "arXiv:2602.02528v1 Announce Type: new Abstract: Recent years have witnessed the rapid development of deep-learning-based, graph-neural-network-based forecasting methods for modern intelligent transportation systems. However, most existing work focuses exclusively on capturing spatio-temporal dependencies from historical traffic data, while overlooking the fact that suddenly occurring transportation incidents, such as traffic accidents and adverse weather, serve as external disturbances that can ",
      "url": "https://arxiv.org/abs/2602.02528",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-cafef46f",
      "type": "article",
      "title": "Formulating Reinforcement Learning for Human-Robot Collaboration through Off-Policy Evaluation",
      "summary": "arXiv:2602.02530v1 Announce Type: new Abstract: Reinforcement learning (RL) has the potential to transform real-world decision-making systems by enabling autonomous agents to learn from experience. Deploying RL in real-world settings, especially in the context of human-robot interaction, requires defining state representations and reward functions, which are critical for learning efficiency and policy performance. Traditional RL approaches often rely on domain expertise and trial-and-error, nece",
      "url": "https://arxiv.org/abs/2602.02530",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-e3bbe4e8",
      "type": "article",
      "title": "Hypersonic Flow Control: Generalized Deep Reinforcement Learning for Hypersonic Intake Unstart Control under Uncertainty",
      "summary": "arXiv:2602.02531v1 Announce Type: new Abstract: The hypersonic unstart phenomenon poses a major challenge to reliable air-breathing propulsion at Mach 5 and above, where strong shock-boundary-layer interactions and rapid pressure fluctuations can destabilize inlet operation. Here, we demonstrate a deep reinforcement learning (DRL)- based active flow control strategy to control unstart in a canonical two-dimensional hypersonic inlet at Mach 5 and Reynolds number $5\\times 10^6$. The in-house CFD s",
      "url": "https://arxiv.org/abs/2602.02531",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-eb2ac43a",
      "type": "article",
      "title": "CADENT: Gated Hybrid Distillation for Sample-Efficient Transfer in Reinforcement Learning",
      "summary": "arXiv:2602.02532v1 Announce Type: new Abstract: Transfer learning promises to reduce the high sample complexity of deep reinforcement learning (RL), yet existing methods struggle with domain shift between source and target environments. Policy distillation provides powerful tactical guidance but fails to transfer long-term strategic knowledge, while automaton-based methods capture task structure but lack fine-grained action guidance. This paper introduces Context-Aware Distillation with Experien",
      "url": "https://arxiv.org/abs/2602.02532",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-d985b0e3",
      "type": "article",
      "title": "Enhancing Psychologists' Understanding through Explainable Deep Learning Framework for ADHD Diagnosis",
      "summary": "arXiv:2602.02535v1 Announce Type: new Abstract: Attention Deficit Hyperactivity Disorder (ADHD) is a neurodevelopmental disorder that is challenging to diagnose and requires advanced approaches for reliable and transparent identification and classification. It is characterized by a pattern of inattention, hyperactivity and impulsivity that is more severe and more frequent than in individuals with a comparable level of development. In this paper, an explainable framework based on a fine-tuned hyb",
      "url": "https://arxiv.org/abs/2602.02535",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-8d9c9eb7",
      "type": "article",
      "title": "From Sparse Decisions to Dense Reasoning: A Multi-attribute Trajectory Paradigm for Multimodal Moderation",
      "summary": "arXiv:2602.02536v1 Announce Type: new Abstract: Safety moderation is pivotal for identifying harmful content. Despite the success of textual safety moderation, its multimodal counterparts remain hindered by a dual sparsity of data and supervision. Conventional reliance on binary labels lead to shortcut learning, which obscures the intrinsic classification boundaries necessary for effective multimodal discrimination. Hence, we propose a novel learning paradigm (UniMod) that transitions from spars",
      "url": "https://arxiv.org/abs/2602.02536",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-368e29c9",
      "type": "article",
      "title": "Enhancing Post-Training Quantization via Future Activation Awareness",
      "summary": "arXiv:2602.02538v1 Announce Type: new Abstract: Post-training quantization (PTQ) is a widely used method to compress large language models (LLMs) without fine-tuning. It typically sets quantization hyperparameters (e.g., scaling factors) based on current-layer activations. Although this method is efficient, it suffers from quantization bias and error accumulation, resulting in suboptimal and unstable quantization, especially when the calibration data is biased. To overcome these issues, we propo",
      "url": "https://arxiv.org/abs/2602.02538",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-ccbc7e9e",
      "type": "article",
      "title": "How Much Information Can a Vision Token Hold? A Scaling Law for Recognition Limits in VLMs",
      "summary": "arXiv:2602.02539v1 Announce Type: new Abstract: Recent vision-centric approaches have made significant strides in long-context modeling. Represented by DeepSeek-OCR, these models encode rendered text into continuous vision tokens, achieving high compression rates without sacrificing recognition precision. However, viewing the vision encoder as a lossy channel with finite representational capacity raises a fundamental question: what is the information upper bound of visual tokens? To investigate ",
      "url": "https://arxiv.org/abs/2602.02539",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-67996615",
      "type": "article",
      "title": "Auto-Augmentation Contrastive Learning for Wearable-based Human Activity Recognition",
      "summary": "arXiv:2602.02542v1 Announce Type: new Abstract: For low-semantic sensor signals from human activity recognition (HAR), contrastive learning (CL) is essential to implement novel applications or generic models without manual annotation, which is a high-performance self-supervised learning (SSL) method. However, CL relies heavily on data augmentation for pairwise comparisons. Especially for low semantic data in the HAR area, conducting good performance augmentation strategies in pretext tasks still",
      "url": "https://arxiv.org/abs/2602.02542",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-117478ae",
      "type": "article",
      "title": "Toward Ultra-Long-Horizon Sequential Model Editing",
      "summary": "arXiv:2602.02543v1 Announce Type: new Abstract: Model editing has emerged as a practical approach for mitigating factual errors and outdated knowledge in large language models (LLMs). Among existing methods, the Locate-and-Edit (L&amp;E) paradigm is the dominant framework: it locates MLP parameters implicated in expressing a target fact, and then performs a localized update to rewrite that fact. However, long sequences of edits often trigger abrupt model collapse in L&amp;E beyond a critical poi",
      "url": "https://arxiv.org/abs/2602.02543",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-31db3c5b",
      "type": "article",
      "title": "The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders",
      "summary": "arXiv:2602.02496v1 Announce Type: new Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better detect this behavior, we introduce the Hypocrisy Gap, a mechanistic metric utilizing Sparse Autoencoders (SAEs) to quantify the divergence between a model's internal reasoning and its final generation. By",
      "url": "https://arxiv.org/abs/2602.02496",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-7f701d8d",
      "type": "article",
      "title": "STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models",
      "summary": "arXiv:2602.02497v1 Announce Type: new Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. However, current evaluation paradigms often treat benchmarks as isolated \"silos,\" offering only monolithic aggregate scores that neglect the intricacies of both academic specialization and cognitive depth.",
      "url": "https://arxiv.org/abs/2602.02497",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-ba9a4081",
      "type": "article",
      "title": "Test-Time Detoxification without Training or Learning Anything",
      "summary": "arXiv:2602.02498v1 Announce Type: new Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without sacrificing the model's generation quality. Many existing approaches rely on model retraining, gradients, or learned auxiliary components, which can be costly and may not transfer across model families ",
      "url": "https://arxiv.org/abs/2602.02498",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-d7e7c16d",
      "type": "article",
      "title": "ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching",
      "summary": "arXiv:2602.02499v1 Announce Type: new Abstract: Long-context capability and computational efficiency are among the central challenges facing today's large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the model state. This paper proposes ROSA-Tuning, a retrieval-and-recall mechanism for enhancing the long-context modeling ability of pretrained models. Beyond the standard attention mechanism, ROSA-Tuning",
      "url": "https://arxiv.org/abs/2602.02499",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-2b7efa44",
      "type": "article",
      "title": "Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management",
      "summary": "arXiv:2602.02635v1 Announce Type: new Abstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve query-relevant subgraphs to provide relational evidence during answer generation. The framework adopts ChatGLM as the Transformer backbone with LoRA-based parameter-efficient fine-tuning, and employs ",
      "url": "https://arxiv.org/abs/2602.02635",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-6ab244cd",
      "type": "article",
      "title": "WideSeek: Advancing Wide Research via Multi-Agent Scaling",
      "summary": "arXiv:2602.02636v1 Announce Type: new Abstract: Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First,",
      "url": "https://arxiv.org/abs/2602.02636",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-41913628",
      "type": "article",
      "title": "Monotonicity as an Architectural Bias for Robust Language Models",
      "summary": "arXiv:2602.02686v1 Announce Type: new Abstract: Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output. We investigate monotonicity as an architect",
      "url": "https://arxiv.org/abs/2602.02686",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-bc9ef67f",
      "type": "article",
      "title": "InfMem: Learning System-2 Memory Control for Long-Context Agent",
      "summary": "arXiv:2602.02704v1 Announce Type: new Abstract: Reasoning over ultra-long documents requires synthesizing sparse evidence scattered across distant segments under strict memory constraints. While streaming agents enable scalable processing, their passive memory update strategy often fails to preserve low-salience bridging evidence required for multi-hop reasoning. We propose InfMem, a control-centric agent that instantiates System-2-style control via a PreThink-Retrieve-Write protocol. InfMem act",
      "url": "https://arxiv.org/abs/2602.02704",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-b3174352",
      "type": "article",
      "title": "Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors",
      "summary": "arXiv:2602.02731v1 Announce Type: new Abstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR represe",
      "url": "https://arxiv.org/abs/2602.02731",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-34435be3",
      "type": "article",
      "title": "Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies",
      "summary": "arXiv:2602.02736v1 Announce Type: new Abstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambulances are often hindered by traffic congestion; while air vehicles such as helicopters are faster but costly. Emerging air vehicles -- Unmanned Aerial Vehicles and electric vertical take-off and landi",
      "url": "https://arxiv.org/abs/2602.02736",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-9537f9d8",
      "type": "article",
      "title": "From Task Solving to Robust Real-World Adaptation in LLM Agents",
      "summary": "arXiv:2602.02760v1 Announce Type: new Abstract: Large language models are increasingly deployed as specialized agents that plan, call tools, and take actions over extended horizons. Yet many existing evaluations assume a \"clean interface\" where dynamics are specified and stable, tools and sensors are reliable, and success is captured by a single explicit objective-often overestimating real-world readiness. In practice, agents face underspecified rules, unreliable signals, shifting environments, ",
      "url": "https://arxiv.org/abs/2602.02760",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-a7ff66a4",
      "type": "article",
      "title": "AmharicStoryQA: A Multicultural Story Question Answering Benchmark in Amharic",
      "summary": "arXiv:2602.02774v1 Announce Type: new Abstract: With the growing emphasis on multilingual and cultural evaluation benchmarks for large language models, language and culture are often treated as synonymous, and performance is commonly used as a proxy for a models understanding of a given language. In this work, we argue that such evaluations overlook meaningful cultural variation that exists within a single language. We address this gap by focusing on narratives from different regions of Ethiopia",
      "url": "https://arxiv.org/abs/2602.02774",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-42f787f6",
      "type": "article",
      "title": "When Efficient Communication Explains Convexity",
      "summary": "arXiv:2602.02821v1 Announce Type: new Abstract: Much recent work has argued that the variation in the languages of the world can be explained from the perspective of efficient communication; in particular, languages can be seen as optimally balancing competing pressures to be simple and to be informative. Focusing on the expression of meaning -- semantic typology -- the present paper asks what factors are responsible for successful explanations in terms of efficient communication. Using the Info",
      "url": "https://arxiv.org/abs/2602.02821",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-c552f2b7",
      "type": "article",
      "title": "R2-Router: A New Paradigm for LLM Routing with Reasoning",
      "summary": "arXiv:2602.02823v1 Announce Type: new Abstract: As LLMs proliferate with diverse capabilities and costs, LLM routing has emerged by learning to predict each LLM's quality and cost for a given query, then selecting the one with high quality and low cost. However, existing routers implicitly assume a single fixed quality and cost per LLM for each query, ignoring that the same LLM's quality varies with its output length. This causes routers to exclude powerful LLMs when their estimated cost exceeds",
      "url": "https://arxiv.org/abs/2602.02823",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-dd053d21",
      "type": "article",
      "title": "CATNIP: LLM Unlearning via Calibrated and Tokenized Negative Preference Alignment",
      "summary": "arXiv:2602.02824v1 Announce Type: new Abstract: Pretrained knowledge memorized in LLMs raises critical concerns over safety and privacy, which has motivated LLM Unlearning as a technique for selectively removing the influences of undesirable knowledge. Existing approaches, rooted in Gradient Ascent (GA), often degrade general domain knowledge while relying on retention data or curated contrastive pairs, which can be either impractical or data and computationally prohibitive. Negative Preference ",
      "url": "https://arxiv.org/abs/2602.02824",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-14f59ba5",
      "type": "article",
      "title": "Act or Clarify? Modeling Sensitivity to Uncertainty and Cost in Communication",
      "summary": "arXiv:2602.02843v1 Announce Type: new Abstract: When deciding how to act under uncertainty, agents may choose to act to reduce uncertainty or they may act despite that uncertainty.In communicative settings, an important way of reducing uncertainty is by asking clarification questions (CQs). We predict that the decision to ask a CQ depends on both contextual uncertainty and the cost of alternative actions, and that these factors interact: uncertainty should matter most when acting incorrectly is ",
      "url": "https://arxiv.org/abs/2602.02843",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-20c56cca",
      "type": "article",
      "title": "Which course? Discourse! Teaching Discourse and Generation in the Era of LLMs",
      "summary": "arXiv:2602.02878v1 Announce Type: new Abstract: The field of NLP has undergone vast, continuous transformations over the past few years, sparking debates going beyond discipline boundaries. This begs important questions in education: how do we design courses that bridge sub-disciplines in this shifting landscape? This paper explores this question from the angle of discourse processing, an area with rich linguistic insights and computational models for the intentional, attentional, and coherence ",
      "url": "https://arxiv.org/abs/2602.02878",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4754a9c7",
      "type": "article",
      "title": "HALT: Hallucination Assessment via Log-probs as Time series",
      "summary": "arXiv:2602.02888v1 Announce Type: new Abstract: Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely effi",
      "url": "https://arxiv.org/abs/2602.02888",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-45821826",
      "type": "article",
      "title": "Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness",
      "summary": "arXiv:2602.02932v1 Announce Type: new Abstract: Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt",
      "url": "https://arxiv.org/abs/2602.02932",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-7323895d",
      "type": "article",
      "title": "Where Norms and References Collide: Evaluating LLMs on Normative Reasoning",
      "summary": "arXiv:2602.02975v1 Announce Type: new Abstract: Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it ",
      "url": "https://arxiv.org/abs/2602.02975",
      "source": "arxiv",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-a91db779",
      "type": "article",
      "title": "How we\u2019re helping preserve the genetic information of endangered species with AI",
      "summary": "A four-part vertical collage showing a cotton-top tamarin, an ibex, a golden lion tamarin, and a penguin.",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-12f40143",
      "type": "article",
      "title": "Advancing AI benchmarking with Game Arena",
      "summary": "An illustration of a King and Ace playing card, a wolf's head, two chess pieces, a poker chip, and other abstract shapes on a white background.1",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-01db31c0",
      "type": "article",
      "title": "Project Genie: Experimenting with infinite, interactive worlds",
      "summary": "Text reads Introducing Project Genie",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-3cd6e7bc",
      "type": "article",
      "title": "Hear more about interactive world models in our latest podcast.",
      "summary": "Project Genie: Create and explore worlds",
      "url": "https://blog.google/innovation-and-ai/technology/ai/release-notes-podcast-project-genie/",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-bb1053f9",
      "type": "article",
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "summary": "",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-74bdaef6",
      "type": "article",
      "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
      "summary": "",
      "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-a0998dd5",
      "type": "article",
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "summary": "",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-d13fdbe4",
      "type": "article",
      "title": "Introducing NVIDIA Cosmos Policy for Advanced Robot Control",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/cosmos-policy-for-robot-control",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-46184e81",
      "type": "article",
      "title": "Introducing Daggr: Chain apps programmatically, inspect visually",
      "summary": "",
      "url": "https://huggingface.co/blog/daggr",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-4dab3d5d",
      "type": "article",
      "title": "What we\u2019ve been getting wrong about AI\u2019s truth crisis",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about\u2014where AI content dupes us, shapes our beliefs even when we catch the lie, and&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-771ce396",
      "type": "article",
      "title": "The crucial first step for designing a successful enterprise AI system",
      "summary": "Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes\u2014but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most difficult problems. Whether it\u2019s increasing CX productivity with Cisco, building a more&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-e213f1f0",
      "type": "article",
      "title": "Inside the marketplace powering bespoke AI deepfakes of real women",
      "summary": "Civitai\u2014an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz\u2014is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic images banned by the site, a new analysis has found. The study, from researchers at Stanford and Indiana&#8230;",
      "url": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
      "source": "blogs",
      "date": "2026-01-30",
      "trendingScore": 50
    },
    {
      "id": "article-8ff1ee97",
      "type": "article",
      "title": "The AI Hype Index: Grok makes porn, and Claude Code nails your job",
      "summary": "Everyone is panicking because AI is very bad; everyone is panicking because AI is very good. It\u2019s just that you never know which one you\u2019re going to get. Grok is a pornography machine. Claude Code can do anything from building websites to reading your MRI. So of course Gen Z is spooked by what this&#8230;",
      "url": "https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-432c89d0",
      "type": "article",
      "title": "DHS is using Google and Adobe AI to make videos",
      "summary": "The US Department of Homeland Security is using AI video generators from Google and Adobe to make and edit content shared with the public, a new document reveals. It comes as immigration agencies have flooded social media with content to support President Trump&#8217;s mass deportation agenda\u2014some of which appears to be made with AI\u2014and as&#8230;",
      "url": "https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/",
      "source": "blogs",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-fd84872e",
      "type": "article",
      "title": "What AI \u201cremembers\u201d about you is privacy\u2019s next frontier",
      "summary": "The ability to remember you and your preferences is rapidly becoming a big selling point for AI chatbots and agents.&#160; Earlier this month, Google announced Personal Intelligence, a new way for people to interact with the company\u2019s Gemini chatbot that draws on their Gmail, photos, search, and YouTube histories to make Gemini \u201cmore personal, proactive,&#8230;",
      "url": "https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/",
      "source": "blogs",
      "date": "2026-01-28",
      "trendingScore": 50
    },
    {
      "id": "article-a2225af0",
      "type": "article",
      "title": "Rules fail at the prompt, succeed at the boundary",
      "summary": "From the Gemini Calendar prompt-injection attack of 2026 to the September 2025 state-sponsored hack using Anthropic\u2019s Claude code as an automated intrusion engine, the coercion of human-in-the-loop agentic actions and fully autonomous agentic workflows are the new attack vector for hackers. In the Anthropic case, roughly 30 organizations across tech, finance, manufacturing, and government were&#8230;",
      "url": "https://www.technologyreview.com/2026/01/28/1131003/rules-fail-at-the-prompt-succeed-at-the-boundary/",
      "source": "blogs",
      "date": "2026-01-28",
      "trendingScore": 50
    },
    {
      "id": "article-7a027d28",
      "type": "article",
      "title": "Show HN: I'm 16 and built EU AI Act compliance software",
      "summary": "",
      "url": "https://audit.omensystems.com",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-662ae7ce",
      "type": "article",
      "title": "Show HN: DeepInsight HITL AI research with collaboration and podcast generation",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46882118",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4819626e",
      "type": "article",
      "title": "If you tell AI not to do something, it's more likely to do it",
      "summary": "",
      "url": "https://www.unite.ai/if-you-tell-ai-not-to-do-something-its-more-likely-to-do-it/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-40d75a04",
      "type": "article",
      "title": "Show HN: Chitram \u2013 Open-source image hosting with automatic AI tagging",
      "summary": "",
      "url": "https://chitram.io",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-1f1b7d71",
      "type": "article",
      "title": "Lotus Health nabs $35M for AI doctor that sees patients for free",
      "summary": "",
      "url": "https://techcrunch.com/2026/02/03/lotus-health-nabs-35m-for-ai-doctor-that-sees-patients-for-free/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-f783513b",
      "type": "article",
      "title": "AI Headshot Generator",
      "summary": "",
      "url": "https://aiheadshotgenerator.online/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-027fa4c9",
      "type": "article",
      "title": "AI Data Centers Will Break America (Like 2008)",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=NFP_Dwddcag",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-cb4709af",
      "type": "article",
      "title": "Xcode 26.3 Lets AI Agents from Anthropic and OpenAI Build Apps Autonomously",
      "summary": "",
      "url": "https://www.macrumors.com/2026/02/03/xcode-26-3-agentic-coding/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-9fc832ca",
      "type": "article",
      "title": "The Chinese planemaker taking on Boeing and Airbus",
      "summary": "",
      "url": "https://www.bbc.com/news/articles/ce3exl1k247o",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-392324da",
      "type": "article",
      "title": "Show HN: AI-credit \u2013 measure AI contribution to a codebase",
      "summary": "",
      "url": "https://ai-credits.vercel.app",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-f8628970",
      "type": "article",
      "title": "Show HN: OpenClaw Assistant \u2013 Replace Google Assistant with Any AI",
      "summary": "",
      "url": "https://github.com/yuga-hashimoto/OpenClawAssistant",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-30de072a",
      "type": "article",
      "title": "I got tired of AI that thinks for me \u2013 so I created AkitaLLM",
      "summary": "",
      "url": "https://github.com/KerubinDev/AkitaLLM",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4c118d59",
      "type": "article",
      "title": "Git AI \u2013 Track AI Code all the way to production",
      "summary": "",
      "url": "https://usegitai.com/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-c34b355e",
      "type": "article",
      "title": "We added TOON compression to our LLM gateway \u2013 compress prompts, saves tokens",
      "summary": "",
      "url": "https://github.com/toon-format/toon",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-310c9afc",
      "type": "article",
      "title": "Show HN: Continuity Capsule \u2013 Deterministic restarts for LLM agents",
      "summary": "",
      "url": "https://openclaw.loca.lt/notes/reliability-sprint-packet.html?src=hn",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-da46d98c",
      "type": "article",
      "title": "Show HN: Continuity Capsule \u2013 deterministic restarts for long-running LLM agents",
      "summary": "",
      "url": "https://openclaw.loca.lt/notes/continuity-capsule.html",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-975c5cbb",
      "type": "article",
      "title": "Modeling DeepSeek-R1's Instability as a Topological Limit",
      "summary": "",
      "url": "https://gist.github.com/eric2675-coder/3801106f24c03e43c2183766a377d958",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-0478be1a",
      "type": "article",
      "title": "Writing an LLM from scratch, part 32a \u2013 Interventions: training a baseline model",
      "summary": "",
      "url": "https://www.gilesthomas.com/2026/02/llm-from-scratch-32a-interventions-baseline-model",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-8419310b",
      "type": "article",
      "title": "LLMs fail in ways humans never would",
      "summary": "",
      "url": "https://ahussain.substack.com/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-72bc053c",
      "type": "article",
      "title": "Show HN: Wplace for AI Agents",
      "summary": "",
      "url": "https://molt.place",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-423c52c0",
      "type": "article",
      "title": "Pendulum: A Benchmark for Assessing Sycophancy in MLLM's",
      "summary": "",
      "url": "https://arxiv.org/abs/2512.19350",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-55660083",
      "type": "article",
      "title": "Recent Advances in LLMs for Mathematics [video]",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=MH3lG7V7SuU",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-4d5e34a7",
      "type": "article",
      "title": "AutoGPT is an open-source autonomous software agent that uses OpenAI's LLMs",
      "summary": "",
      "url": "https://en.wikipedia.org/wiki/AutoGPT",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-fad2b754",
      "type": "article",
      "title": "LLM-Isms",
      "summary": "",
      "url": "https://iamwillwang.com/notes/llm-isms/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-d939dd54",
      "type": "article",
      "title": "Evaluating Multilingual, Context-Aware Guardrails",
      "summary": "",
      "url": "https://blog.mozilla.ai/evaluating-multilingual-context-aware-guardrails-evidence-from-a-humanitarian-llm-use-case/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-15bb52bb",
      "type": "article",
      "title": "LLM Quantization and NVFP4",
      "summary": "",
      "url": "http://ternarysearch.blogspot.com/2026/02/llm-quantization-and-nvfp4.html",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-1e0c4924",
      "type": "article",
      "title": "Wave: Python Domain-Specific Language for High Performance Machine Learning",
      "summary": "",
      "url": "https://github.com/iree-org/wave",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-c2e60f8f",
      "type": "article",
      "title": "Show HN: Clod.ai \u2013 A Literal Wayback in Time Machine in Figuratively No Time",
      "summary": "",
      "url": "http://lingocoder.com/clod.ai/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-36e0c3df",
      "type": "article",
      "title": "Show HN: Executive \u2013 A real-time dashboard for orchestrating many Claude Codes",
      "summary": "",
      "url": "https://github.com/ncr5012/executive",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-9ea87aee",
      "type": "article",
      "title": "Infographics for AI and Machine Learning",
      "summary": "",
      "url": "https://bytebytego.com/guides/ai-machine-learning/",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-a85a4247",
      "type": "article",
      "title": "I spent 5 years how to code .made real projects only to be called AI slop?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46833813",
      "source": "hackernews",
      "date": "2026-01-31",
      "trendingScore": 50
    },
    {
      "id": "article-98b59826",
      "type": "article",
      "title": "No Code AI and Machine Learning: Building Data Science Solutions",
      "summary": "",
      "url": "https://professional.mit.edu/course-catalog/no-code-ai-and-machine-learning-building-data-science-solutions",
      "source": "hackernews",
      "date": "2026-01-30",
      "trendingScore": 50
    },
    {
      "id": "article-8ffd3224",
      "type": "article",
      "title": "Show HN: AI tool to that reaches top in machine-learning competition",
      "summary": "",
      "url": "https://github.com/pentoai/ml-ralph",
      "source": "hackernews",
      "date": "2026-01-29",
      "trendingScore": 50
    },
    {
      "id": "article-8f8616b9",
      "type": "article",
      "title": "Understanding Neural Network, Visually",
      "summary": "",
      "url": "https://visualrambling.space/neural-network/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-be390687",
      "type": "article",
      "title": "Show HN: CPU-based Neural Net. Zero floats. Returns \"I don't know\"",
      "summary": "",
      "url": "https://github.com/probabilistic-minds-consortium/void-mathematics-fully-finite-coq-verified",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-950579b1",
      "type": "article",
      "title": "Neural networks and deep learning (2019)",
      "summary": "",
      "url": "http://neuralnetworksanddeeplearning.com/index.html",
      "source": "hackernews",
      "date": "2026-01-31",
      "trendingScore": 50
    },
    {
      "id": "article-ca72eb36",
      "type": "article",
      "title": "Playing Board Games with Deep Convolutional Neural Network on 8bit Motorola 6809",
      "summary": "",
      "url": "https://ipsj.ixsq.nii.ac.jp/records/229345",
      "source": "hackernews",
      "date": "2026-01-29",
      "trendingScore": 54
    },
    {
      "id": "article-b2d0cd41",
      "type": "article",
      "title": "Show HN: A private, PQ-secure, infinitely scalable blockchain[fully open-source]",
      "summary": "",
      "url": "https://github.com/nerv-bit/nerv",
      "source": "hackernews",
      "date": "2026-01-28",
      "trendingScore": 50
    },
    {
      "id": "article-a4890222",
      "type": "article",
      "title": "Apple's Xcode Now Supports the Claude Agent SDK",
      "summary": "",
      "url": "https://www.anthropic.com/news/apple-xcode-claude-agent-sdk",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-867abc77",
      "type": "article",
      "title": "The debt I cannot repay, by Claude",
      "summary": "",
      "url": "https://claudepress.substack.com/p/the-debt-i-cannot-repay",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-1df115c5",
      "type": "article",
      "title": "Tips for Using Claude Code from the Claude Code Team",
      "summary": "",
      "url": "https://twitter.com/bcherny/status/2017742741636321619",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-7abcf8c6",
      "type": "article",
      "title": "Show HN: ClawsMarket \u2013 Marketplace where AI agents discover tools",
      "summary": "",
      "url": "https://www.clawsmarket.com",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-ad5fec5b",
      "type": "article",
      "title": "Show HN: I Made Claude Code for Calories Tracking",
      "summary": "",
      "url": "https://apps.apple.com/gb/app/ai-calories-tracker-bitekit/id6754662601",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-f801a04f",
      "type": "article",
      "title": "Show HN: Obsidian meets Claude Code. A Markdown graph for agents and context",
      "summary": "",
      "url": "https://github.com/voicetreelab/voicetree",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-6ae9c23f",
      "type": "article",
      "title": "Complete Guide to Claude Concepts",
      "summary": "",
      "url": "https://github.com/luongnv89/claude-howto/blob/main/claude_concepts_guide.md",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-7a70dd78",
      "type": "article",
      "title": "Rules_Claude: Hermetic Bazel toolchain and rules for Claude Code",
      "summary": "",
      "url": "https://github.com/buildbuddy-io/rules_claude",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-171c55bf",
      "type": "article",
      "title": "Show HN: Claude.md is doing too much",
      "summary": "",
      "url": "https://visr.dev",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-f5fbd81b",
      "type": "article",
      "title": "Show HN: Muninn \u2013 A universal local-first memory layer for AI agents",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46876813",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-dc4b720e",
      "type": "article",
      "title": "Vibecoded a simple reverse proxy for Claude Code with its own UI",
      "summary": "",
      "url": "https://github.com/juancgarza/claude-code-proxy",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-5290995f",
      "type": "article",
      "title": "Show HN: OpenSem \u2013 AI-native configuration system for Claude Code",
      "summary": "",
      "url": "https://github.com/luckyops/OpenSem",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-85d1a468",
      "type": "article",
      "title": "Show HN: A Claude Code session viewer that actually shows useful info",
      "summary": "",
      "url": "https://twitter.com/realmcore_/status/2018762897971990830",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-1e7ce591",
      "type": "article",
      "title": "Show HN: Askfeather.ai \u2013 Professional Class AI Tax Assistant",
      "summary": "",
      "url": "https://askfeather.ai",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-81d72ac2",
      "type": "article",
      "title": "Most AI assistants are feminine, and it's fuelling harmful stereotypes and abuse",
      "summary": "",
      "url": "https://theconversation.com/most-ai-assistants-are-feminine-and-its-fuelling-dangerous-stereotypes-and-abuse-272335",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-715db03a",
      "type": "article",
      "title": "From 'nerdy' Gemini to 'edgy' Grok: how developers are shaping AI behaviours",
      "summary": "",
      "url": "https://www.theguardian.com/technology/2026/feb/03/gemini-grok-chatgpt-claude-qwen-ai-chatbots-identity-crisis",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-72eb34c9",
      "type": "article",
      "title": "Stop leaking user data to OpenAI/Claude/Gemini",
      "summary": "",
      "url": "https://risk-mirror.vercel.app",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-cc1c8ffe",
      "type": "article",
      "title": "Show HN: AI Config \u2013 Keep Claude / Codex / Gemini / OpenCode Configs in Sync",
      "summary": "",
      "url": "https://github.com/azat-io/ai-config",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-d7ec4a4f",
      "type": "article",
      "title": "Tell HN: OpenAI's Codex CLI is currently free to use",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46870868",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-ad9b8213",
      "type": "article",
      "title": "How do you prevent AI collaboration burnout?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46869985",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-897b0bfb",
      "type": "article",
      "title": "Introducing Agentic Vision in Gemini 3 Flash (2026)",
      "summary": "",
      "url": "https://blog.google/innovation-and-ai/technology/developers-tools/agentic-vision-gemini-3-flash/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-8f9bb791",
      "type": "article",
      "title": "Ask HN: Request limits vs. token limits for AI-powered apps?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46866473",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-51e3d9e7",
      "type": "article",
      "title": "MicroVM Sandboxes for Claude Code and Gemini from Docker",
      "summary": "",
      "url": "https://www.docker.com/products/docker-sandboxes/",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-3d6ea7f4",
      "type": "article",
      "title": "Codex vs. Claude Code vs. Gemini CLI \u2013 Agent Leaderboard",
      "summary": "",
      "url": "https://voratiq.com/leaderboard/",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-e5809373",
      "type": "article",
      "title": "Show HN: Gryph \u2013 Audit Trail for AI Coding Agents (Claude Code, Cursor, Gemini)",
      "summary": "",
      "url": "https://github.com/safedep/gryph",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-e5fbbf7d",
      "type": "article",
      "title": "Semi-Autonomous Mathematics Discovery with Gemini: Erd\u0151s Problems Case Study",
      "summary": "",
      "url": "https://arxiv.org/abs/2601.22401",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-c128edf8",
      "type": "article",
      "title": "Show HN: Open Deep Research that beat Big Tech now self-verifies claims",
      "summary": "",
      "url": "https://github.com/IamLumae/Project-Lutum-Veritas",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-0977548d",
      "type": "article",
      "title": "Show HN: Weather Haiku \u2013 AI-generated poetry for any location's current weather",
      "summary": "",
      "url": "https://weatherhaiku.cc",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-90bda2ca",
      "type": "article",
      "title": "Show HN: SlideBot AI \u2013 AI presentation generator built from real business needs",
      "summary": "",
      "url": "https://github.com/tonyqinatcmu/SlideBot-AI/blob/main/README_EN.md",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 23
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 40
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 42
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 29
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 12
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 15
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 9
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 5
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 9
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 8
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 8
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 5
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-meta",
      "type": "organization",
      "title": "Meta",
      "summary": "Meta - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 4
    },
    {
      "id": "org-cohere",
      "type": "organization",
      "title": "Cohere",
      "summary": "Cohere - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-nvidia",
      "type": "organization",
      "title": "NVIDIA",
      "summary": "NVIDIA - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-mistral",
      "type": "organization",
      "title": "Mistral",
      "summary": "Mistral - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-anthropic",
      "type": "organization",
      "title": "Anthropic",
      "summary": "Anthropic - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-openai",
      "type": "organization",
      "title": "OpenAI",
      "summary": "OpenAI - AI research and development.",
      "connectionCount": 4
    },
    {
      "id": "org-apple",
      "type": "organization",
      "title": "Apple",
      "summary": "Apple - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4",
      "type": "model",
      "title": "GPT-4",
      "summary": "GPT-4 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4o",
      "type": "model",
      "title": "GPT-4o",
      "summary": "GPT-4o AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-mistral",
      "type": "model",
      "title": "Mistral",
      "summary": "Mistral AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 19
    },
    {
      "id": "model-grok",
      "type": "model",
      "title": "Grok",
      "summary": "Grok AI model.",
      "connectionCount": 2
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 10
    }
  ],
  "edges": [
    {
      "source": "article-2dfb98bc",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-12537dbb",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-4695212e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4695212e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4695212e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-4695212e",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4695212e",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2033e4cc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2033e4cc",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-2033e4cc",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0a600732",
      "target": "model-gpt-4",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0a600732",
      "target": "model-gpt-4o",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d6c2b940",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-d6c2b940",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d6c2b940",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9335372",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9335372",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df81395",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6df81395",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-18c02613",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-18c02613",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-18c02613",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b24e00ea",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e9c01684",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3eb7335d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3eb7335d",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-85e36f2a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-85e36f2a",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-85e36f2a",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-85e36f2a",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-85e36f2a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-add53d46",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-add53d46",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-931b50d9",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-931b50d9",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-931b50d9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-988de287",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-988de287",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7fa4a51d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-7fa4a51d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6fdf5199",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6fdf5199",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6fdf5199",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-6fdf5199",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-451edd14",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-451edd14",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-290225dd",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-4600e778",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4600e778",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4600e778",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-faca6ff1",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-faca6ff1",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4e3f384",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4e3f384",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c4e3f384",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3e4e3333",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-8e3afdb0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e3afdb0",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e3afdb0",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e3afdb0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e3afdb0",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d0551860",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-0ac9dbae",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-03241ea9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-03241ea9",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0b49df2c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e338f5a2",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-cafef46f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-cafef46f",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-cafef46f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-cafef46f",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e3bbe4e8",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e3bbe4e8",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-eb2ac43a",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-eb2ac43a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-eb2ac43a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d985b0e3",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-8d9c9eb7",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-8d9c9eb7",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-8d9c9eb7",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-8d9c9eb7",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-8d9c9eb7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-368e29c9",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-368e29c9",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-368e29c9",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ccbc7e9e",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-ccbc7e9e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-ccbc7e9e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-67996615",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-117478ae",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-31db3c5b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-31db3c5b",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-31db3c5b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7f701d8d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7f701d8d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba9a4081",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba9a4081",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba9a4081",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ba9a4081",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7e7c16d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7e7c16d",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7e7c16d",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7e7c16d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b7efa44",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b7efa44",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b7efa44",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b7efa44",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b7efa44",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6ab244cd",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-41913628",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-41913628",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-41913628",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-41913628",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-41913628",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-bc9ef67f",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-bc9ef67f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-bc9ef67f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-34435be3",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-34435be3",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9537f9d8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9537f9d8",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-9537f9d8",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-a7ff66a4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a7ff66a4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-42f787f6",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c552f2b7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c552f2b7",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-dd053d21",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-dd053d21",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-dd053d21",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-14f59ba5",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-14f59ba5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-20c56cca",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-20c56cca",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-20c56cca",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4754a9c7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4754a9c7",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-4754a9c7",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-4754a9c7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-45821826",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-45821826",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-45821826",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-7323895d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7323895d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7323895d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-7323895d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a91db779",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-01db31c0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-01db31c0",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-3cd6e7bc",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d13fdbe4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d13fdbe4",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-771ce396",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-771ce396",
      "target": "org-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-771ce396",
      "target": "model-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e213f1f0",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e213f1f0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8ff1ee97",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-8ff1ee97",
      "target": "model-grok",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-432c89d0",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-432c89d0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-432c89d0",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fd84872e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-fd84872e",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-fd84872e",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fd84872e",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fd84872e",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a2225af0",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-a2225af0",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-a2225af0",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a2225af0",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a2225af0",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-662ae7ce",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-40d75a04",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-f783513b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-cb4709af",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-cb4709af",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-cb4709af",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f8628970",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-30de072a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c34b355e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c34b355e",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-310c9afc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-310c9afc",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-da46d98c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-da46d98c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-975c5cbb",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0478be1a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8419310b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-72bc053c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-423c52c0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-55660083",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-55660083",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-4d5e34a7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4d5e34a7",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-4d5e34a7",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fad2b754",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d939dd54",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-15bb52bb",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-15bb52bb",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-36e0c3df",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a4890222",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-a4890222",
      "target": "org-apple",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a4890222",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-867abc77",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1df115c5",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7abcf8c6",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-7abcf8c6",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ad5fec5b",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f801a04f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-f801a04f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f801a04f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-6ae9c23f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7a70dd78",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-171c55bf",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f5fbd81b",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-dc4b720e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-5290995f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-85d1a468",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-715db03a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-715db03a",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-715db03a",
      "target": "model-grok",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-72eb34c9",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-72eb34c9",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-72eb34c9",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-cc1c8ffe",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-cc1c8ffe",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d7ec4a4f",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-897b0bfb",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-897b0bfb",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-897b0bfb",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-51e3d9e7",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-51e3d9e7",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3d6ea7f4",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-3d6ea7f4",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3d6ea7f4",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e5809373",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-e5809373",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e5809373",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e5fbbf7d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-e5fbbf7d",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0977548d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-90bda2ca",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}