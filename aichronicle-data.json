{
  "metadata": {
    "lastUpdated": "2026-01-07T06:31:47.825786Z",
    "totalArticles": 132,
    "totalNodes": 158,
    "totalEdges": 202,
    "dateRange": {
      "start": "2026-01-02",
      "end": "2026-01-07"
    }
  },
  "nodes": [
    {
      "id": "article-1268d449",
      "type": "article",
      "title": "Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections",
      "summary": "arXiv:2601.00814v1 Announce Type: new Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar enti",
      "url": "https://arxiv.org/abs/2601.00814",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-9bf07684",
      "type": "article",
      "title": "MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback",
      "summary": "arXiv:2601.00816v1 Announce Type: new Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates ar",
      "url": "https://arxiv.org/abs/2601.00816",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f9af5012",
      "type": "article",
      "title": "Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making",
      "summary": "arXiv:2601.00818v1 Announce Type: new Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system w",
      "url": "https://arxiv.org/abs/2601.00818",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8b7a7eec",
      "type": "article",
      "title": "CogCanvas: Verbatim-Grounded Artifact Extraction for Long LLM Conversations",
      "summary": "arXiv:2601.00821v2 Announce Type: new Abstract: Conversation summarization loses nuanced details: when asked about coding preferences after 40 turns, summarization recalls \"use type hints\" but drops the critical constraint \"everywhere\" (19.0% exact match vs. 93.0% for our approach). We present CogCanvas, a training-free framework inspired by how teams use whiteboards to anchor shared memory. Rather than compressing conversation history, CogCanvas extracts verbatim-grounded artifacts (decisions, ",
      "url": "https://arxiv.org/abs/2601.00821",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d39a0414",
      "type": "article",
      "title": "Energy-Aware Routing to Large Reasoning Models",
      "summary": "arXiv:2601.00823v1 Announce Type: new Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which nei",
      "url": "https://arxiv.org/abs/2601.00823",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-abf20bec",
      "type": "article",
      "title": "Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis",
      "summary": "arXiv:2601.00828v1 Announce Type: new Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=5",
      "url": "https://arxiv.org/abs/2601.00828",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-35c9f81d",
      "type": "article",
      "title": "Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning",
      "summary": "arXiv:2601.00830v1 Announce Type: new Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. Thi",
      "url": "https://arxiv.org/abs/2601.00830",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-1a2b6aa5",
      "type": "article",
      "title": "OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification",
      "summary": "arXiv:2601.00843v1 Announce Type: new Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the \"Black Box\" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexi",
      "url": "https://arxiv.org/abs/2601.00843",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3aa1d71c",
      "type": "article",
      "title": "Enhancing Temporal Awareness in LLMs for Temporal Point Processes",
      "summary": "arXiv:2601.00845v1 Announce Type: new Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that ",
      "url": "https://arxiv.org/abs/2601.00845",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-5971ec6e",
      "type": "article",
      "title": "Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models",
      "summary": "arXiv:2601.00848v1 Announce Type: new Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. ",
      "url": "https://arxiv.org/abs/2601.00848",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-0075f93f",
      "type": "article",
      "title": "Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks",
      "summary": "arXiv:2601.00856v1 Announce Type: new Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) ana",
      "url": "https://arxiv.org/abs/2601.00856",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e90ae87d",
      "type": "article",
      "title": "Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery",
      "summary": "arXiv:2601.00869v1 Announce Type: new Abstract: As artificial intelligence systems increasingly mediate consumer information discovery, brands face algorithmic invisibility. This study investigates Cultural Encoding in Large Language Models (LLMs) -- systematic differences in brand recommendations arising from training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o, Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6 percentage ",
      "url": "https://arxiv.org/abs/2601.00869",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-b2b3be14",
      "type": "article",
      "title": "Universal Conditional Logic: A Formal Language for Prompt Engineering",
      "summary": "arXiv:2601.00880v1 Announce Type: new Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance",
      "url": "https://arxiv.org/abs/2601.00880",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a712315c",
      "type": "article",
      "title": "Counterfactual Self-Questioning for Stable Policy Optimization in Language Models",
      "summary": "arXiv:2601.00885v1 Announce Type: new Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual c",
      "url": "https://arxiv.org/abs/2601.00885",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-ac1448ea",
      "type": "article",
      "title": "Context Collapse: In-Context Learning and Model Collapse",
      "summary": "arXiv:2601.00923v1 Announce Type: new Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear",
      "url": "https://arxiv.org/abs/2601.00923",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-fdc0022c",
      "type": "article",
      "title": "ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems",
      "summary": "arXiv:2601.00994v1 Announce Type: new Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs,",
      "url": "https://arxiv.org/abs/2601.00994",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-95ced44d",
      "type": "article",
      "title": "Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering",
      "summary": "arXiv:2601.01195v1 Announce Type: new Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning e",
      "url": "https://arxiv.org/abs/2601.01195",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-c0a33d9b",
      "type": "article",
      "title": "Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies",
      "summary": "arXiv:2601.01301v1 Announce Type: new Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, \"RMCTS\". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster whe",
      "url": "https://arxiv.org/abs/2601.01301",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-317e41d6",
      "type": "article",
      "title": "Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models",
      "summary": "arXiv:2601.01321v1 Announce Type: new Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing t",
      "url": "https://arxiv.org/abs/2601.01321",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-46852fbb",
      "type": "article",
      "title": "Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale",
      "summary": "arXiv:2601.01330v1 Announce Type: new Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely o",
      "url": "https://arxiv.org/abs/2601.01330",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3343cb0f",
      "type": "article",
      "title": "Physical Transformer",
      "summary": "arXiv:2601.02433v1 Announce Type: new Abstract: Digital AI systems spanning large language models, vision models, and generative architectures that operate primarily in symbolic, linguistic, or pixel domains. They have achieved striking progress, but almost all of this progress lives in virtual spaces. These systems transform embeddings and tokens, yet do not themselves touch the world and rarely admit a physical interpretation. In this work we propose a physical transformer that couples modern ",
      "url": "https://arxiv.org/abs/2601.02433",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-fb5f63dd",
      "type": "article",
      "title": "WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks",
      "summary": "arXiv:2601.02439v1 Announce Type: new Abstract: We present WebGym, the largest-to-date open-source environment for training realistic visual web agents. Real websites are non-stationary and diverse, making artificial or small-scale task sets insufficient for robust policy learning. WebGym contains nearly 300,000 tasks with rubric-based evaluations across diverse, real-world websites and difficulty levels. We train agents with a simple reinforcement learning (RL) recipe, which trains on the agent",
      "url": "https://arxiv.org/abs/2601.02439",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-0bda8543",
      "type": "article",
      "title": "mHC-GNN: Manifold-Constrained Hyper-Connections for Graph Neural Networks",
      "summary": "arXiv:2601.02451v1 Announce Type: new Abstract: Graph Neural Networks (GNNs) suffer from over-smoothing in deep architectures and expressiveness bounded by the 1-Weisfeiler-Leman (1-WL) test. We adapt Manifold-Constrained Hyper-Connections (\\mhc)~\\citep{xie2025mhc}, recently proposed for Transformers, to graph neural networks. Our method, mHC-GNN, expands node representations across $n$ parallel streams and constrains stream-mixing matrices to the Birkhoff polytope via Sinkhorn-Knopp normalizati",
      "url": "https://arxiv.org/abs/2601.02451",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3332af3a",
      "type": "article",
      "title": "Polynomial Convergence of Riemannian Diffusion Models",
      "summary": "arXiv:2601.02499v1 Announce Type: new Abstract: Diffusion models have demonstrated remarkable empirical success in the recent years and are considered one of the state-of-the-art generative models in modern AI. These models consist of a forward process, which gradually diffuses the data distribution to a noise distribution spanning the whole space, and a backward process, which inverts this transformation to recover the data distribution from noise. Most of the existing literature assumes that t",
      "url": "https://arxiv.org/abs/2601.02499",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-6da27e71",
      "type": "article",
      "title": "GEM-Style Constraints for PEFT with Dual Gradient Projection in LoRA",
      "summary": "arXiv:2601.02500v1 Announce Type: new Abstract: Full fine-tuning of Large Language Models (LLMs) is computationally costly, motivating Continual Learning (CL) approaches that utilize parameter-efficient adapters. We revisit Gradient Episodic Memory (GEM) within the Low-Rank Adapter (LoRA) subspace and introduce I-GEM: a fixed-budget, GPU-resident dual projected-gradient approximation to GEM's quadratic projection. By constraining non-interference solely within the adapter parameters, I-GEM prese",
      "url": "https://arxiv.org/abs/2601.02500",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-9d4864a1",
      "type": "article",
      "title": "hdlib 2.0: Extending Machine Learning Capabilities of Vector-Symbolic Architectures",
      "summary": "arXiv:2601.02509v1 Announce Type: new Abstract: Following the initial publication of hdlib, a Python library for designing Vector-Symbolic Architectures (VSA), we introduce a major extension that significantly enhances its machine learning capabilities. VSA, also known as Hyperdimensional Computing, is a computing paradigm that represents and processes information using high-dimensional vectors. While the first version of hdlib established a robust foundation for creating and manipulating these ",
      "url": "https://arxiv.org/abs/2601.02509",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f6f05476",
      "type": "article",
      "title": "LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection",
      "summary": "arXiv:2601.02511v1 Announce Type: new Abstract: Detecting anomalies in time series data is crucial for finance, healthcare, sensor networks, and industrial monitoring applications. However, time series anomaly detection often suffers from sparse labels, complex temporal patterns, and costly expert annotation. We propose a unified framework that integrates Large Language Model (LLM)-based potential functions for reward shaping with Reinforcement Learning (RL), Variational Autoencoder (VAE)-enhanc",
      "url": "https://arxiv.org/abs/2601.02511",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-128108f0",
      "type": "article",
      "title": "Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction",
      "summary": "arXiv:2601.02530v1 Announce Type: new Abstract: We present Connection-Aware Motif Sequencing (CamS), a graph-to-sequence representation that enables decoder-only Transformers to learn molecular graphs via standard next-token prediction (NTP). For molecular property prediction, SMILES-based NTP scales well but lacks explicit topology, whereas graph-native masked modeling captures connectivity but risks disrupting the pivotal chemical details (e.g., activity cliffs). CamS bridges this gap by seria",
      "url": "https://arxiv.org/abs/2601.02530",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-09e47db6",
      "type": "article",
      "title": "Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers",
      "summary": "arXiv:2601.02543v1 Announce Type: new Abstract: In this paper, we propose a novel information theoretic surrogate loss; normalized conditional mutual information (NCMI); as a drop in alternative to the de facto cross-entropy (CE) for training deep neural network (DNN) based classifiers. We first observe that the model's NCMI is inversely proportional to its accuracy. Building on this insight, we introduce an alternating algorithm to efficiently minimize the NCMI. Across image recognition and who",
      "url": "https://arxiv.org/abs/2601.02543",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-cad93c15",
      "type": "article",
      "title": "CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening",
      "summary": "arXiv:2601.02562v1 Announce Type: new Abstract: The rapid growth of dermatological imaging and mobile diagnostic tools calls for systems that not only demonstrate empirical performance but also provide strong theoretical guarantees. Deep learning models have shown high predictive accuracy; however, they are often criticized for lacking well, calibrated uncertainty estimates without which these models are hardly deployable in a clinical setting. To this end, we present the Conformal Bayesian Derm",
      "url": "https://arxiv.org/abs/2601.02562",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e8435775",
      "type": "article",
      "title": "LendNova: Towards Automated Credit Risk Assessment with Language Models",
      "summary": "arXiv:2601.02573v1 Announce Type: new Abstract: Credit risk assessment is essential in the financial sector, but has traditionally depended on costly feature-based models that often fail to utilize all available information in raw credit records. This paper introduces LendNova, the first practical automated end-to-end pipeline for credit risk assessment, designed to utilize all available information in raw credit records by leveraging advanced NLP techniques and language models. LendNova transfo",
      "url": "https://arxiv.org/abs/2601.02573",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-1ccb65ac",
      "type": "article",
      "title": "Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis",
      "summary": "arXiv:2601.02581v1 Announce Type: new Abstract: The accelerated development of social media websites has posed intricate security issues in cyberspace, where these sites have increasingly become victims of criminal activities including attempts to intrude into them, abnormal traffic patterns, and organized attacks. The conventional rule-based security systems are not always scalable and dynamic to meet such a threat. This paper introduces a threat detection framework based on machine learning th",
      "url": "https://arxiv.org/abs/2601.02581",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-c3bb4b2d",
      "type": "article",
      "title": "Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth",
      "summary": "arXiv:2601.02609v1 Announce Type: new Abstract: Large language model fine-tuning is bottlenecked by memory: a 7B parameter model requires 84GB--14GB for weights, 14GB for gradients, and 56GB for FP32 optimizer states--exceeding even A100-40GB capacity. We present Chronicals, an open-source training framework achieving 3.51x speedup over Unsloth through four synergistic optimizations: (1) fused Triton kernels eliminating 75% of memory traffic via RMSNorm (7x), SwiGLU (5x), and QK-RoPE (2.3x) fusi",
      "url": "https://arxiv.org/abs/2601.02609",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-2587e428",
      "type": "article",
      "title": "Credit Assignment via Neural Manifold Noise Correlation",
      "summary": "arXiv:2601.02636v1 Announce Type: new Abstract: Credit assignment--how changes in individual neurons and synapses affect a network's output--is central to learning in brains and machines. Noise correlation, which estimates gradients by correlating perturbations of activity with changes in output, provides a biologically plausible solution to credit assignment but scales poorly as accurately estimating the Jacobian requires that the number of perturbations scale with network size. Moreover, isotr",
      "url": "https://arxiv.org/abs/2601.02636",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-01ee4b89",
      "type": "article",
      "title": "Prioritized Replay for RL Post-training",
      "summary": "arXiv:2601.02648v1 Announce Type: new Abstract: We introduce a problem-level prioritization framework for RL post-training of large language models. Building on insights from prioritized replay in deep RL, as well as prior observations that rollouts with intermediate success rates tend to produce stronger learning signals under methods such as GRPO, our approach selects problems according to a simple, model-driven priority score derived from empirical success statistics. In contrast to conventio",
      "url": "https://arxiv.org/abs/2601.02648",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d747c23a",
      "type": "article",
      "title": "When Prompting Meets Spiking: Graph Sparse Prompting via Spiking Graph Prompt Learning",
      "summary": "arXiv:2601.02662v1 Announce Type: new Abstract: Graph Prompt Feature (GPF) learning has been widely used in adapting pre-trained GNN model on the downstream task. GPFs first introduce some prompt atoms and then learns the optimal prompt vector for each graph node using the linear combination of prompt atoms. However, existing GPFs generally conduct prompting over node's all feature dimensions which is obviously redundant and also be sensitive to node feature noise. To overcome this issue, for th",
      "url": "https://arxiv.org/abs/2601.02662",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-7da9adf4",
      "type": "article",
      "title": "MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods",
      "summary": "arXiv:2601.02668v1 Announce Type: new Abstract: Feature selection is essential for high-dimensional biomedical data, enabling stronger predictive performance, reduced computational cost, and improved interpretability in precision medicine applications. Existing approaches face notable challenges. Filter methods are highly scalable but cannot capture complex relationships or eliminate redundancy. Deep learning-based approaches can model nonlinear patterns but often lack stability, interpretabilit",
      "url": "https://arxiv.org/abs/2601.02668",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-6037ba09",
      "type": "article",
      "title": "Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment",
      "summary": "arXiv:2601.02677v1 Announce Type: new Abstract: Financial institutions and regulators require systems that integrate heterogeneous data to assess risks from stock fluctuations to systemic vulnerabilities. Existing approaches often treat these tasks in isolation, failing to capture cross-scale dependencies. We propose Uni-FinLLM, a unified multimodal large language model that uses a shared Transformer backbone and modular task heads to jointly process financial text, numerical time series, fundam",
      "url": "https://arxiv.org/abs/2601.02677",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-0abb848b",
      "type": "article",
      "title": "Topology-Independent Robustness of the Weighted Mean under Label Poisoning Attacks in Heterogeneous Decentralized Learning",
      "summary": "arXiv:2601.02682v1 Announce Type: new Abstract: Robustness to malicious attacks is crucial for practical decentralized signal processing and machine learning systems. A typical example of such attacks is label poisoning, meaning that some agents possess corrupted local labels and share models trained on these poisoned data. To defend against malicious attacks, existing works often focus on designing robust aggregators; meanwhile, the weighted mean aggregator is typically considered a simple, vul",
      "url": "https://arxiv.org/abs/2601.02682",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-ddb5968c",
      "type": "article",
      "title": "Scaling Laws of Machine Learning for Optimal Power Flow",
      "summary": "arXiv:2601.02706v1 Announce Type: new Abstract: Optimal power flow (OPF) is one of the fundamental tasks for power system operations. While machine learning (ML) approaches such as deep neural networks (DNNs) have been widely studied to enhance OPF solution speed and performance, their practical deployment faces two critical scaling questions: What is the minimum training data volume required for reliable results? How should ML models' complexity balance accuracy with real-time computational lim",
      "url": "https://arxiv.org/abs/2601.02706",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d079a4f3",
      "type": "article",
      "title": "WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables",
      "summary": "arXiv:2601.02391v1 Announce Type: new Abstract: Wearable devices such as AI glasses are transforming voice assistants into always-available, hands-free collaborators that integrate seamlessly with daily life, but they also introduce challenges like egocentric audio affected by motion and noise, rapid micro-interactions, and the need to distinguish device-directed speech from background conversations. Existing benchmarks largely overlook these complexities, focusing instead on clean or generic co",
      "url": "https://arxiv.org/abs/2601.02391",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-b4b54426",
      "type": "article",
      "title": "PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models",
      "summary": "arXiv:2601.02404v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, including software development, education, and technical assistance. Among these, software development is one of the key areas where LLMs are increasingly adopted. However, when hardware constraints are considered-for instance, in physical computing, where software must interact with and control physical hardware -their effectiveness has not been fully ex",
      "url": "https://arxiv.org/abs/2601.02404",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-46474c3f",
      "type": "article",
      "title": "Losses that Cook: Topological Optimal Transport for Structured Recipe Generation",
      "summary": "arXiv:2601.02531v1 Announce Type: new Abstract: Cooking recipes are complex procedures that require not only a fluent and factual text, but also accurate timing, temperature, and procedural coherence, as well as the correct composition of ingredients. Standard training procedures are primarily based on cross-entropy and focus solely on fluency. Building on RECIPE-NLG, we investigate the use of several composite objectives and present a new topological loss that represents ingredient lists as poi",
      "url": "https://arxiv.org/abs/2601.02531",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-1b68b215",
      "type": "article",
      "title": "ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation",
      "summary": "arXiv:2601.02535v1 Announce Type: new Abstract: Selecting a single high-quality output from multiple stochastic generations remains a fundamental challenge for large language models (LLMs), particularly in open-ended tasks where no canonical answer exists. While Best-of-N and self-consistency methods show that aggregating multiple generations can improve performance, existing approaches typically rely on external evaluators, reward models, or exact string-match voting, limiting their applicabili",
      "url": "https://arxiv.org/abs/2601.02535",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-511fbd84",
      "type": "article",
      "title": "LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference",
      "summary": "arXiv:2601.02569v1 Announce Type: new Abstract: Autoregressive large language models (LLMs) are bottlenecked by sequential decoding, where each new token typically requires executing all transformer layers. Existing dynamic-depth and layer-skipping methods reduce this cost, but often rely on auxiliary routing mechanisms or incur accuracy degradation when bypassed layers are left uncompensated. We present \\textbf{LoRA-Drop}, a plug-and-play inference framework that accelerates decoding by applyin",
      "url": "https://arxiv.org/abs/2601.02569",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-353a970c",
      "type": "article",
      "title": "Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency",
      "summary": "arXiv:2601.02574v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly used in applications requiring factual accuracy, yet their outputs often contain hallucinated responses. While fact-checking can mitigate these errors, existing methods typically retrieve external evidence indiscriminately, overlooking the model's internal knowledge and potentially introducing irrelevant noise. Moreover, current systems lack targeted mechanisms to resolve specific uncertainties in the m",
      "url": "https://arxiv.org/abs/2601.02574",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-5636b646",
      "type": "article",
      "title": "DataParasite Enables Scalable and Repurposable Online Data Curation",
      "summary": "arXiv:2601.02578v1 Announce Type: new Abstract: Many questions in computational social science rely on datasets assembled from heterogeneous online sources, a process that is often labor-intensive, costly, and difficult to reproduce. Recent advances in large language models enable agentic search and structured extraction from the web, but existing systems are frequently opaque, inflexible, or poorly suited to scientific data curation. Here we introduce DataParasite, an open-source, modular pipel",
      "url": "https://arxiv.org/abs/2601.02578",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-bbc3e020",
      "type": "article",
      "title": "Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models",
      "summary": "arXiv:2601.02580v1 Announce Type: new Abstract: Traditional methods for determining assessment item parameters, such as difficulty and discrimination, rely heavily on expensive field testing to collect student performance data for Item Response Theory (IRT) calibration. This study introduces a novel approach that implicitly models these psychometric properties by fine-tuning Large Language Models (LLMs) to simulate student responses across a spectrum of latent abilities. Leveraging the Qwen-3 de",
      "url": "https://arxiv.org/abs/2601.02580",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-085703bf",
      "type": "article",
      "title": "FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions",
      "summary": "arXiv:2601.02589v1 Announce Type: new Abstract: Over 3.5 million patents are filed annually, with drafting patent descriptions requiring deep technical and legal expertise. Transforming scientific papers into patent descriptions is particularly challenging due to their differing rhetorical styles and stringent legal requirements. Unlike black-box text-to-text approaches that struggle to model structural reasoning and legal constraints, we propose FlowPlan-G2P, a novel framework that mirrors the ",
      "url": "https://arxiv.org/abs/2601.02589",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-6d48899b",
      "type": "article",
      "title": "Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs",
      "summary": "arXiv:2601.02604v1 Announce Type: new Abstract: The integration of Large Language Models (LLMs) into biomedical research offers new opportunities for domainspecific reasoning and knowledge representation. However, their performance depends heavily on the semantic quality of training data. In oncology, where precision and interpretability are vital, scalable methods for constructing structured knowledge bases are essential for effective fine-tuning. This study presents a pipeline for developing a",
      "url": "https://arxiv.org/abs/2601.02604",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-1ebda538",
      "type": "article",
      "title": "Improved Evidence Extraction for Document Inconsistency Detection with LLMs",
      "summary": "arXiv:2601.02627v1 Announce Type: new Abstract: Large language models (LLMs) are becoming useful in many domains due to their impressive abilities that arise from large training datasets and large model sizes. However, research on LLM-based approaches to document inconsistency detection is relatively limited. There are two key aspects of document inconsistency detection: (i) classification of whether there exists any inconsistency, and (ii) providing evidence of the inconsistent sentences. We fo",
      "url": "https://arxiv.org/abs/2601.02627",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-70ae97d7",
      "type": "article",
      "title": "Empirical Comparison of Encoder-Based Language Models and Feature-Based Supervised Machine Learning Approaches to Automated Scoring of Long Essays",
      "summary": "arXiv:2601.02659v1 Announce Type: new Abstract: Long context may impose challenges for encoder-only language models in text processing, specifically for automated scoring of essays. This study trained several commonly used encoder-based language models for automated scoring of long essays. The performance of these trained models was evaluated and compared with the ensemble models built upon the base language models with a token limit of 512?. The experimented models include BERT-based models (BE",
      "url": "https://arxiv.org/abs/2601.02659",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-31c55c13",
      "type": "article",
      "title": "When Do Tools and Planning Help LLMs Think? A Cost- and Latency-Aware Benchmark",
      "summary": "arXiv:2601.02663v1 Announce Type: new Abstract: Modern large language models (LLMs) increasingly rely on inference-time planning and external tools to improve reasoning. We benchmark this behavior on two real-world settings: event-centric question answering over graph-structured knowledge (Event-QA) and persuasive response generation in Reddit ChangeMyView (CMV). Using LangChain and LangGraph, we compare a one-shot baseline against a plan--execute--replan agent equipped with task-specific tools ",
      "url": "https://arxiv.org/abs/2601.02663",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-c46cdc4c",
      "type": "article",
      "title": "Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking",
      "summary": "arXiv:2601.02669v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed in real-world fact-checking systems, yet existing evaluations focus predominantly on claim verification and overlook the broader fact-checking workflow, including claim extraction and evidence retrieval. This narrow focus prevents current benchmarks from revealing systematic reasoning failures, factual blind spots, and robustness limitations of modern LLMs. To bridge this gap, we present FactAr",
      "url": "https://arxiv.org/abs/2601.02669",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-7d57b7fc",
      "type": "article",
      "title": "Multi-Turn Jailbreaking of Aligned LLMs via Lexical Anchor Tree Search",
      "summary": "arXiv:2601.02670v1 Announce Type: new Abstract: Most jailbreak methods achieve high attack success rates (ASR) but require attacker LLMs to craft adversarial queries and/or demand high query budgets. These resource limitations make jailbreaking expensive, and the queries generated by attacker LLMs often consist of non-interpretable random prefixes. This paper introduces Lexical Anchor Tree Search (), addressing these limitations through an attacker-LLM-free method that operates purely via lexica",
      "url": "https://arxiv.org/abs/2601.02670",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d7bfbfc6",
      "type": "article",
      "title": "Extracting books from production language models",
      "summary": "arXiv:2601.02671v1 Announce Type: new Abstract: Many unresolved legal questions over LLMs and copyright center on memorization: whether specific training data have been encoded in the model's weights during training, and whether those memorized data can be extracted in the model's outputs. While many believe that LLMs do not memorize much of their training data, recent work shows that substantial amounts of copyrighted text can be extracted from open-weight models. However, it remains an open qu",
      "url": "https://arxiv.org/abs/2601.02671",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f48c4c0a",
      "type": "article",
      "title": "Iterative Structured Pruning for Large Language Models with Multi-Domain Calibration",
      "summary": "arXiv:2601.02674v1 Announce Type: new Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide spectrum of natural language processing tasks. However, their ever-growing scale introduces significant barriers to real-world deployment, including substantial computational overhead, memory footprint, and inference latency. While model pruning presents a viable solution to these challenges, existing unstructured pruning techniques often yield irregular sparsity patterns t",
      "url": "https://arxiv.org/abs/2601.02674",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-679f1e9f",
      "type": "article",
      "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems",
      "summary": "arXiv:2601.02695v1 Announce Type: new Abstract: Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art pe",
      "url": "https://arxiv.org/abs/2601.02695",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-eeea6b41",
      "type": "article",
      "title": "Boosting Accuracy and Interpretability in Multilingual Hate Speech Detection Through Layer Freezing and Explainable AI",
      "summary": "arXiv:2601.02697v1 Announce Type: new Abstract: Sentiment analysis focuses on identifying the emotional polarity expressed in textual data, typically categorized as positive, negative, or neutral. Hate speech detection, on the other hand, aims to recognize content that incites violence, discrimination, or hostility toward individuals or groups based on attributes such as race, gender, sexual orientation, or religion. Both tasks play a critical role in online content moderation by enabling the de",
      "url": "https://arxiv.org/abs/2601.02697",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d83a5bab",
      "type": "article",
      "title": "Adversarial Question Answering Robustness: A Multi-Level Error Analysis and Mitigation Study",
      "summary": "arXiv:2601.02700v1 Announce Type: new Abstract: Question answering (QA) systems achieve impressive performance on standard benchmarks like SQuAD, but remain vulnerable to adversarial examples. This project investigates the adversarial robustness of transformer models on the AddSent adversarial dataset through systematic experimentation across model scales and targeted mitigation strategies. We perform comprehensive multi-level error analysis using five complementary categorization schemes, ident",
      "url": "https://arxiv.org/abs/2601.02700",
      "source": "arxiv",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-6e5e60bf",
      "type": "article",
      "title": "Small Yet Mighty: Improve Accuracy In Multimodal Search and Visual Document Retrieval with Llama Nemotron RAG Models",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/llama-nemotron-vl-1b",
      "source": "blogs",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-650e8a5e",
      "type": "article",
      "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
      "summary": "",
      "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-66f18b5e",
      "type": "article",
      "title": "NVIDIA brings agents to life with DGX Spark and Reachy Mini",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia-reachy-mini",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-f2318d54",
      "type": "article",
      "title": "Why AI predictions are so hard",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. Sometimes AI feels like a niche topic to write about, but then the holidays happen, and I hear relatives of all ages talking about cases of chatbot-induced psychosis, blaming rising electricity prices&#8230;",
      "url": "https://www.technologyreview.com/2026/01/06/1130707/why-ai-predictions-are-so-hard/",
      "source": "blogs",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8bdc2f5a",
      "type": "article",
      "title": "What\u2019s next for AI in 2026",
      "summary": "MIT Technology Review\u2019s What\u2019s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. In an industry in constant flux, sticking your neck out to predict what\u2019s coming next may seem reckless. (AI bubble? What AI bubble?) But for the&#8230;",
      "url": "https://www.technologyreview.com/2026/01/05/1130662/whats-next-for-ai-in-2026/",
      "source": "blogs",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-fc968b6d",
      "type": "article",
      "title": "Siemens and Nvidia Expand Partnership to Build the Industrial AI OS",
      "summary": "",
      "url": "https://nvidianews.nvidia.com/news/siemens-and-nvidia-expand-partnership-industrial-ai-operating-system",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-f5f86384",
      "type": "article",
      "title": "Why AI agents stall inside fast-moving teams",
      "summary": "",
      "url": "https://twitter.com/siddhxrth10/status/2008784631370498262",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-977d2850",
      "type": "article",
      "title": "Debunking the AI food delivery hoax that fooled Reddit",
      "summary": "",
      "url": "https://www.platformer.news/fake-uber-eats-whisleblower-hoax-debunked/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-61bf13ca",
      "type": "article",
      "title": "Show HN: AI tutor to study and practice STEM books",
      "summary": "",
      "url": "https://studyjunkie.co/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-67da45c5",
      "type": "article",
      "title": "Show HN: Agentlearn \u2013 Interactive course for AI agent fundamentals",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46522985",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a2214b10",
      "type": "article",
      "title": "Resurrecting My Game Dev Time with AI",
      "summary": "",
      "url": "https://rsaul.com/resurrecting-my-game-dev-project-with-ai/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-460aa6db",
      "type": "article",
      "title": "AIVO Standard Methodology Note: Correction and Assurance Ledger",
      "summary": "",
      "url": "https://zenodo.org/records/18168755",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-ef135e3d",
      "type": "article",
      "title": "LMArena is a cancer on AI",
      "summary": "",
      "url": "https://surgehq.ai/blog/lmarena-is-a-plague-on-ai",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-62562e5c",
      "type": "article",
      "title": "Ask HN: What is your set-up and process for using AI agents in Coding",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46522578",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3e5fce9b",
      "type": "article",
      "title": "When AI writes almost all code, what happens to software engineering?",
      "summary": "",
      "url": "https://newsletter.pragmaticengineer.com/p/when-ai-writes-almost-all-code-what",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-61aec0db",
      "type": "article",
      "title": "Innovation Cycles in an Age of AI",
      "summary": "",
      "url": "https://www.apifirst.tech/p/ai-innovation-cycles",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8a3f81a5",
      "type": "article",
      "title": "AI Is Coming for Your Job. Now What? [video]",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=cJfKqKEyw1o",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e22fe996",
      "type": "article",
      "title": "Show HN: Hostbento.com \u2013 MCP server to host websites designed in AI assistants",
      "summary": "",
      "url": "https://hostbento.com/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-fddcf29a",
      "type": "article",
      "title": "Show HN: Vy, a cross platform AI agent that automates apps without APIs",
      "summary": "",
      "url": "https://vercept.com/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-5e03b7d9",
      "type": "article",
      "title": "Azure GPT-5.1-Codex-Max does not support web search tool",
      "summary": "",
      "url": "https://learn.microsoft.com/en-us/answers/questions/5527650/how-to-get-access-to-web-search-preview-tool-on-ai",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a10992e9",
      "type": "article",
      "title": "Claude Opus 4.5 vs. GLM-4.6",
      "summary": "",
      "url": "https://llm-stats.com/models/compare/claude-opus-4-5-20251101-vs-glm-4.6",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a4dd395e",
      "type": "article",
      "title": "Show HN: Library for HTML interaction using voice agent",
      "summary": "",
      "url": "https://github.com/rajnandan1/atticus",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-537747b0",
      "type": "article",
      "title": "Show HN: Proof that any fixed-axis type system fails for some domain (Lean4)",
      "summary": "",
      "url": "https://zenodo.org/records/18123532",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8ed6f8b2",
      "type": "article",
      "title": "Would you pay for audit of your LLM responses",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46521869",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-a84ab669",
      "type": "article",
      "title": "Why machine learning fails at prioritization problems",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46521799",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8e55d23d",
      "type": "article",
      "title": "Programming is not coding: The cognitive cost of LLM generation",
      "summary": "",
      "url": "https://github.com/oliveigah/misc-text/blob/main/Impact%20of%20LLM%20code%20generation%20on%20programming.md",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-3d3d61db",
      "type": "article",
      "title": "Paper2md \u2013 convert papers to Markdown to be used for LLM context",
      "summary": "",
      "url": "https://github.com/angelotc/paper2md",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-733d0f4a",
      "type": "article",
      "title": "Show HN: Julie update \u2013 local LLMs, CUA, installers and perf gains",
      "summary": "",
      "url": "https://tryjulie.vercel.app/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-8caf8dd8",
      "type": "article",
      "title": "Show HN: Dowser \u2013 Training Data Recommendation System",
      "summary": "",
      "url": "https://huggingface.co/spaces/durinn/dowser",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-b66a0072",
      "type": "article",
      "title": "Show HN: StellarMCP \u2013 Free MCP Tools for Claude and Other LLMs",
      "summary": "",
      "url": "https://stellarmcp.com",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-403855fd",
      "type": "article",
      "title": "Show HN: Enclose Horse \u2013 Daily Puzzle Game",
      "summary": "",
      "url": "https://enclosehorse.com/",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d181b8b4",
      "type": "article",
      "title": "Benchmarking Postgres for FTS with TOASTed JSONBs and GINs Against Elasticsearch",
      "summary": "",
      "url": "https://github.com/inevolin/Postgres-FTS-TOASTed-vs-ElasticSearch",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d7fb0d6f",
      "type": "article",
      "title": "Show HN: Symbolic Circuit Distillation: prove program to LLM circuit equivalence",
      "summary": "",
      "url": "https://github.com/neelsomani/symbolic-circuit-distillation",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 51
    },
    {
      "id": "article-dab272a6",
      "type": "article",
      "title": "Beyond 1s and 0s: Can AI Reason Without the Ability to Ask \"Why?\"",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46511704",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-9165c26c",
      "type": "article",
      "title": "\"I love you\" \"too\": LLM Attention Explained",
      "summary": "",
      "url": "https://kaamvaam.com/machine-learning-ai/llm-attention-explanation/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-4c78339b",
      "type": "article",
      "title": "Show HN: Training a Hamiltonian Neural Netwrork from Scratch in PyTorch",
      "summary": "",
      "url": "https://github.com/ritog/harmonic",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-8bfd8eaf",
      "type": "article",
      "title": "Show HN: ScrollMind \u2013 A visual engineering guide to AI that fits in your feed",
      "summary": "",
      "url": "https://scrollmind.ai",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5b17ee09",
      "type": "article",
      "title": "Practically Utilizing Neural Networks in CPU-Based Production Rendering (JCGT)",
      "summary": "",
      "url": "https://jcgt.org/published/0015/01/01/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f38bf4fb",
      "type": "article",
      "title": "Training a Hamiltonian Neural Network",
      "summary": "",
      "url": "https://ritog.github.io/posts/hamiltonian_nn/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-949fbb3d",
      "type": "article",
      "title": "Visualizing neural network inference in 3D with WebGL and ONNX",
      "summary": "",
      "url": "https://www.erikjs.com/blog/building-neural-network-visualizer",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-e345449d",
      "type": "article",
      "title": "Neural Networks: Zero to Hero",
      "summary": "",
      "url": "https://karpathy.ai/zero-to-hero.html",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 100
    },
    {
      "id": "article-fadf0f36",
      "type": "article",
      "title": "Show HN: Stability First AI \u2013 Recovering memory without training data",
      "summary": "",
      "url": "https://github.com/vitali-sialedchyk/stability-first-ai",
      "source": "hackernews",
      "date": "2026-01-03",
      "trendingScore": 50
    },
    {
      "id": "article-b9019ba6",
      "type": "article",
      "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks (2018)",
      "summary": "",
      "url": "https://arxiv.org/abs/1803.03635",
      "source": "hackernews",
      "date": "2026-01-02",
      "trendingScore": 61
    },
    {
      "id": "article-127e664e",
      "type": "article",
      "title": "Mastering Claude Code in 30 minutes (2025) [video]",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=6eBSHbLKuN0",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-d894ab72",
      "type": "article",
      "title": "Run Claude Code in Obsidian",
      "summary": "",
      "url": "https://github.com/derek-larson14/obsidian-claude-sidebar",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-98600f0d",
      "type": "article",
      "title": "I made a free open-source SwiftUI macOS menu bar app to track Claude Code usage",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46519778",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-780616c7",
      "type": "article",
      "title": "Cooking with Claude",
      "summary": "",
      "url": "https://simonwillison.net/2025/Dec/23/cooking-with-claude/",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-354d2dff",
      "type": "article",
      "title": "Rwx: \"Ralph Wiggum Loop\" util for Claude/codex",
      "summary": "",
      "url": "https://github.com/r2d4/rwx",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-ad4af2ed",
      "type": "article",
      "title": "Show HN: Agents Council \u2013 Connect Claude, Codex, and Local Agents via MCP",
      "summary": "",
      "url": "https://github.com/MrLesk/agents-council",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-b92a9761",
      "type": "article",
      "title": "Claude Playwright plugin without the bloat",
      "summary": "",
      "url": "https://github.com/ddrscott/wiz-marketplace",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f6e3ca6f",
      "type": "article",
      "title": "Show HN: Breakrs \u2013 Natural Language CLI Timer with MCP Server for AI Integration",
      "summary": "",
      "url": "https://github.com/sqrew/breakrs",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-46f0f76f",
      "type": "article",
      "title": "Show HN: Auto-dispatch Linear tasks to Claude Code web via Slack",
      "summary": "",
      "url": "https://github.com/manugomez95/claude-dispatcher",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-422cb7a1",
      "type": "article",
      "title": "Thoughts on Claude Code",
      "summary": "",
      "url": "https://www.spakhm.com/claude-code",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-e9f7b1ba",
      "type": "article",
      "title": "Insights into Claude Opus 4.5 from Pok\u00e9mon",
      "summary": "",
      "url": "https://www.lesswrong.com/posts/u6Lacc7wx4yYkBQ3r/insights-into-claude-opus-4-5-from-pokemon",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-c3925617",
      "type": "article",
      "title": "roborev: Background agent to review your Git commits with Codex or Claude Code",
      "summary": "",
      "url": "https://github.com/wesm/roborev",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-f9c88ab9",
      "type": "article",
      "title": "Show HN: AI that edits your files directly, no approvals [demo]",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46514632",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-27fb2bbc",
      "type": "article",
      "title": "Anthropic reduced usage quota for all Claude users",
      "summary": "",
      "url": "https://github.com/anthropics/claude-code/issues/16157",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 52
    },
    {
      "id": "article-a92417fc",
      "type": "article",
      "title": "Gemini's 3 line execution mode",
      "summary": "",
      "url": "https://olshansky.info/thoughts/2026-01-06-gemini-s-3-line-execution-mode",
      "source": "hackernews",
      "date": "2026-01-07",
      "trendingScore": 50
    },
    {
      "id": "article-e12a5dc0",
      "type": "article",
      "title": "Ask HN: Advise what to pick up to transition into AI/ML space",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46516268",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-744f3221",
      "type": "article",
      "title": "Gemini Protocol Deployment Statistics",
      "summary": "",
      "url": "https://www.obsessivefacts.com/gemini-proxy?uri=gemini%3A%2F%2Fgemini.bortzmeyer.org%2Fsoftware%2Flupa%2Fstats.gmi",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 57
    },
    {
      "id": "article-a93662e9",
      "type": "article",
      "title": "Show HN: VoltCode Run multiple Claude/Gemini tasks in parallel",
      "summary": "",
      "url": "https://github.com/stevensu1977/voltcode",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-184e34c6",
      "type": "article",
      "title": "Show HN: A Ralph Wiggum\u2013Style Gemini CLI Extension",
      "summary": "",
      "url": "https://github.com/AsyncFuncAI/ralph-wiggum-extension",
      "source": "hackernews",
      "date": "2026-01-06",
      "trendingScore": 50
    },
    {
      "id": "article-5abf57e3",
      "type": "article",
      "title": "AI Assistant with Intelligent Memory",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46506268",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-c2c00de9",
      "type": "article",
      "title": "Show HN: I accidentally built \"SQLite for AI memory\" (Memvid)",
      "summary": "",
      "url": "https://github.com/memvid/memvid",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-175d4bb3",
      "type": "article",
      "title": "Show HN: We're pitting 9 AI models in a stock portfolio competition",
      "summary": "",
      "url": "https://portfoliogenius.ai/leaderboards",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-2d246e51",
      "type": "article",
      "title": "Show HN: Context Protocol, a sovereign-first workflow for thinking with LLMs",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46502088",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-1850275a",
      "type": "article",
      "title": "Show HN: Generate photography prompts from a product image (for Gemini)",
      "summary": "",
      "url": "https://imagetransformprompt.com/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-437a5264",
      "type": "article",
      "title": "Show HN: AgTrace \u2013 Observability for AI Coding Agents via MCP (Claude Code etc.)",
      "summary": "",
      "url": "https://github.com/lanegrid/agtrace",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-5ddb05a7",
      "type": "article",
      "title": "Samsung to double AI mobile devices to 800M units this year",
      "summary": "",
      "url": "https://www.reuters.com/world/china/samsung-double-mobile-devices-powered-by-googles-gemini-800-mln-units-this-year-2026-01-05/",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-44ad89be",
      "type": "article",
      "title": "Translating Cave Story into Classical Latin with Gemini",
      "summary": "",
      "url": "https://www.semilin.dev/blog/doukutsu-translator",
      "source": "hackernews",
      "date": "2026-01-05",
      "trendingScore": 50
    },
    {
      "id": "article-b7d7a098",
      "type": "article",
      "title": "Show HN: DayLeet \u2013 A daily habit for sharpening whiteboard logic",
      "summary": "",
      "url": "https://dayleet.com/",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "article-a70dbbed",
      "type": "article",
      "title": "Orchestrating GCP Packet Mirroring with Gemini CLI and Google MCP",
      "summary": "",
      "url": "https://www.thefactorysystem.ai/blog/orchestrating-gcp-packet-mirroring-gemini-cli-google-mcp",
      "source": "hackernews",
      "date": "2026-01-04",
      "trendingScore": 50
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 46
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 3
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 33
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 7
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 12
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 18
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 6
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 3
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 18
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 3
    },
    {
      "id": "topic-diffusion-models",
      "type": "topic",
      "title": "Diffusion Models",
      "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
      "connectionCount": 1
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 4
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 2
    },
    {
      "id": "org-nvidia",
      "type": "organization",
      "title": "NVIDIA",
      "summary": "NVIDIA - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-cohere",
      "type": "organization",
      "title": "Cohere",
      "summary": "Cohere - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-anthropic",
      "type": "organization",
      "title": "Anthropic",
      "summary": "Anthropic - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-chatgpt",
      "type": "model",
      "title": "ChatGPT",
      "summary": "ChatGPT AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4",
      "type": "model",
      "title": "GPT-4",
      "summary": "GPT-4 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-4o",
      "type": "model",
      "title": "GPT-4o",
      "summary": "GPT-4o AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 17
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 9
    },
    {
      "id": "model-llama",
      "type": "model",
      "title": "Llama",
      "summary": "Llama AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gpt-5",
      "type": "model",
      "title": "GPT-5",
      "summary": "GPT-5 AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-gemini-pro",
      "type": "model",
      "title": "Gemini Pro",
      "summary": "Gemini Pro AI model.",
      "connectionCount": 1
    }
  ],
  "edges": [
    {
      "source": "article-1268d449",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1268d449",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9bf07684",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9af5012",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9af5012",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b7a7eec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-d39a0414",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-abf20bec",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-35c9f81d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-35c9f81d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a2b6aa5",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-1a2b6aa5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3aa1d71c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3aa1d71c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5971ec6e",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-0075f93f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0075f93f",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gpt-4",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gpt-4o",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e90ae87d",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b2b3be14",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-a712315c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ac1448ea",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ac1448ea",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdc0022c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fdc0022c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-95ced44d",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c0a33d9b",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c0a33d9b",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-317e41d6",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-46852fbb",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-46852fbb",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3343cb0f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3343cb0f",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-3343cb0f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3343cb0f",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-fb5f63dd",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-fb5f63dd",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0bda8543",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3332af3a",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3332af3a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6da27e71",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6da27e71",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f6f05476",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f6f05476",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-128108f0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-09e47db6",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-cad93c15",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8435775",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8435775",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-e8435775",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c3bb4b2d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c3bb4b2d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c3bb4b2d",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-2587e428",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-2587e428",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-01ee4b89",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-01ee4b89",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d747c23a",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-d747c23a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6037ba09",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6037ba09",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6037ba09",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-0abb848b",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ddb5968c",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d079a4f3",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d079a4f3",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b4b54426",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-46474c3f",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-46474c3f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-46474c3f",
      "target": "org-cohere",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1b68b215",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1b68b215",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1b68b215",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-511fbd84",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-511fbd84",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-511fbd84",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-353a970c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-353a970c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5636b646",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5636b646",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5636b646",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-bbc3e020",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-bbc3e020",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-bbc3e020",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-085703bf",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-085703bf",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-085703bf",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d48899b",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d48899b",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-6d48899b",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-1ebda538",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-70ae97d7",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-70ae97d7",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-31c55c13",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-31c55c13",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-31c55c13",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-31c55c13",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-31c55c13",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c46cdc4c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c46cdc4c",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c46cdc4c",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-c46cdc4c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d57b7fc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d57b7fc",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d57b7fc",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7bfbfc6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7bfbfc6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f48c4c0a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f48c4c0a",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-f48c4c0a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f48c4c0a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-679f1e9f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-679f1e9f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-679f1e9f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-eeea6b41",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-d83a5bab",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d83a5bab",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6e5e60bf",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-6e5e60bf",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-6e5e60bf",
      "target": "model-llama",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-66f18b5e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-66f18b5e",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fc968b6d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-fc968b6d",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f5f86384",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-67da45c5",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-62562e5c",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-8a3f81a5",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-fddcf29a",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5e03b7d9",
      "target": "model-gpt-5",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a10992e9",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a4dd395e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-8ed6f8b2",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e55d23d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8e55d23d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3d3d61db",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3d3d61db",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-733d0f4a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b66a0072",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b66a0072",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d7fb0d6f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d7fb0d6f",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-9165c26c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8bfd8eaf",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-127e664e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-127e664e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d894ab72",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-98600f0d",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-780616c7",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-354d2dff",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ad4af2ed",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ad4af2ed",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b92a9761",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f6e3ca6f",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-46f0f76f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-422cb7a1",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e9f7b1ba",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c3925617",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-c3925617",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-27fb2bbc",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-27fb2bbc",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a92417fc",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-744f3221",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-744f3221",
      "target": "model-gemini-pro",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a93662e9",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a93662e9",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-184e34c6",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2d246e51",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2d246e51",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-1850275a",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-437a5264",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-437a5264",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-44ad89be",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a70dbbed",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a70dbbed",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}