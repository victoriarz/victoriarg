{
  "metadata": {
    "lastUpdated": "2026-02-06T06:53:22.860994Z",
    "totalArticles": 141,
    "totalNodes": 169,
    "totalEdges": 238,
    "dateRange": {
      "start": "2026-01-30",
      "end": "2026-02-06"
    }
  },
  "nodes": [
    {
      "id": "article-d0c8ef7d",
      "type": "article",
      "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
      "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can imp",
      "url": "https://arxiv.org/abs/2602.03900",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-969c04d8",
      "type": "article",
      "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
      "summary": "arXiv:2602.03950v1 Announce Type: new Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents ei",
      "url": "https://arxiv.org/abs/2602.03950",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-44c47286",
      "type": "article",
      "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
      "summary": "arXiv:2602.03955v1 Announce Type: new Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the int",
      "url": "https://arxiv.org/abs/2602.03955",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7cf6b4fb",
      "type": "article",
      "title": "Active Epistemic Control for Query-Efficient Verified Planning",
      "summary": "arXiv:2602.03974v1 Announce Type: new Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \\textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer t",
      "url": "https://arxiv.org/abs/2602.03974",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-93d6cf45",
      "type": "article",
      "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure",
      "summary": "arXiv:2602.03975v1 Announce Type: new Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \\emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a ",
      "url": "https://arxiv.org/abs/2602.03975",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f9b049d7",
      "type": "article",
      "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning",
      "summary": "arXiv:2602.03978v1 Announce Type: new Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model",
      "url": "https://arxiv.org/abs/2602.03978",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7746a5c9",
      "type": "article",
      "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making",
      "summary": "arXiv:2602.04003v1 Announce Type: new Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communic",
      "url": "https://arxiv.org/abs/2602.04003",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-8ad77aee",
      "type": "article",
      "title": "Axiomatic Foundations of Counterfactual Explanations",
      "summary": "arXiv:2602.04028v1 Announce Type: new Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has bee",
      "url": "https://arxiv.org/abs/2602.04028",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-e4609be6",
      "type": "article",
      "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL",
      "summary": "arXiv:2602.04089v1 Announce Type: new Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables ada",
      "url": "https://arxiv.org/abs/2602.04089",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-3158b6dc",
      "type": "article",
      "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
      "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external s",
      "url": "https://arxiv.org/abs/2602.04101",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-aaf09057",
      "type": "article",
      "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
      "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict betwe",
      "url": "https://arxiv.org/abs/2602.04144",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-6479ed0a",
      "type": "article",
      "title": "Steering LLMs via Scalable Interactive Oversight",
      "summary": "arXiv:2602.04210v1 Announce Type: new Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI s",
      "url": "https://arxiv.org/abs/2602.04210",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1d39dc72",
      "type": "article",
      "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons",
      "summary": "arXiv:2602.04213v1 Announce Type: new Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instru",
      "url": "https://arxiv.org/abs/2602.04213",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-b67d3d41",
      "type": "article",
      "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search",
      "summary": "arXiv:2602.04248v1 Announce Type: new Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-",
      "url": "https://arxiv.org/abs/2602.04248",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-ce2e9674",
      "type": "article",
      "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
      "summary": "arXiv:2602.04284v1 Announce Type: new Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings",
      "url": "https://arxiv.org/abs/2602.04284",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-aacf25ed",
      "type": "article",
      "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents",
      "summary": "arXiv:2602.04326v1 Announce Type: new Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent",
      "url": "https://arxiv.org/abs/2602.04326",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-ee8ddf2c",
      "type": "article",
      "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications",
      "summary": "arXiv:2602.04385v1 Announce Type: new Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level ",
      "url": "https://arxiv.org/abs/2602.04385",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-d3c90d2e",
      "type": "article",
      "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control",
      "summary": "arXiv:2602.04496v1 Announce Type: new Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rat",
      "url": "https://arxiv.org/abs/2602.04496",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-364fe029",
      "type": "article",
      "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums",
      "summary": "arXiv:2602.04572v1 Announce Type: new Abstract: While Generative AI (GenAI) systems draw users away from (Q&amp;A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and in",
      "url": "https://arxiv.org/abs/2602.04572",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-2540c6ed",
      "type": "article",
      "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
      "summary": "arXiv:2602.04575v2 Announce Type: new Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired",
      "url": "https://arxiv.org/abs/2602.04575",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-c788da37",
      "type": "article",
      "title": "Denoising diffusion networks for normative modeling in neuroimaging",
      "summary": "arXiv:2602.04886v1 Announce Type: new Abstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenotype (IDP), which scales well but discards multivariate dependence that may encode coordinated patterns. We propose denoising diffusion probabilistic models (DDPMs) as a unified conditional density estim",
      "url": "https://arxiv.org/abs/2602.04886",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-fffd529c",
      "type": "article",
      "title": "A Causal Perspective for Enhancing Jailbreak Attack and Defense",
      "summary": "arXiv:2602.04893v1 Announce Type: new Abstract: Uncovering the mechanisms behind \"jailbreaks\" in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing latent representations, often overlooking the causal relationships between interpretable prompt features and jailbreak occurrences. In this work, we propose Causal Analyst, a framework that integrates LLM",
      "url": "https://arxiv.org/abs/2602.04893",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-8b6c614d",
      "type": "article",
      "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability",
      "summary": "arXiv:2602.04902v1 Announce Type: new Abstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a symplectic augmentation embedding physical priors via the kinematic difference operator $p_t = q_t - q_{t-1}$, implementing the symplectic shear $\\hat{q}_t = q_t + \\gamma p_t$ on queries and keys. We i",
      "url": "https://arxiv.org/abs/2602.04902",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7d2a79f3",
      "type": "article",
      "title": "Mind the Performance Gap: Capability-Behavior Trade-offs in Feature Steering",
      "summary": "arXiv:2602.04903v1 Announce Type: new Abstract: Feature steering has emerged as a promising approach for controlling LLM behavior through direct manipulation of internal representations, offering advantages over prompt engineering. However, its practical effectiveness in real-world applications remains poorly understood, particularly regarding potential trade-offs with output quality. We show that feature steering methods substantially degrade model performance even when successfully controlling",
      "url": "https://arxiv.org/abs/2602.04903",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f743282e",
      "type": "article",
      "title": "DCER: Dual-Stage Compression and Energy-Based Reconstruction",
      "summary": "arXiv:2602.04904v1 Announce Type: new Abstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a unified framework addressing both challenges through dual-stage compression and energy-based reconstruction. The compression stage operates at two levels: within-modality frequency transforms (wavelet for audio, DCT for video) remove noise while preserving task-relevant patterns, and cr",
      "url": "https://arxiv.org/abs/2602.04904",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-5ca56907",
      "type": "article",
      "title": "LISA: Laplacian In-context Spectral Analysis",
      "summary": "arXiv:2602.04906v1 Announce Type: new Abstract: We propose Laplacian In-context Spectral Analysis (LISA), a method for inference-time adaptation of Laplacian-based time-series models using only an observed prefix. LISA combines delay-coordinate embeddings and Laplacian spectral learning to produce diffusion-coordinate state representations, together with a frozen nonlinear decoder for one-step prediction. We introduce lightweight latent-space residual adapters based on either Gaussian-process re",
      "url": "https://arxiv.org/abs/2602.04906",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f5cfe545",
      "type": "article",
      "title": "Physics as the Inductive Bias for Causal Discovery",
      "summary": "arXiv:2602.04907v1 Announce Type: new Abstract: Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these paradigms potentially allows physical knowledge to act as an inductive bias, improving identifiability, stability, and robustness of causal discovery in dynamical systems. However, such integration remains",
      "url": "https://arxiv.org/abs/2602.04907",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-43f8d18a",
      "type": "article",
      "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
      "summary": "arXiv:2602.04908v1 Announce Type: new Abstract: Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this via explicit smoothness penalties, trajectory regularization, or modified probability paths and solvers. We introduce Temporal Pair Consistency (TPC), ",
      "url": "https://arxiv.org/abs/2602.04908",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-3957168a",
      "type": "article",
      "title": "Learning Where It Matters: Geometric Anchoring for Robust Preference Alignment",
      "summary": "arXiv:2602.04909v1 Announce Type: new Abstract: Direct Preference Optimization (DPO) and related methods align large language models from pairwise preferences by regularizing updates against a fixed reference policy. As the policy drifts, a static reference, however, can become increasingly miscalibrated, leading to distributional mismatch and amplifying spurious preference signals under noisy supervision. Conversely, reference-free variants avoid mismatch but often suffer from unconstrained rew",
      "url": "https://arxiv.org/abs/2602.04909",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-0796ddf6",
      "type": "article",
      "title": "A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture",
      "summary": "arXiv:2602.04911v1 Announce Type: new Abstract: We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data are straightforwardly encoded as graphs whose edges correspond to codes from a small fixed primitive set of elemental pairwise relations, such that simple relational encoding is not an add-on, but occu",
      "url": "https://arxiv.org/abs/2602.04911",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-18e6ce82",
      "type": "article",
      "title": "A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model",
      "summary": "arXiv:2602.04913v1 Announce Type: new Abstract: Developing expressive and responsive conversational digital humans is a cornerstone of next-generation human-computer interaction. While large language models (LLMs) have significantly enhanced dialogue capabilities, most current systems still rely on cascaded architectures that connect independent modules. These pipelines are often plagued by accumulated errors, high latency, and poor real-time performance. Lacking access to the underlying convers",
      "url": "https://arxiv.org/abs/2602.04913",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-30d2225a",
      "type": "article",
      "title": "SLAY: Geometry-Aware Spherical Linearized Attention with Yat-Kernel",
      "summary": "arXiv:2602.04915v1 Announce Type: new Abstract: We propose a new class of linear-time attention mechanisms based on a relaxed and computationally efficient formulation of the recently introduced E-Product, often referred to as the Yat-kernel (Bouhsine, 2025). The resulting interactions are geometry-aware and inspired by inverse-square interactions in physics. Our method, Spherical Linearized Attention with Yat Kernels (SLAY), constrains queries and keys to the unit sphere so that attention depen",
      "url": "https://arxiv.org/abs/2602.04915",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-2b63585e",
      "type": "article",
      "title": "Multi-Aspect Mining and Anomaly Detection for Heterogeneous Tensor Streams",
      "summary": "arXiv:2602.04917v1 Announce Type: new Abstract: Analysis and anomaly detection in event tensor streams consisting of timestamps and multiple attributes - such as communication logs(time, IP address, packet length)- are essential tasks in data mining. While existing tensor decomposition and anomaly detection methods provide useful insights, they face the following two limitations. (i) They cannot handle heterogeneous tensor streams, which comprises both categorical attributes(e.g., IP address) an",
      "url": "https://arxiv.org/abs/2602.04917",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-45d9c9ba",
      "type": "article",
      "title": "Simulated Adoption: Decoupling Magnitude and Direction in LLM In-Context Conflict Resolution",
      "summary": "arXiv:2602.04918v1 Announce Type: new Abstract: Large Language Models (LLMs) frequently prioritize conflicting in-context information over pre-existing parametric memory, a phenomenon often termed sycophancy or compliance. However, the mechanistic realization of this behavior remains obscure, specifically how the model resolves these knowledge conflicts through compliance, and whether this suppression arises from signal magnitude dilution or directional geometric alteration within the residual s",
      "url": "https://arxiv.org/abs/2602.04918",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-e35fdcae",
      "type": "article",
      "title": "Gradually Compacting Large Language Models for Reasoning Like a Boiling Frog",
      "summary": "arXiv:2602.04919v1 Announce Type: new Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, but their substantial size often demands significant computational resources. To reduce resource consumption and accelerate inference, it is essential to eliminate redundant parameters without compromising performance. However, conventional pruning methods that directly remove such parameters often lead to a dramatic drop in model performance in reasoning tasks, and r",
      "url": "https://arxiv.org/abs/2602.04919",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-8cbff354",
      "type": "article",
      "title": "CyIN: Cyclic Informative Latent Space for Bridging Complete and Incomplete Multimodal Learning",
      "summary": "arXiv:2602.04920v1 Announce Type: new Abstract: Multimodal machine learning, mimicking the human brain's ability to integrate various modalities has seen rapid growth. Most previous multimodal models are trained on perfectly paired multimodal input to reach optimal performance. In real-world deployments, however, the presence of modality is highly variable and unpredictable, causing the pre-trained models in suffering significant performance drops and fail to remain robust with dynamic missing m",
      "url": "https://arxiv.org/abs/2602.04920",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-26f66cd3",
      "type": "article",
      "title": "Imposing Boundary Conditions on Neural Operators via Learned Function Extensions",
      "summary": "arXiv:2602.04923v1 Announce Type: new Abstract: Neural operators have emerged as powerful surrogates for the solution of partial differential equations (PDEs), yet their ability to handle general, highly variable boundary conditions (BCs) remains limited. Existing approaches often fail when the solution operator exhibits strong sensitivity to boundary forcings. We propose a general framework for conditioning neural operators on complex non-homogeneous BCs through function extensions. Our key ide",
      "url": "https://arxiv.org/abs/2602.04923",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-c847ce89",
      "type": "article",
      "title": "Knowing When to Answer: Adaptive Confidence Refinement for Reliable Audio-Visual Question Answering",
      "summary": "arXiv:2602.04924v1 Announce Type: new Abstract: We present a formal problem formulation for \\textit{Reliable} Audio-Visual Question Answering ($\\mathcal{R}$-AVQA), where we prefer abstention over answering incorrectly. While recent AVQA models have high accuracy, their ability to identify when they are likely wrong and their consequent abstention from answering remain underexplored areas of research. To fill this gap, we explore several approaches and then propose Adaptive Confidence Refinement ",
      "url": "https://arxiv.org/abs/2602.04924",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-2fc173e1",
      "type": "article",
      "title": "Internalizing LLM Reasoning via Discovery and Replay of Latent Actions",
      "summary": "arXiv:2602.04925v1 Announce Type: new Abstract: The internalization of chain-of-thought processes into hidden states has emerged as a highly efficient paradigm for scaling test-time compute. However, existing activation steering methods rely on static control vectors that fail to adapt to the non-stationary evolution of complex reasoning tasks. To address this limitation, we propose STIR (Self-Distilled Tools for Internal Reasoning), a framework that reformulates reasoning enhancement as a dynam",
      "url": "https://arxiv.org/abs/2602.04925",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-48952f74",
      "type": "article",
      "title": "Euphonium: Steering Video Flow Matching via Process Reward Gradient Guided Stochastic Dynamics",
      "summary": "arXiv:2602.04928v1 Announce Type: new Abstract: While online Reinforcement Learning has emerged as a crucial technique for aligning flow matching models with human preferences, current approaches are hindered by inefficient exploration during training rollouts. Relying on undirected stochasticity and sparse outcome rewards, these methods struggle to discover high-reward samples, resulting in data-inefficient and slow optimization. To address these limitations, we propose Euphonium, a novel frame",
      "url": "https://arxiv.org/abs/2602.04928",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-5ea8bf5e",
      "type": "article",
      "title": "BioACE: An Automated Framework for Biomedical Answer and Citation Evaluations",
      "summary": "arXiv:2602.04982v1 Announce Type: new Abstract: With the increasing use of large language models (LLMs) for generating answers to biomedical questions, it is crucial to evaluate the quality of the generated answers and the references provided to support the facts in the generated answers. Evaluation of text generated by LLMs remains a challenge for question answering, retrieval-augmented generation (RAG), summarization, and many other natural language processing tasks in the biomedical domain, d",
      "url": "https://arxiv.org/abs/2602.04982",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-22691e30",
      "type": "article",
      "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System",
      "summary": "arXiv:2602.05004v1 Announce Type: new Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either rely on frequent in-episode reasoning that induces latency and timing jitter, or deliver post-episode improvements through unstructured text that is dif",
      "url": "https://arxiv.org/abs/2602.05004",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-9c37099e",
      "type": "article",
      "title": "Capacity Constraints and the Multilingual Penalty for Lexical Disambiguation",
      "summary": "arXiv:2602.05035v1 Announce Type: new Abstract: Multilingual language models (LMs) sometimes under-perform their monolingual counterparts, possibly due to capacity limitations. We quantify this ``multilingual penalty'' for lexical disambiguation--a task requiring precise semantic representations and contextualization mechanisms--using controlled datasets of human relatedness judgments for ambiguous words in both English and Spanish. Comparing monolingual and multilingual LMs from the same famili",
      "url": "https://arxiv.org/abs/2602.05035",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-ef0ba600",
      "type": "article",
      "title": "Locas: Your Models are Principled Initializers of Locally-Supported Parametric Memories",
      "summary": "arXiv:2602.05085v1 Announce Type: new Abstract: In this paper, we aim to bridge test-time-training with a new type of parametric memory that can be flexibly offloaded from or merged into model parameters. We present Locas, a Locally-Supported parametric memory that shares the design of FFN blocks in modern transformers, allowing it to be flexibly permanentized into the model parameters while supporting efficient continual learning. We discuss two major variants of Locas: one with a conventional ",
      "url": "https://arxiv.org/abs/2602.05085",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-3a11f595",
      "type": "article",
      "title": "Data Kernel Perspective Space Performance Guarantees for Synthetic Data from Transformer Models",
      "summary": "arXiv:2602.05106v1 Announce Type: new Abstract: Scarcity of labeled training data remains the long pole in the tent for building performant language technology and generative AI models. Transformer models -- particularly LLMs -- are increasingly being used to mitigate the data scarcity problem via synthetic data generation. However, because the models are black boxes, the properties of the synthetic data are difficult to predict. In practice it is common for language technology engineers to 'fid",
      "url": "https://arxiv.org/abs/2602.05106",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-fb86e9bd",
      "type": "article",
      "title": "Multilingual Extraction and Recognition of Implicit Discourse Relations in Speech and Text",
      "summary": "arXiv:2602.05107v1 Announce Type: new Abstract: Implicit discourse relation classification is a challenging task, as it requires inferring meaning from context. While contextual cues can be distributed across modalities and vary across languages, they are not always captured by text alone. To address this, we introduce an automatic method for distantly related and unrelated language pairs to construct a multilingual and multimodal dataset for implicit discourse relations in English, French, and ",
      "url": "https://arxiv.org/abs/2602.05107",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-3459cc12",
      "type": "article",
      "title": "GreekMMLU: A Native-Sourced Multitask Benchmark for Evaluating Language Models in Greek",
      "summary": "arXiv:2602.05150v1 Announce Type: new Abstract: Large Language Models (LLMs) are commonly trained on multilingual corpora that include Greek, yet reliable evaluation benchmarks for Greek-particularly those based on authentic, native-sourced content-remain limited. Existing datasets are often machine-translated from English, failing to capture Greek linguistic and cultural characteristics. We introduce GreekMMLU, a native-sourced benchmark for massive multitask language understanding in Greek, co",
      "url": "https://arxiv.org/abs/2602.05150",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-9de45cda",
      "type": "article",
      "title": "Among Us: Measuring and Mitigating Malicious Contributions in Model Collaboration Systems",
      "summary": "arXiv:2602.05176v1 Announce Type: new Abstract: Language models (LMs) are increasingly used in collaboration: multiple LMs trained by different parties collaborate through routing systems, multi-agent debate, model merging, and more. Critical safety risks remain in this decentralized paradigm: what if some of the models in multi-LLM systems are compromised or malicious? We first quantify the impact of malicious models by engineering four categories of malicious LMs, plug them into four types of ",
      "url": "https://arxiv.org/abs/2602.05176",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-115177d1",
      "type": "article",
      "title": "The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems",
      "summary": "arXiv:2602.05182v1 Announce Type: new Abstract: Model collaboration -- systems where multiple language models (LMs) collaborate -- combines the strengths of diverse models with cost in loading multiple LMs. We improve efficiency while preserving the strengths of collaboration by distilling collaborative patterns into a single model, where the model is trained on the outputs of the model collaboration system. At inference time, only the distilled model is employed: it imitates the collaboration w",
      "url": "https://arxiv.org/abs/2602.05182",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-de115f59",
      "type": "article",
      "title": "Are Open-Weight LLMs Ready for Social Media Moderation? A Comparative Study on Bluesky",
      "summary": "arXiv:2602.05189v1 Announce Type: new Abstract: As internet access expands, so does exposure to harmful content, increasing the need for effective moderation. Research has demonstrated that large language models (LLMs) can be effectively utilized for social media moderation tasks, including harmful content detection. While proprietary LLMs have been shown to zero-shot outperform traditional machine learning models, the out-of-the-box capability of open-weight LLMs remains an open question. Motiv",
      "url": "https://arxiv.org/abs/2602.05189",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-29852c60",
      "type": "article",
      "title": "Aligning Large Language Model Behavior with Human Citation Preferences",
      "summary": "arXiv:2602.05205v1 Announce Type: new Abstract: Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process should be controlled remains underexplored. In this study, we focus on what kinds of content LLMs currently tend to cite and how well that behavior aligns w",
      "url": "https://arxiv.org/abs/2602.05205",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7b335dd0",
      "type": "article",
      "title": "Quantifying the Knowledge Proximity Between Academic and Industry Research: An Entity and Semantic Perspective",
      "summary": "arXiv:2602.05211v1 Announce Type: new Abstract: The academia and industry are characterized by a reciprocal shaping and dynamic feedback mechanism. Despite distinct institutional logics, they have adapted closely in collaborative publishing and talent mobility, demonstrating tension between institutional divergence and intensive collaboration. Existing studies on their knowledge proximity mainly rely on macro indicators such as the number of collaborative papers or patents, lacking an analysis o",
      "url": "https://arxiv.org/abs/2602.05211",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-2b11c14e",
      "type": "article",
      "title": "Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions",
      "summary": "arXiv:2602.05220v1 Announce Type: new Abstract: Current audio foundation models typically rely on rigid, task-specific supervision, addressing isolated factors of audio rather than the whole. In contrast, human intelligence processes audio holistically, seamlessly bridging physical signals with abstract cognitive concepts to execute complex tasks. Grounded in this philosophy, we introduce Bagpiper, an 8B audio foundation model that interprets physical audio via rich captions, i.e., comprehensive",
      "url": "https://arxiv.org/abs/2602.05220",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-cefa0a27",
      "type": "article",
      "title": "FedMosaic: Federated Retrieval-Augmented Generation via Parametric Adapters",
      "summary": "arXiv:2602.05235v1 Announce Type: new Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by grounding generation in external knowledge to improve factuality and reduce hallucinations. Yet most deployments assume a centralized corpus, which is infeasible in privacy aware domains where knowledge remains siloed. This motivates federated RAG (FedRAG), where a central LLM server collaborates with distributed silos without sharing raw documents. In context RAG violate",
      "url": "https://arxiv.org/abs/2602.05235",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-7d588ea0",
      "type": "article",
      "title": "Copyright Detective: A Forensic System to Evidence LLMs Flickering Copyright Leakage Risks",
      "summary": "arXiv:2602.05252v1 Announce Type: new Abstract: We present Copyright Detective, the first interactive forensic system for detecting, analyzing, and visualizing potential copyright risks in LLM outputs. The system treats copyright infringement versus compliance as an evidence discovery process rather than a static classification task due to the complex nature of copyright law. It integrates multiple detection paradigms, including content recall testing, paraphrase-level similarity analysis, persu",
      "url": "https://arxiv.org/abs/2602.05252",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-9fbf4e9c",
      "type": "article",
      "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
      "summary": "arXiv:2602.05258v1 Announce Type: new Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoPE frequencies to accommodate unseen positions, and (2) Semantic Modeling, which posits that the attention scores computed with RoPE should always priori",
      "url": "https://arxiv.org/abs/2602.05258",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-12a23324",
      "type": "article",
      "title": "Length-Unbiased Sequence Policy Optimization: Revealing and Controlling Response Length Variation in RLVR",
      "summary": "arXiv:2602.05261v1 Announce Type: new Abstract: Recent applications of Reinforcement Learning with Verifiable Rewards (RLVR) to Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated significant success in enhancing reasoning capabilities for complex tasks. During RLVR training, an increase in response length is often regarded as a key factor contributing to the growth of reasoning ability. However, the patterns of change in response length vary significantly across dif",
      "url": "https://arxiv.org/abs/2602.05261",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1565aa2d",
      "type": "article",
      "title": "Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science",
      "summary": "arXiv:2602.05289v1 Announce Type: new Abstract: Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical trial-and-error. It lacks a unified and principled scientific framework necessary for systematic optimization and improvement. This bottleneck stems from ",
      "url": "https://arxiv.org/abs/2602.05289",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-cca09de5",
      "type": "article",
      "title": "MentorCollab: Selective Large-to-Small Inference-Time Guidance for Efficient Reasoning",
      "summary": "arXiv:2602.05307v1 Announce Type: new Abstract: Large reasoning models (LRMs) achieve strong performance by producing long chains of thought, but their inference costs are high and often generate redundant reasoning. Small language models (SLMs) are far more efficient, yet struggle on multi-step reasoning tasks. A natural idea is to let a large model guide a small one at inference time as a mentor, yet existing collaboration methods often promote imitation, resulting in verbose reasoning without",
      "url": "https://arxiv.org/abs/2602.05307",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-b50b3538",
      "type": "article",
      "title": "How Do Language Models Acquire Character-Level Information?",
      "summary": "arXiv:2602.05347v1 Announce Type: new Abstract: Language models (LMs) have been reported to implicitly encode character-level information, despite not being explicitly provided during training. However, the mechanisms underlying this phenomenon remain largely unexplored. To reveal the mechanisms, we analyze how models acquire character-level knowledge by comparing LMs trained under controlled settings, such as specifying the pre-training dataset or tokenizer, with those trained under standard se",
      "url": "https://arxiv.org/abs/2602.05347",
      "source": "arxiv",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-e42f6ff4",
      "type": "article",
      "title": "Natively Adaptive Interfaces: A new framework for AI accessibility",
      "summary": "A collage of four images, the first of a woman with curly hair in front of a silver laptop, the second of the same woman and a man with short black hair speaking on a stairwell, the third of a the same man with glasses, and an aerial image of NTID",
      "url": "https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-828c66e8",
      "type": "article",
      "title": "How Google Cloud is helping Team USA elevate their tricks with AI",
      "summary": "A woman outdoors in the snow looks at a tablet. A half pipe is behind her.",
      "url": "https://blog.google/innovation-and-ai/infrastructure-and-cloud/google-cloud/us-ski-snowboard-tool-winter-olympics-2026/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-f9c339ba",
      "type": "article",
      "title": "Watch our new Gemini ad ahead of football\u2019s biggest weekend",
      "summary": "A toddler in a blue and yellow striped shirt sits on a kitchen counter eating a red apple. Text in the corner reads: 'New Home, Google Gemini SB Commercial\u2019",
      "url": "https://blog.google/company-news/inside-google/company-announcements/gemini-ad-new-home/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-1eabfc9f",
      "type": "article",
      "title": "The latest AI news we announced in January",
      "summary": "mp4 showing a carousel of images including a card reading \"Help that's made for you\"",
      "url": "https://blog.google/innovation-and-ai/products/google-ai-updates-january-2026/",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-a91db779",
      "type": "article",
      "title": "How we\u2019re helping preserve the genetic information of endangered species with AI",
      "summary": "A four-part vertical collage showing a cotton-top tamarin, an ibex, a golden lion tamarin, and a penguin.",
      "url": "https://blog.google/innovation-and-ai/technology/ai/ai-to-preserve-endangered-species/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-12f40143",
      "type": "article",
      "title": "Advancing AI benchmarking with Game Arena",
      "summary": "An illustration of a King and Ace playing card, a wolf's head, two chess pieces, a poker chip, and other abstract shapes on a white background.1",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-4b956a17",
      "type": "article",
      "title": "Introducing SyGra Studio",
      "summary": "",
      "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-5a59b4d6",
      "type": "article",
      "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3\u2019s Top Model",
      "summary": "",
      "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-54a2e4d6",
      "type": "article",
      "title": "Community Evals: Because we're done trusting black-box leaderboards over the community",
      "summary": "",
      "url": "https://huggingface.co/blog/community-evals",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-bb1053f9",
      "type": "article",
      "title": "H Company's new Holo2 model takes the lead in UI Localization",
      "summary": "",
      "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-74bdaef6",
      "type": "article",
      "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
      "summary": "",
      "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-a0998dd5",
      "type": "article",
      "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
      "summary": "",
      "url": "https://huggingface.co/blog/Photoroom/prx-part2",
      "source": "blogs",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-4c5e5bb4",
      "type": "article",
      "title": "This is the most misunderstood graph in AI",
      "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what\u2019s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn\u2019t exhale until METR, an AI&#8230;",
      "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
      "source": "blogs",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-1ca5a016",
      "type": "article",
      "title": "From guardrails to governance: A CEO\u2019s guide for securing agentic systems",
      "summary": "The previous article in this series, \u201cRules fail at the prompt, succeed at the boundary,\u201d focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;",
      "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
      "source": "blogs",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4dab3d5d",
      "type": "article",
      "title": "What we\u2019ve been getting wrong about AI\u2019s truth crisis",
      "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about\u2014where AI content dupes us, shapes our beliefs even when we catch the lie, and&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-771ce396",
      "type": "article",
      "title": "The crucial first step for designing a successful enterprise AI system",
      "summary": "Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes\u2014but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most difficult problems. Whether it\u2019s increasing CX productivity with Cisco, building a more&#8230;",
      "url": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
      "source": "blogs",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-e213f1f0",
      "type": "article",
      "title": "Inside the marketplace powering bespoke AI deepfakes of real women",
      "summary": "Civitai\u2014an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz\u2014is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic images banned by the site, a new analysis has found. The study, from researchers at Stanford and Indiana&#8230;",
      "url": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
      "source": "blogs",
      "date": "2026-01-30",
      "trendingScore": 50
    },
    {
      "id": "article-723e91f6",
      "type": "article",
      "title": "PaperBanana \u2013 Generate publication-ready academic figures with AI",
      "summary": "",
      "url": "https://www.paperbanana.xyz/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-5f0d0859",
      "type": "article",
      "title": "Show HN: Hive Agent \u2013 Embed Claude Code-like AI agents in your app",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46909873",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-6c226016",
      "type": "article",
      "title": "Beat AI in Incident Diagnosis Competition \u2013 $225 in Prizes, This Saturday",
      "summary": "",
      "url": "https://incidentfox.slack.com/join/shared_invite/zt-3ojlxvs46-xuEJEplqBHPlymxtzQi8KQ?nojsmode=1",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-646b7880",
      "type": "article",
      "title": "Show HN: Termoil \u2013 Terminal dashboard for managing parallel AI coding agents",
      "summary": "",
      "url": "https://github.com/fantom845/termoil",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-c47322d0",
      "type": "article",
      "title": "How exposed are software stocks to AI tools? We put vibe-coding to the test",
      "summary": "",
      "url": "https://www.cnbc.com/2026/02/05/how-exposed-are-software-stocks-to-ai-tools-we-tested-vibe-coding.html",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f5582bb1",
      "type": "article",
      "title": "What can still be a reasonable AI bear thesis?",
      "summary": "",
      "url": "https://metacriticcapital.substack.com/p/what-can-still-be-a-reasonable-ai",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-982a8b5f",
      "type": "article",
      "title": "Show HN: Cursor Agent Factory \u2013 5-layer architecture for AI agent systems",
      "summary": "",
      "url": "https://github.com/gitwalter/cursor-agent-factory",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f963044a",
      "type": "article",
      "title": "Open-Source Software in the Age of AI",
      "summary": "",
      "url": "https://essays.johnloeber.com/p/31-open-source-software-in-the-age",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-30f81c9f",
      "type": "article",
      "title": "Unbrowse \u2013 100x faster web automation for AI agents",
      "summary": "",
      "url": "https://github.com/lekt9/unbrowse-openclaw",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-194bbbbc",
      "type": "article",
      "title": "Memory for AI agents in 6 lines of code",
      "summary": "",
      "url": "https://github.com/topoteretes/cognee",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-afbdde05",
      "type": "article",
      "title": "Olimex HoT aims to be lightweight, easier-to-use alternative to Home Assistant",
      "summary": "",
      "url": "https://www.cnx-software.com/2026/02/06/olimex-hot-aims-to-be-lightweight-easier-to-use-alternative-to-home-assistant/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f727f24e",
      "type": "article",
      "title": "Craft \u2013 image models can think like LLMs",
      "summary": "",
      "url": "https://huggingface.co/blog/flymy-ai/craft-1",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-20134f6e",
      "type": "article",
      "title": "Show HN: Built AI Music Generator Using Claude 4.5 and 4.6",
      "summary": "",
      "url": "https://trymusic.ai",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-b3509e44",
      "type": "article",
      "title": "Ask HN: 10 months since the Llama-4 release: what happened to Meta AI?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46909060",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 51
    },
    {
      "id": "article-80b1885c",
      "type": "article",
      "title": "Show HN: An LLM-enabled bash-based shell for Linux",
      "summary": "",
      "url": "https://yoshell.ai/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1d8da9f1",
      "type": "article",
      "title": "Show HN: T87s \u2013 LLM-optimized cache invalidation with ACID consistency",
      "summary": "",
      "url": "https://t87s.dev",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-c8be4a92",
      "type": "article",
      "title": "Show HN: Free Unlimited Claude Code usage with Nvidia NIM models",
      "summary": "",
      "url": "https://github.com/Alishahryar1/claude-code-free",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-a35bbb6f",
      "type": "article",
      "title": "I Gave Claude Code Infinity Gauntlet of LLMs",
      "summary": "",
      "url": "https://github.com/Pickle-Pixel/HydraMCP",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-14db9944",
      "type": "article",
      "title": "I shipped 706 commits in 5 days with Taskwarrior and Claude Code",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46908809",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-11425cc4",
      "type": "article",
      "title": "Study: Meta AI model can reproduce almost half of Harry Potter book",
      "summary": "",
      "url": "https://arstechnica.com/features/2025/06/study-metas-llama-3-1-can-recall-42-percent-of-the-first-harry-potter-book/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-71ce3d2e",
      "type": "article",
      "title": "Style tips for less experienced developers coding with AI",
      "summary": "",
      "url": "https://honnibal.dev/blog/llm-style-tips",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-71a2e0b5",
      "type": "article",
      "title": "Show HN: Reader \u2013 open-source web scraping engine built for LLMs",
      "summary": "",
      "url": "https://github.com/vakra-dev/reader",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-aea76289",
      "type": "article",
      "title": "Llms.txt \u2013 A Robots.txt for AI Assistants",
      "summary": "",
      "url": "https://seekrates-ai.com/llms-txt-file/",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-dce374a4",
      "type": "article",
      "title": "LLMs do plan before they genenrate tokens",
      "summary": "",
      "url": "https://arxiv.org/abs/2502.06258",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1969b0cc",
      "type": "article",
      "title": "A Very Small SAT Solver (From Haskell) Now in Dafny, Proved Correct with LLMs",
      "summary": "",
      "url": "https://github.com/namin/dafny-sandbox/blob/master/Sat.dfy",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-6c079d6d",
      "type": "article",
      "title": "Mark Russinovich's BSOD Photomosaic",
      "summary": "",
      "url": "https://github.com/markrussinovich/bsodmosaic",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-d3d9536e",
      "type": "article",
      "title": "Portfolio Monitor \u2013 Claude Code skill for multi-broker portfolio analytics",
      "summary": "",
      "url": "https://github.com/2165187809-AXE/portfolio-monitor",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-13646364",
      "type": "article",
      "title": "Show HN: Skeletoken, a Python package for editing model tokenizers",
      "summary": "",
      "url": "https://github.com/stephantul/skeletoken",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-c2d508d8",
      "type": "article",
      "title": "Show HN: LayerClaw \u2013 Observability tool for PyTorch training",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46892694",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-31345870",
      "type": "article",
      "title": "Why Most Machine Learning Projects Fail to Reach Production \u2013 InfoQ",
      "summary": "",
      "url": "https://www.infoq.com/articles/why-ml-projects-fail-production/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-4b903709",
      "type": "article",
      "title": "Show HN: PostgreSQL extension for privacy \u2013 AI training and RAG monetization",
      "summary": "",
      "url": "https://github.com/machine-squelch/kernel-privacy",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-1e0c4924",
      "type": "article",
      "title": "Wave: Python Domain-Specific Language for High Performance Machine Learning",
      "summary": "",
      "url": "https://github.com/iree-org/wave",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-c2e60f8f",
      "type": "article",
      "title": "Show HN: Clod.ai \u2013 A Literal Wayback in Time Machine in Figuratively No Time",
      "summary": "",
      "url": "http://lingocoder.com/clod.ai/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-9ea87aee",
      "type": "article",
      "title": "Infographics for AI and Machine Learning",
      "summary": "",
      "url": "https://bytebytego.com/guides/ai-machine-learning/",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-a85a4247",
      "type": "article",
      "title": "I spent 5 years how to code .made real projects only to be called AI slop?",
      "summary": "",
      "url": "https://news.ycombinator.com/item?id=46833813",
      "source": "hackernews",
      "date": "2026-01-31",
      "trendingScore": 50
    },
    {
      "id": "article-98b59826",
      "type": "article",
      "title": "No Code AI and Machine Learning: Building Data Science Solutions",
      "summary": "",
      "url": "https://professional.mit.edu/course-catalog/no-code-ai-and-machine-learning-building-data-science-solutions",
      "source": "hackernews",
      "date": "2026-01-30",
      "trendingScore": 50
    },
    {
      "id": "article-29a8aa5e",
      "type": "article",
      "title": "Hypernetworks: Neural Networks for Hierarchical Data",
      "summary": "",
      "url": "https://blog.sturdystatistics.com/posts/hnet_part_I/",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 55
    },
    {
      "id": "article-8f8616b9",
      "type": "article",
      "title": "Understanding Neural Network, Visually",
      "summary": "",
      "url": "https://visualrambling.space/neural-network/",
      "source": "hackernews",
      "date": "2026-02-03",
      "trendingScore": 50
    },
    {
      "id": "article-be390687",
      "type": "article",
      "title": "Show HN: CPU-based Neural Net. Zero floats. Returns \"I don't know\"",
      "summary": "",
      "url": "https://github.com/probabilistic-minds-consortium/void-mathematics-fully-finite-coq-verified",
      "source": "hackernews",
      "date": "2026-02-02",
      "trendingScore": 50
    },
    {
      "id": "article-950579b1",
      "type": "article",
      "title": "Neural networks and deep learning (2019)",
      "summary": "",
      "url": "http://neuralnetworksanddeeplearning.com/index.html",
      "source": "hackernews",
      "date": "2026-01-31",
      "trendingScore": 50
    },
    {
      "id": "article-023976cd",
      "type": "article",
      "title": "Deep Dive: How Claude Code's /Insights Command Works",
      "summary": "",
      "url": "https://www.zolkos.com/2026/02/04/deep-dive-how-claude-codes-insights-command-works.html",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1b59b4e0",
      "type": "article",
      "title": "OpenAI and Anthropic go to war: Claude Opus 4.6 vs. GPT 5.3 Codex",
      "summary": "",
      "url": "https://www.latent.space/p/ainews-openai-and-anthropic-go-to",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-bf56ebd3",
      "type": "article",
      "title": "UX Anti-patterns skill: Catch the UX sins Claude ships when you're not looking",
      "summary": "",
      "url": "https://github.com/cassiozen/UX-antipatterns",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-a668dfa1",
      "type": "article",
      "title": "Claude Opus 4.6 System Card [pdf]",
      "summary": "",
      "url": "https://www-cdn.anthropic.com/0dd865075ad3132672ee0ab40b05a53f14cf5288.pdf",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-1fb34713",
      "type": "article",
      "title": "Show HN: MIE \u2013 Shared memory for all your AI agents (Claude, Cursor, ChatGPT)",
      "summary": "",
      "url": "https://github.com/kraklabs/mie",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-2031cb97",
      "type": "article",
      "title": "Claude has been having a moment \u2013 can it keep it up?",
      "summary": "",
      "url": "https://www.theverge.com/report/874308/anthropic-claude-code-opus-hype-moment",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-e126d6ff",
      "type": "article",
      "title": "Counter-Strike Bench: GPT 5.3 Codex vs. Claude Opus 4.6",
      "summary": "",
      "url": "https://www.instantdb.com/essays/codex_53_opus_46_cs_bench",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-f4bd28b2",
      "type": "article",
      "title": "Watch Claude Code debug WebGPU code without a GPU",
      "summary": "",
      "url": "https://www.youtube.com/watch?v=x791YvPIhFo",
      "source": "hackernews",
      "date": "2026-02-06",
      "trendingScore": 50
    },
    {
      "id": "article-be227acf",
      "type": "article",
      "title": "Show HN: Askie \u2013 Child-safe AI voice chat and art creation for kids (ages 4-15)",
      "summary": "",
      "url": "https://kidsai.app",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-fef6ca90",
      "type": "article",
      "title": "Beyond Roleplay: Jailbreaking Gemini with drugs and ritual",
      "summary": "",
      "url": "https://tidepool.leaflet.pub/3me44bxloz227",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-1afd7cc8",
      "type": "article",
      "title": "Show HN: Athena \u2013 A sovereign, local-first AI agent framework (anti-subscription",
      "summary": "",
      "url": "https://github.com/winstonkoh87/Athena-Public",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-635110c9",
      "type": "article",
      "title": "Show HN: Relai \u2013 Share context between AI assistants, 100% local",
      "summary": "",
      "url": "https://github.com/kirillpolevoy/relai",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-cf586a8e",
      "type": "article",
      "title": "Show HN: AgentCircuit \u2013 Circuit breaker for AI agent functions",
      "summary": "",
      "url": "https://github.com/simranmultani197/AgentCircuit",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-08bbd89b",
      "type": "article",
      "title": "Google deprecates Gemini-2.5-pro",
      "summary": "",
      "url": "https://ai.google.dev/gemini-api/docs/deprecations",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-da40c4b3",
      "type": "article",
      "title": "Show HN: Remote AI coding without moving your code \u2013 CloudForge",
      "summary": "",
      "url": "https://cloud-forge.me",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-7f3f6185",
      "type": "article",
      "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
      "summary": "",
      "url": "https://arxiv.org/abs/2602.03837",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-81163fe5",
      "type": "article",
      "title": "Show HN: All in One AI Assistant",
      "summary": "",
      "url": "https://fluxchat.org/",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-8073388e",
      "type": "article",
      "title": "Show HN: Toktrack \u2013 1000x faster AI CLI cost tracker (Rust and SIMD)",
      "summary": "",
      "url": "https://github.com/mag123c/toktrack",
      "source": "hackernews",
      "date": "2026-02-05",
      "trendingScore": 50
    },
    {
      "id": "article-64de52e2",
      "type": "article",
      "title": "Google takes down YouTube video of Claude Code running rings around Gemini",
      "summary": "",
      "url": "https://stateofutopia.com/7gYBAB4.png",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-ba2c11c0",
      "type": "article",
      "title": "Evolve SDK \u2013 Open-Source Manus Powered by Claude Code, Codex CLI, Gemini CLI",
      "summary": "",
      "url": "https://github.com/evolving-machines-lab/manus-evolve",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-5b8cddbd",
      "type": "article",
      "title": "Choosing Antigravity or Gemini CLI",
      "summary": "",
      "url": "https://cloud.google.com/blog/topics/developers-practitioners/choosing-antigravity-or-gemini-cli/",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-715db03a",
      "type": "article",
      "title": "From 'nerdy' Gemini to 'edgy' Grok: how developers are shaping AI behaviours",
      "summary": "",
      "url": "https://www.theguardian.com/technology/2026/feb/03/gemini-grok-chatgpt-claude-qwen-ai-chatbots-identity-crisis",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "article-52c2e04c",
      "type": "article",
      "title": "Workspace Studio- Automate your work with Gemini",
      "summary": "",
      "url": "https://studio.workspace.google.com/u/0/templates",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 51
    },
    {
      "id": "article-d462b192",
      "type": "article",
      "title": "Show HN: Codag \u2013 Visualize and share LLM workflows in VS Code",
      "summary": "",
      "url": "https://github.com/michaelzixizhou/codag",
      "source": "hackernews",
      "date": "2026-02-04",
      "trendingScore": 50
    },
    {
      "id": "topic-large-language-models",
      "type": "topic",
      "title": "Large Language Models",
      "summary": "Foundation models trained on massive text corpora that can generate and understand natural language.",
      "connectionCount": 48
    },
    {
      "id": "topic-ai-reasoning",
      "type": "topic",
      "title": "AI Reasoning",
      "summary": "Methods to improve logical reasoning, mathematical problem-solving, and multi-step thinking in AI systems.",
      "connectionCount": 16
    },
    {
      "id": "topic-prompt-engineering",
      "type": "topic",
      "title": "Prompt Engineering",
      "summary": "Methods for crafting effective prompts to guide AI model behavior and outputs.",
      "connectionCount": 5
    },
    {
      "id": "topic-ai-agents",
      "type": "topic",
      "title": "AI Agents",
      "summary": "Autonomous AI systems that can plan, use tools, and take actions to accomplish goals.",
      "connectionCount": 22
    },
    {
      "id": "topic-nlp",
      "type": "topic",
      "title": "NLP",
      "summary": "Natural Language Processing: AI techniques for understanding and generating human language.",
      "connectionCount": 32
    },
    {
      "id": "topic-reinforcement-learning",
      "type": "topic",
      "title": "Reinforcement Learning",
      "summary": "Training AI through rewards and penalties to learn optimal behaviors.",
      "connectionCount": 21
    },
    {
      "id": "topic-ai-safety",
      "type": "topic",
      "title": "AI Safety",
      "summary": "Research focused on making AI systems safe, aligned with human values, and beneficial.",
      "connectionCount": 5
    },
    {
      "id": "topic-multimodal-ai",
      "type": "topic",
      "title": "Multimodal AI",
      "summary": "Systems that process and understand multiple types of input including text, images, audio, and video.",
      "connectionCount": 7
    },
    {
      "id": "topic-rag",
      "type": "topic",
      "title": "RAG",
      "summary": "Retrieval-Augmented Generation: combining LLMs with external knowledge retrieval for more accurate responses.",
      "connectionCount": 7
    },
    {
      "id": "topic-computer-vision",
      "type": "topic",
      "title": "Computer Vision",
      "summary": "AI systems for understanding and processing visual information from images and video.",
      "connectionCount": 12
    },
    {
      "id": "topic-model-efficiency",
      "type": "topic",
      "title": "Model Efficiency",
      "summary": "Techniques to reduce computational costs and improve inference speed of AI models.",
      "connectionCount": 3
    },
    {
      "id": "topic-diffusion-models",
      "type": "topic",
      "title": "Diffusion Models",
      "summary": "Generative models that create content by iteratively denoising random noise into structured outputs.",
      "connectionCount": 3
    },
    {
      "id": "topic-fine-tuning",
      "type": "topic",
      "title": "Fine-tuning",
      "summary": "Adapting pre-trained models to specific tasks or domains.",
      "connectionCount": 3
    },
    {
      "id": "org-meta",
      "type": "organization",
      "title": "Meta",
      "summary": "Meta - AI research and development.",
      "connectionCount": 3
    },
    {
      "id": "org-aws",
      "type": "organization",
      "title": "AWS",
      "summary": "AWS - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-google",
      "type": "organization",
      "title": "Google",
      "summary": "Google - AI research and development.",
      "connectionCount": 5
    },
    {
      "id": "org-apple",
      "type": "organization",
      "title": "Apple",
      "summary": "Apple - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-openai",
      "type": "organization",
      "title": "OpenAI",
      "summary": "OpenAI - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-anthropic",
      "type": "organization",
      "title": "Anthropic",
      "summary": "Anthropic - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-mistral",
      "type": "organization",
      "title": "Mistral",
      "summary": "Mistral - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "org-meta-ai",
      "type": "organization",
      "title": "Meta AI",
      "summary": "Meta AI - AI research and development.",
      "connectionCount": 2
    },
    {
      "id": "org-nvidia",
      "type": "organization",
      "title": "NVIDIA",
      "summary": "NVIDIA - AI research and development.",
      "connectionCount": 1
    },
    {
      "id": "model-gemini",
      "type": "model",
      "title": "Gemini",
      "summary": "Gemini AI model.",
      "connectionCount": 9
    },
    {
      "id": "model-mistral",
      "type": "model",
      "title": "Mistral",
      "summary": "Mistral AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-claude",
      "type": "model",
      "title": "Claude",
      "summary": "Claude AI model.",
      "connectionCount": 16
    },
    {
      "id": "model-llama",
      "type": "model",
      "title": "Llama",
      "summary": "Llama AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-chatgpt",
      "type": "model",
      "title": "ChatGPT",
      "summary": "ChatGPT AI model.",
      "connectionCount": 1
    },
    {
      "id": "model-grok",
      "type": "model",
      "title": "Grok",
      "summary": "Grok AI model.",
      "connectionCount": 1
    }
  ],
  "edges": [
    {
      "source": "article-d0c8ef7d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d0c8ef7d",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d0c8ef7d",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-969c04d8",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-969c04d8",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-969c04d8",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-44c47286",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-44c47286",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-44c47286",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-7cf6b4fb",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7cf6b4fb",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-93d6cf45",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-93d6cf45",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9b049d7",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9b049d7",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9b049d7",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7746a5c9",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7746a5c9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-8ad77aee",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-8ad77aee",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e4609be6",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e4609be6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e4609be6",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e4609be6",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-3158b6dc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3158b6dc",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-aaf09057",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-aaf09057",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-aaf09057",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-aaf09057",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-6479ed0a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-6479ed0a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d39dc72",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d39dc72",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b67d3d41",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b67d3d41",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-b67d3d41",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-b67d3d41",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-ce2e9674",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-ce2e9674",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ce2e9674",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-ce2e9674",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-aacf25ed",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-aacf25ed",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-aacf25ed",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-ee8ddf2c",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-ee8ddf2c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3c90d2e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3c90d2e",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3c90d2e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3c90d2e",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3c90d2e",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-364fe029",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-364fe029",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2540c6ed",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-2540c6ed",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2540c6ed",
      "target": "org-aws",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c788da37",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-c788da37",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fffd529c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-fffd529c",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-fffd529c",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-fffd529c",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b6c614d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-8b6c614d",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d2a79f3",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d2a79f3",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d2a79f3",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f743282e",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-f743282e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-f743282e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ca56907",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ca56907",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ca56907",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-f5cfe545",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-43f8d18a",
      "target": "topic-diffusion-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-43f8d18a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3957168a",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3957168a",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-3957168a",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-3957168a",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-0796ddf6",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-18e6ce82",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-18e6ce82",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-18e6ce82",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-45d9c9ba",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-45d9c9ba",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-e35fdcae",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-e35fdcae",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e35fdcae",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-8cbff354",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-8cbff354",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-26f66cd3",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-c847ce89",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-c847ce89",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-2fc173e1",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2fc173e1",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-48952f74",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-48952f74",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-48952f74",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ea8bf5e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ea8bf5e",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-5ea8bf5e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-22691e30",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-22691e30",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-22691e30",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-22691e30",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-9c37099e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9c37099e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-ef0ba600",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3a11f595",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3a11f595",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3a11f595",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-fb86e9bd",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-fb86e9bd",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-3459cc12",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-3459cc12",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-9de45cda",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9de45cda",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-9de45cda",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-115177d1",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-115177d1",
      "target": "topic-model-efficiency",
      "relationship": "COVERS"
    },
    {
      "source": "article-de115f59",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-de115f59",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-29852c60",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-2b11c14e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-cefa0a27",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-cefa0a27",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-cefa0a27",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-cefa0a27",
      "target": "topic-fine-tuning",
      "relationship": "COVERS"
    },
    {
      "source": "article-7d588ea0",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9fbf4e9c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-9fbf4e9c",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-12a23324",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-12a23324",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-12a23324",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-12a23324",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-12a23324",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-1565aa2d",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1565aa2d",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-cca09de5",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-cca09de5",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-cca09de5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-b50b3538",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-b50b3538",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-e42f6ff4",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e42f6ff4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-828c66e8",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-f9c339ba",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "org-apple",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f9c339ba",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1eabfc9f",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-a91db779",
      "target": "topic-ai-reasoning",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a59b4d6",
      "target": "topic-multimodal-ai",
      "relationship": "COVERS"
    },
    {
      "source": "article-5a59b4d6",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-a0998dd5",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "topic-reinforcement-learning",
      "relationship": "COVERS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4c5e5bb4",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1ca5a016",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-1ca5a016",
      "target": "topic-prompt-engineering",
      "relationship": "COVERS"
    },
    {
      "source": "article-771ce396",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-771ce396",
      "target": "org-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-771ce396",
      "target": "model-mistral",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e213f1f0",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-e213f1f0",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-723e91f6",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f0d0859",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-5f0d0859",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-646b7880",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-982a8b5f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-30f81c9f",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-194bbbbc",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-f727f24e",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-f727f24e",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-20134f6e",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-20134f6e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b3509e44",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b3509e44",
      "target": "org-meta-ai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-b3509e44",
      "target": "model-llama",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-80b1885c",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1d8da9f1",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-c8be4a92",
      "target": "org-nvidia",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-c8be4a92",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a35bbb6f",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-a35bbb6f",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-14db9944",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-11425cc4",
      "target": "org-meta",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-11425cc4",
      "target": "org-meta-ai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-71a2e0b5",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-aea76289",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-dce374a4",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-1969b0cc",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "article-d3d9536e",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-4b903709",
      "target": "topic-rag",
      "relationship": "COVERS"
    },
    {
      "source": "article-023976cd",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1b59b4e0",
      "target": "org-openai",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1b59b4e0",
      "target": "org-anthropic",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1b59b4e0",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-bf56ebd3",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-a668dfa1",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1fb34713",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-1fb34713",
      "target": "model-chatgpt",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1fb34713",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-2031cb97",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-e126d6ff",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-f4bd28b2",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-fef6ca90",
      "target": "topic-ai-safety",
      "relationship": "COVERS"
    },
    {
      "source": "article-fef6ca90",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-1afd7cc8",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-635110c9",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-cf586a8e",
      "target": "topic-ai-agents",
      "relationship": "COVERS"
    },
    {
      "source": "article-08bbd89b",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-08bbd89b",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-7f3f6185",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-64de52e2",
      "target": "topic-computer-vision",
      "relationship": "COVERS"
    },
    {
      "source": "article-64de52e2",
      "target": "org-google",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-64de52e2",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-64de52e2",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ba2c11c0",
      "target": "model-claude",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-ba2c11c0",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-5b8cddbd",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-715db03a",
      "target": "topic-nlp",
      "relationship": "COVERS"
    },
    {
      "source": "article-715db03a",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-715db03a",
      "target": "model-grok",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-52c2e04c",
      "target": "model-gemini",
      "relationship": "MENTIONS"
    },
    {
      "source": "article-d462b192",
      "target": "topic-large-language-models",
      "relationship": "COVERS"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-reasoning",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-ai-agents",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-large-language-models",
      "target": "topic-rag",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-multimodal-ai",
      "target": "topic-computer-vision",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-agents",
      "target": "topic-prompt-engineering",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-model-efficiency",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    },
    {
      "source": "topic-ai-safety",
      "target": "topic-large-language-models",
      "relationship": "RELATED_TO"
    }
  ]
}